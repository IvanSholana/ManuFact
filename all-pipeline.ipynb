{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. LOAD DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/combined_train_dataset.csv\")\n",
    "test_df = pd.read_csv(\"./dataset/Test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. PREPROCESSING TRAIN DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 DROP UNRELEVANT FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=['Lithology_code'],inplace=True)\n",
    "train_df = train_df.drop(columns=['DTS','SGR','ROPA','RMIC','RXO','DCAL','RSHA','file_name','filename','DEPTH_MD','Z_LOC','MUDWEIGHT','PEF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 CLEANING DTC AND CONVERT TO NUMBER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus 'val:' dan '[UNIT]' serta konversi ke float\n",
    "def clean_value(value):\n",
    "    if isinstance(value, str):  # Pastikan nilai adalah string\n",
    "        # Hapus 'val:' jika ada\n",
    "        if 'val:' in value:\n",
    "            value = value.replace('val:', '').strip()\n",
    "        # Hapus '[UNIT]' jika ada\n",
    "        if '[UNIT]' in value:\n",
    "            value = value.replace('[UNIT]', '').strip()\n",
    "        # Coba konversi ke float\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return value  # Kembalikan asli jika gagal konversi\n",
    "    # Jika bukan string (misalnya sudah float), kembalikan apa adanya\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return value  # Kembalikan asli jika gagal konversi\n",
    "\n",
    "# Terapkan fungsi ke kolom DTC\n",
    "train_df['DTC'] = train_df['DTC'].apply(clean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 FILL NAN LOCATION FEATURE WITH CDKTREE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# Ensure X_LOC and Y_LOC have no missing values\n",
    "train_df = train_df.dropna(subset=['X_LOC', 'Y_LOC'])\n",
    "\n",
    "# Create KDTree using valid spatial coordinates\n",
    "coords = train_df[['X_LOC', 'Y_LOC']].values\n",
    "tree = cKDTree(coords)\n",
    "\n",
    "# Find the 2 nearest neighbors (excluding itself)\n",
    "_, idx = tree.query(coords, k=3)  # k=3 for backup if the first neighbor is missing\n",
    "\n",
    "# Fill missing values using nearest neighbor\n",
    "for col in ['NPHI', 'DTC', 'SP', 'GR', 'RHOB', 'CALI']:\n",
    "    missing_mask = train_df[col].isna()  # Find missing values\n",
    "    \n",
    "    # Create an empty array to store filled values\n",
    "    filled_values = train_df[col].values.copy()\n",
    "    \n",
    "    for i, is_missing in enumerate(missing_mask):\n",
    "        if is_missing:\n",
    "            # Check nearest neighbors\n",
    "            for neighbor_idx in idx[i, 1:]:  # Skip self (idx[i, 0] is the same point)\n",
    "                if not np.isnan(train_df.iloc[neighbor_idx][col]):  # Use first non-NaN neighbor\n",
    "                    filled_values[i] = train_df.iloc[neighbor_idx][col]\n",
    "                    break  # Stop after finding the first valid neighbor\n",
    "    \n",
    "    # Assign the new filled values\n",
    "    train_df[col] = filled_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4 CREATE CLUSTER FEATURE BY (X_LOC AND DEPT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAIjCAYAAAD/Q/hmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABewklEQVR4nO3dB5QUVdbA8TukAZScc5CcoyxJQZIomMFFJIkYAFEQXMFAUhFFQBcEUQF1F0EWYVkFliQgHyB5BZQMkhFYYAQkyNR37tPu7Z7pnukZqkN1/3/nFExXV9fUzJtw59Z998VZlmUJAAAA4DAZwn0BAAAAQHoQyAIAAMCRCGQBAADgSASyAAAAcCQCWQAAADgSgSwAAAAciUAWAAAAjkQgCwAAAEcikAUAAIAjEcgCQBLNmjUzmxOtWLFC4uLizP8AEO0IZAGHmj59uglYXFvWrFmlaNGi0qZNG3nvvffkl19+SfaaYcOGeb0mQ4YMUqRIEWnXrp2sW7cu2fHbtm2Thx56SEqVKmXOX6xYMWnVqpX89a9/TXbs9evXZdq0aSYAzJs3r8THx0vp0qWlR48esnHjRp8fw/vvv2+uo0GDBn4/Tte1vvPOO34/B/7On9TJkydl4MCBUqlSJcmePbvcdNNNUrduXXnttdfk3LlzEipvvPGGzJs3L2TvDwCiVaZwXwCAGzNixAgpU6aMXLt2TU6cOGEycc8995yMHTtW5s+fLzVq1Ej2mkmTJsnNN98siYmJcvjwYfnwww/ltttuk/Xr10utWrXMMWvWrJHmzZtLyZIlpVevXlK4cGFzrAa87777rjzzzDPu8/3666/ywAMPyKJFi8x5hgwZYoLZgwcPyhdffCGffPKJHDp0SIoXL+51HX//+99NsKvvd+/evVKuXDm/H+fbb78tTz/9tAlA02PDhg1y1113yYULF+TRRx81AazSIPjNN9+UVatWyeLFiyVUgaz+gXDffffZfm79/Ot4ZMmSxfZzA0CkIZAFHK5t27ZSr1499+PBgwfL8uXLTZb1nnvukR9//FGyZcvm9RoNovLnz+9+rAFVtWrVZPbs2e5A9vXXX5dcuXKZADB37txer//555+9Hg8aNMgEsePGjTNBtKehQ4ea/UkdOHDABMtffvmlPPnkkyao1WN90WvaunWrTJ48WQYMGCBppdnW+++/XzJmzChbtmwxGVlP+rFqMO9kly9fNsGrZtk1ew4AsYDSAiAK3XHHHfLKK6/ITz/9JH/7299SPV6zrSpTpv/9bbtv3z6pWrVqsiBWFSxY0P32kSNH5IMPPjAlB0mDWKXBo97O95WNzZMnj9x9990msNbH/jRu3Nh8TG+99ZbJNqaVXt/Ro0dNljppEKsKFSokL7/8st/Xu0oYNMOcWj3qnj175MEHHzSfUw0o9eP+85//LOfPnzfP6/EXL140WWpX2UT37t3dr9frfOyxx8w1aXmGjsHUqVN9vt+ZM2ea69aSD81UJyQk+LwmLffQP1R++OEHk2XXY/U1+vlMSr9m9A8gLbvQce7fv7/8+9//pu4WQEQiIwtEqS5duphb/Hq7XEsDPP33v/81/2tpgQZOI0eONEFXx44d3cdoXezatWtl+/btJgjyZ+HChfLbb7+Z95cWGrhqOYJmETt16mTKHTT7W79+fZ/Ha32v3jbX49KaldUSC81Ka8AcTFevXjU1yleuXDGlFxrM6uf3q6++MllhzXB/9tln8vjjj8utt94qTzzxhHndLbfc4q7h/dOf/mSCxr59+0qBAgXM57dnz54mSE36h4KOm37+9A8FfZ8plROcPXtW7rzzTvM513H+xz/+IX/5y1+kevXqJquvNMDWPxiOHz8uzz77rLn+GTNmyDfffBPUzxsApBeBLBClNBOogZNmVpOqWLGi12PNuurkI83+uWhwpAGO3tbXoKtp06bSokULk9HLnDmz+zgtXVAaEAVq06ZNsnPnTveksSZNmpjr1eDWXyCr71/ft6tWNmm5REr0GitUqBD0ulHNeGrJhJZoeAbNr776qvttrc996qmnpGzZsuZtTy+99JKZNKeT7PLly2f26bEa6GsgryUYnh+3lhNojW8gn4tjx47Jp59+6v6DQ4Nj/WPl448/dgeymrnev3+/+Vq49957zT59n7Vr177hzw0ABAOlBUAU0wldvroXzJkzR5YsWWKytdppQIM8vR2uNasuWiqgGVm9zfyf//zH3IbWbKPektYMp4tmClWOHDkCvi4NWPXWuQamSjOQDz/8sLlVroGcPxrM6YQ2rZVNC73GtFxfeukfDkpvxV+6dClNr7Usy4xL+/btzdunT592b/p519KEzZs3e72mW7duAQf0+rXgGThrUK9/oGjg6qJ1zjq+OuYumqlPmtEHgEhBIJsKncmsv1i0rZH+sk1Pyxz9pTRmzBgTLGjNm/6i0MklQLDpDH1fAZzeom/ZsqUJVrU+c9myZeY4z04ESrOjOhlLb0trZwGdSKaBsWYbNfuocubMaf73FTD7ooGqBqwaxGr2UrsV6KYtuPTWul6LP3rd+rq01srqNQZ6fTdCu0do2cNHH31kJtNpADpx4kR3fWxKTp06ZcoPpkyZYkoKPDdtYeZrkp2+v0Bpxlt/hnnSGmUdW8/6WC1zSHpcSt0kACCcCGRToTVjNWvWNL+M0ktrzfQXmwazejtVs1maCQGCSSdhaQAVSBCi2ToNJDXjp1/zSWn2ToNabRulNara6ktvnyvX5Cm9HR4I7aigNZgazJYvX969uepzU5r0pbSzgWZl9TZ4oPQad+/ebWpY0yNpYOfiK3us/W6///57U5+swXa/fv1MyYaOR0q0Xllp1lSz5b42nfTmKS3lFTrpzt8f2gDgVNTIpkJrx1z1Y77oBAuta/v8889NNkUnxYwePdq9KpDW5ukvfp0w46pLTEsWBUgvnVSkNCsYCJ2w5cri6ox1f1ytvjQYVfr9oUGSdkcIZMKXBqo6G97XH4ea/Z07d64pHfAXpN1+++3m+0u/zzxrT1Oid1W0TEJv3Wu9aVpp5lIlXTRBM5i+aL2wbtpRQMs1NADVj0kXXvAXGGvmVbPiGhxrtjwctGZWM+0a3Hpeo2bMASASkZG9QTqzWH9BanZJszAdOnQwM4O1BY/617/+ZSZ16KxlDWC1+bvOWHbNGgeCQbOeOqNdv+Y6d+6c6vH69agBl85Sd7XW0pnqvrJ1CxYsMP+7/jArUaKEqaHUeltfK35pplGzlJqR1AylBqva41bLE5Ju+v2kJQCeNbgp1crqbfhA6IQpXcHs+eefN5nZpPSWvSvI9MXVVUBLjVw04Ez6/rUW1/UHgYsGtNrbVf/oddE/FJIGxfrHgNYpa7Ctf/j6Kj0INv2jR7sseH7+dUKZ03vsAoheZGRvgK5UpBNl9H+toXXN9NYJE7pfb8PqRArN2uhtWJ0xrL/8tC+j/tLWYAO4UdqeSUtWNIDSGlP9utLb0Jpd04DEV3N8bb2k5QQaqOpsdp25rrWSmjV0ZeK0XlYnLOlCAnprXm/La7A7a9Ys99KzLhqoancEvY3uClQ1i6nfG/q1r9envVT1ejRQ9ZxM5ElbT2lmUrO2OvnLH83K6rZy5cqAPkd6LZrp1ZW9tAuD58peWk6hd1QaNmzo9/VaGqDXpjXCGvTrqmX6x2vSoFU/9xqM6x+0WhOvz2tm3BWkuuj7Xrp0qelrqz879A8OLe3QFcb0Dwh9W/84qFKlinl/eo16fLD/ANYOBRMmTDBZay2J0uBfx8L1NeSvxAIAwsZCwPTTNXfuXPfjr776yuy76aabvLZMmTJZHTt2NMf06tXLHLNr1y736zZt2mT27dy5MywfB6LDtGnTzNeRa8uSJYtVuHBhq1WrVta7775rJSQkJHvN0KFDvV7j+vpt2LCh9cUXX3gdu3DhQuuxxx6zKlWqZN18883m/OXKlbOeeeYZ6+TJk8nO/dtvv1kfffSR1bRpUytXrlxW5syZrVKlSlk9evSwtmzZYo5p3769lTVrVuvixYt+P67u3bub154+fdo81mvs06dPsuO++eYb98ewYcOGgD5nx44ds/r3729VqFDBXEf27NmtunXrWq+//rp1/vx593G333672Tzt27fPatmypRUfH28VKlTIGjJkiLVkyRLz/vVa1P79+83n7JZbbjHnz5s3r9W8eXNr6dKlXufS7/3bbrvNypYtm3l9t27d3M/p51Y/3hIlSpjPg45pixYtrClTpiT72GfPnu338+K6JtfHU7Vq1WTH6vvVMfKkH8Pdd99trq1AgQLW888/b82ZM8ecc926dQF9ngEgVOL0n/CF0c6i2QjN6rjWR9fMlN623bFjR7KJFJrt0tu0OjFFM7M6OcZFb6/qyjp6K1ZnjQNAJBs/fry5k6TlIdp1BQAiBaUFN0CbhGupgNbXabN2X3SSh95e1Nuurjo7V42e3voFgEiif2gnXXRBO0RoZwmCWACRhkA2FTqD23PGrva93Lp1q6mR0xo4zch27drV1AhqYKsTMrQPZo0aNcwa8jr7uE6dOmbtdM1q6MSXPn36mEysvh4AIokuYVuyZElTS6zt27QbhdY4p9YWDQDCgdKCVKxYscK9+lDSFXWmT59uSgZ0trNO5NLZvtoEXSeFDB8+3L1kp06m0YkzWkqgs5W1XZEGvhoMA0Ak0T+4te/1wYMHzR0nnXD2wgsvpDj5DgDChUAWAAAgiowaNcp0kNG7KVoq1KhRI9N729U20VU2pC0JtQOLtgfU9nvvv/++WT7cHw0Zde6PtuTTFoJaPqm98rX0KFzoIwsAABBFVq5cacoY161bZ9ox6t3j1q1be63cqBM4tde9tkjU4/XusZYWpUSXB3/vvfdMq8bvvvvO3GXWAFiD4nAhIwsAABDFTp06ZRa70YD1tttuM/Xv2rN7xowZpq+90uxt5cqVzSJPWiKZlIaL2vdas7jaM1/peTSDq6WW2is8HJjs5YNOyNK/THS5SBqAAwDgDBps6aIrGnDpinqhpplJXTwmGJIuHa3i4+PNlhoNOJVrbs6mTZtMltZzOWxd+EYnevoLZHWyu66o6PmaXLlymQVc9DUEshFEg1hddhMAADjP4cOHpXjx4iEPYsuULiAnTl4Iyvm1P712UvI0dOhQs2R3asm55557ztSzVqtWzezTgDRLliySO3dur2M1u6rP+eLan7SGNqXXhAKBrA+aiXV9I+TMmTPcl2P+atKOB1rfkjlz5nBfDgLAmDkPY+ZMjJvzBHPMEhISTCLK9Xs8lDQTq0HsTzv6Sc4cqWdJ0yLhlytSqup7yeKS+ACysVoru337dlm9erVEIwJZH1ype/1iiZRAVlcC02vhB7UzMGbOw5g5E+PmPKEYs3CWBebIkUVy5Mxi6zktsxp32uOSvn37yldffSWrVq3yylDryqMaeGvnAc+s7MmTJ81zvrj26zFFihTxeo32nQ4XuhYAAADYJFGsoGxpraft27evzJ07V5YvXy5lypTxer5u3brmjwhdwMll165dcujQIWnYsKHPc+o5NJj1fI1mwLV7gb/XhAKBLAAAQBTp06ePWZVPuxJomYXWsOqmS1C7Jmn17NlTBgwYIN98842Z/NWjRw8TkHpO9NIJYBoMu7LcWmuri0DNnz9ftm3bZlY21Yl19913X9g+VkoLAAAAbCwDcJUC2HnOtJg0aZL5v1mzZl77p02bJt27dzdvjxs3znR2ePDBB70WRPCkWVpXxwOlq/xpL9onnnjClCU0adJEFi1aJFmzZpVwIZAFAACIIlYASwRo8Dlx4kSzBXoezcqOGDHCbJGCQBYAACCKMrKxhBpZAAAAOBIZWQAAAJskWpbZ7D4nfCMjCwAAAEciIwsAAGATzZ3anT8lH+sfgSwAAIBN0rOAQSDnhG+UFgAAAMCRyMgCAADYhPZboUUgG6U+2t3U/fbjFb4N67UAAAAEA4FsFAewSfcR0AIAEFyJ1u+b3eeEb9TIRnkQm5bnAQAAnISMbJQgSAUAIPxovxVaZGRjDAEvAACIFmRkAQAAbEIf2dAikAUAALCJhpyJQTgnfKO0IMbQuQAAAEQLMrIAAAA2YbJXaJGRjaFMK9lYAAAQTQhko0hKgSpBLAAAwZcocUHZ4BulBVGGgBUAAMQKAlkAAACbWNbvm93nhG+UFgAAAMCRwh7IHj16VB599FHJly+fZMuWTapXry4bN270e3z37t0lLi4u2Va1alX3McOGDUv2fKVKlUL0EQEAgFiVGKQNEVhacPbsWWncuLE0b95cFi5cKAUKFJA9e/ZInjx5/L7m3XfflTfffNP9+LfffpOaNWtKhw4dvI7TwHbp0qXux5kyUUUBAACCy5I4s9l9TvgW1uhu9OjRUqJECZk2bZp7X5kyZVJ8Ta5cuczmMm/ePBMQ9+jRw+s4DVwLFy4chKsGAACAxHogO3/+fGnTpo3Jpq5cuVKKFSsmvXv3ll69egV8jo8//lhatmwppUqV8tqvmd2iRYtK1qxZpWHDhjJq1CgpWbKkz3NcuXLFbC4JCQnm/2vXrpkt3FzXEAnXgsAwZs7DmDkT4+Y8wRyzSPg6CEa7LNpv+RdnWeGbC6dBphowYIAJZjds2CDPPvusTJ48Wbp165bq648dO2aC0xkzZkjHjh3d+7VM4cKFC1KxYkU5fvy4DB8+3NTibt++XXLkyJHsPFpTq8ckpefNnj37DX+cAAAg+C5duiSPPPKInD9/XnLmzBnS961JML1jvOPAc5IjZ7yt5/4l4YpULTM+LB9XpAtrIJslSxapV6+erFmzxr2vX79+JqBdu3Ztqq/XLOs777xjAlo9lz/nzp0zGduxY8dKz549A8rIasnD6dOnI+ILRv/CXLJkibRq1UoyZ84c7stBABgz52HMnIlxc55gjpn+/s6fP39YA9ntQQpkqxHIRl5pQZEiRaRKlSpe+ypXrixz5sxJ9bUaf0+dOlW6dOmSYhCrcufOLRUqVJC9e/f6fD4+Pt5sSek3WCT9YIy060HqGDPnYcyciXFznmCMGV8DsSes7be0Y8GuXbu89u3evTtZvasvWlOrgamvDGtSWmawb98+EzgDAAAEC0vUxlAg279/f1m3bp288cYbJijVmtQpU6ZInz593McMHjxYunbt6nOSV4MGDaRatWrJnhs4cKAJdA8ePGjKFu6//37JmDGjdOrUKegfEwAAAGKgtKB+/foyd+5cE6yOGDHCtN4aP368dO7c2X2MTtY6dOiQ1+u0RkTLD7SnrC9HjhwxQeuZM2dMb9omTZqYgFnfBgAACGofWYs+sqES9lUC2rVrZzZ/pk+fnmyfFlPrzER/Zs6cadv1AQAABIr2WzG2RC0AAADgyIwsAABAtNCygkS7SwtsPl80ISMLAAAARyIjCwAAYOdkL5trWpns5R+BLAAgbF76/oFk+16v8WVYrgWA8xDIAgAiIoD1fI5gFk5F14LQokYWABAxQWxajgEAMrIAAAA2ISMbWgSyAAAANrH+2Ow+J3yjtAAAAACOREYWAADA1tICe/OElBb4R0YWAAAAjkRGFgAAwCaJQVii1u7zRRMysgCAkAqkRyx9ZAEEgkAWABByGqj6Clb97QectkSt3VtarVq1Stq3by9FixaVuLg4mTdvntfzus/X9vbbb/s957Bhw5IdX6lSJQknSgsAAGFD0AoEx8WLF6VmzZry2GOPyQMPJF9g5Pjx416PFy5cKD179pQHH3wwxfNWrVpVli5d6n6cKVN4Q0kCWQAAAAcsiJCQkOC1Pz4+3my+tG3b1mz+FC5c2OvxP//5T2nevLmULVs2xWvRwDXpa8OJ0gIAAAAHlBaUKFFCcuXK5d5GjRplyzWfPHlSvv76a5ORTc2ePXtMuYIGvJ07d5ZDhw5JOJGRBQAAcIDDhw9Lzpw53Y/j/WRj0+qTTz6RHDly+CxB8NSgQQOZPn26VKxY0ZQmDB8+XJo2bSrbt283rw8HAlkAAAAHtN/SINYzkLXL1KlTTXY1a9asKR7nWapQo0YNE9iWKlVKvvjii4CyucFAIAsAABCjvv32W9m1a5fMmjUrza/NnTu3VKhQQfbu3SvhQo0sAABAlLXfCtTHH38sdevWNR0O0urChQuyb98+KVKkiIQLgSwAAECU0SBz69atZlMHDhwwb3tOztIuCLNnz5bHH3/c5zlatGghEyZMcD8eOHCgrFy5Ug4ePChr1qyR+++/XzJmzCidOnWScKG0AAAAwCZWEGpk9ZxptXHjRtNOy2XAgAHm/27dupkJW2rmzJliWZbfQFSzradPn3Y/PnLkiDn2zJkzUqBAAWnSpImsW7fOvB0uBLIAAABRplmzZiZITckTTzxhNn808+pJA99IQyALAABgk2DUtAazRtbpCGQBAAAcsLIXkmOyFwAAAByJjCwAAIBNKC0ILTKyAAAAcCQysgAAAA5YohbJkZEFAACAI5GRBQAAsAldC0KLjCwAAAAciYwsAACATehaEFpkZAEAAOBIZGQBAABsQo1saBHIAgAA2MSy4sxm9znhG6UFAAAAcCQysgAAADahtCC0yMgCAADAkcjIAgAA2IQa2dAiIwsAAABHIiMLAABgEysINa16TvhGRhYAAACOREYWAADAJixRG1oEsgAAADZJtOLMZvc54RulBQAAAHAkMrIAAAA2obQgtMjIAgAAwJHIyAIAANiEJWpDi4wsAAAAHImMLAAAgE0s6/fN7nPCNzKyAAAAcKSwB7JHjx6VRx99VPLlyyfZsmWT6tWry8aNG/0e3717d4mLi0u2Va1a1eu4iRMnSunSpSVr1qzSoEEDWb9+fQg+GgAAEMsSJUNQNvgW1s/M2bNnpXHjxpI5c2ZZuHCh/PDDD/LOO+9Injx5/L7m3XfflePHj7u3w4cPS968eaVDhw7uY2bNmiUDBgyQoUOHyubNm6VmzZrSpk0b+fnnn0P0kQEAgFguLbB7QwTWyI4ePVpKlCgh06ZNc+8rU6ZMiq/JlSuX2VzmzZtnAuIePXq4940dO1Z69erl3jd58mT5+uuvZerUqfLiiy8G5WMBAABADAWy8+fPN5lSzaauXLlSihUrJr179zZBaKA+/vhjadmypZQqVco8vnr1qmzatEkGDx7sPiZDhgzmmLVr1/o8x5UrV8zmkpCQYP6/du2a2cLNdQ2RcC0IDGPmPIyZMzFuzhPMMYuErwMWRIihQHb//v0yadIkUwYwZMgQ2bBhg/Tr10+yZMki3bp1S/X1x44dMyUJM2bMcO87ffq0XL9+XQoVKuR1rD7euXOnz/OMGjVKhg8fnmz/4sWLJXv27BIplixZEu5LQBoxZs7DmDkT4+Y8wRizS5cu2X5ORLawBrKJiYlSr149eeONN8zj2rVry/bt200pQCCB7CeffCK5c+eW++6774auQ7O3Gkx7ZmS15KF169aSM2dOCTf9C1O/4Vu1amXqiRH5GDPnYcyciXFznmCOmeuOajixIEIMBbJFihSRKlWqeO2rXLmyzJkzJ9XXWpZlal67dOliMrgu+fPnl4wZM8rJkye9jtfHhQsX9nmu+Ph4syWl32CR9IMx0q4HqWPMnIcxcybGzXmCMWZ8DcSesHYt0I4Fu3bt8tq3e/dud71rSrSmdu/evdKzZ0+v/RrU1q1bV5YtW+aV+dXHDRs2tPHqAQAAvFlWXFA2RGAg279/f1m3bp0pLdCgVGtdp0yZIn369PG67d+1a1efk7y0P2y1atWSPadlAh9++KEpPfjxxx/l6aeflosXL3p1NgAAAICzhbW0oH79+jJ37lwTrI4YMcK03ho/frx07tzZfYz2ij106JDX686fP2/KD7SnrC8PP/ywnDp1Sl599VU5ceKE1KpVSxYtWpRsAhgAAICd6FoQQ4Gsateundn8mT59erJ92kc2tZmJffv2NRsAAECoJP6x2X1O+MaaZwAAAHCksGdkAQAAokUwJmcx2cs/MrIAAABwJDKyAAAANmZPE8nIhgwZWQAAADgSGVkAAACb0H4rtMjIAgAARJlVq1ZJ+/btpWjRohIXFyfz5s3zer579+5mv+d25513pnreiRMnSunSpSVr1qxmYar169dLOBHIAgAA2NxH1u4trS5evCg1a9Y0gac/GrjqwlOu7fPPP0/xnLNmzTKrpw4dOlQ2b95szt+mTRv5+eefJVwoLQAAALCJZWUwm93nTKu2bduaLSXx8fFSuHDhgM85duxY6dWrl/To0cM8njx5snz99dcydepUefHFFyUcyMgCAAA4QEJCgtd25cqVGzrfihUrpGDBglKxYkV5+umn5cyZM36PvXr1qmzatElatmzp3pchQwbzeO3atRIuBLIAAAA2sYK0qRIlSkiuXLnc26hRo9J9nVpW8Omnn8qyZctk9OjRsnLlSpPBvX79us/jT58+bZ4rVKiQ1359fOLECQkXSgsAAAAc4PDhw5IzZ06v0oD0+vOf/+x+u3r16lKjRg255ZZbTJa2RYsW4hRkZAEAAGxuv2X3pjSI9dzibyCQTaps2bKSP39+2bt3r8/n9bmMGTPKyZMnvfbr47TU2dqNQBYAACDGHTlyxNTIFilSxOfzWbJkkbp165pSBJfExETzuGHDhhIuBLIAAAA2sazgbGl14cIF2bp1q9nUgQMHzNuHDh0yzw0aNEjWrVsnBw8eNMHovffeK+XKlTPttFy0xGDChAnux9p668MPP5RPPvlEfvzxRzNBTNt8uboYhAM1sgAAAFFm48aN0rx5c68gVHXr1k0mTZok33//vQlIz507ZxZNaN26tYwcOdKrXGHfvn1mkpfLww8/LKdOnZJXX33VTPCqVauWLFq0KNkEsFAikAUAALBJohUniTb3kdVzplWzZs3ESiGV++9//zvVc2i2Nqm+ffuaLVIQyAIAANjEs12WneeEb9TIAgAAwJHIyAIAANjEs12WneeEb2RkAQAA4EhkZAEAAGyS3nZZqZ0TvpGRBQAAgCORkQUAALAJNbKhRUYWAAAAjkRGFgAAwCaJogsixNl+TvhGIAsAAGATJnuFFqUFAAAAcCQysgAAALaxf7KXnhO+kZEFAACAI5GRBQAAsImWs9pd0kqJrH9kZAEAAOBIZGQBAABsYllxZrP7nPCNjCwAAAAciYwsAACATRL/2Ow+J3wjkAUAALAJpQWhRWkBAAAAHImMLAAAgF00e2p3BpWMrF9kZAEAAOBIZGQBAABswmSv0CIjCwAAAEciIwsAAGATS+LMZvc54RsZWQAAADgSGVkAAAC7WH9sdp8TPpGRBQAAgCORkQUAALBJosSZze5zwjcCWQAAALuwIEJIUVoAAAAARyIjCwAAYBPL+n2z+5zwjYwsAAAAHImMLAAAgE3ovhVaZGQBAADgSGRkAQAAbMIStaFFRhYAAACOFPZA9ujRo/Loo49Kvnz5JFu2bFK9enXZuHFjiq+5cuWKvPTSS1KqVCmJj4+X0qVLy9SpU93PT58+XeLi4ry2rFmzhuCjAQAAsczVtcDuDRFYWnD27Flp3LixNG/eXBYuXCgFChSQPXv2SJ48eVJ8XceOHeXkyZPy8ccfS7ly5eT48eOSmJjodUzOnDll165d7scazAIAAAQTpQUxFMiOHj1aSpQoIdOmTXPvK1OmTIqvWbRokaxcuVL2798vefPmNfs0I5uUBq6FCxcOwlUDAABAYj2QnT9/vrRp00Y6dOhggtNixYpJ7969pVevXim+pl69evLWW2/JZ599JjfddJPcc889MnLkSFOa4HLhwgVTeqCZ2jp16sgbb7whVatW9VuqoJtLQkKC+f/atWtmCzfXNUTCtSAwjJnzMGbOxLg5TzDHLBK+DlgQIYYCWc2qTpo0SQYMGCBDhgyRDRs2SL9+/SRLlizSrVs3v69ZvXq1qXmdO3eunD592gS/Z86ccWd2K1asaGpma9SoIefPn5cxY8ZIo0aNZMeOHVK8ePFk5xw1apQMHz482f7FixdL9uzZJVIsWbIk3JeANGLMnIcxcybGzXmCMWaXLl2y/ZyIbHGWFb44XwNWza6uWbPGvU8DWQ1o165d6/M1rVu3lm+//VZOnDghuXLlMvu+/PJLeeihh+TixYteWVnPv9AqV64snTp1MpnbQDKyWvKgQbLW2oabXr9+w7dq1UoyZ84c7stBABgz52HMnIlxc55gjpn+/s6fP79JYoX697e+b41LBq/+XLLebG8S7PKFSzKqSaewfFyRLqwZ2SJFikiVKlW89mnAOWfOnBRfoyUIriDW9RqNx48cOSLly5dP9hr9Rqldu7bs3bvX5zm184Fuvl4XST8YI+16kDrGzHkiccwqvD4u2b7dL/UPy7VEqkgcN4R+zPgaiD1hbb+lHQs8Owuo3bt3m9rWlF5z7NgxUwPr+ZoMGTL4LBtQ169fl23btpkgGACcQgNYX0Gs6zkAkbtErd0bIjCQ7d+/v6xbt85MxNJs6YwZM2TKlCnSp08f9zGDBw+Wrl27uh8/8sgjpudsjx495IcffpBVq1bJoEGD5LHHHnOXFYwYMcLUt2o97ebNm02f2p9++kkef/zxsHycAJBWgQSqBLMAYl1YA9n69eubCVuff/65VKtWzdSvjh8/Xjp37uw+RnvEHjp0yP345ptvNrU1586dM/W1emz79u3lvffe8+pPq50PtOTgrrvuMnUrWoebtIwBAADAVlacWDZvek5EYI2sateundn80VW6kqpUqVKKsx3HjRtnNgBIzS2zXjf/x0sGGZW1itT8coxckUTZ9/BL4b40AA4UjFKA9Jxv1apV8vbbb8umTZtMUlATh/fdd597wt3LL78sCxYsMHevdd5Ry5Yt5c0335SiRYv6PeewYcOSdXnSTlE7d+6UmF2iFgDCFcC6glh/zwOAU128eFFq1qwpEydO9NmmTEsvX3nlFfO/dn/SOUvalz812pNfA2PXpi1RYzojCwCRSoNZMrMAnJiSbdu2rdl80Qxs0jvbEyZMkFtvvdWUc5YsWdLveTNlyhRRK6eSkQUQc8i2AnAinfPjuV3x6IF/o7RHbVxcnOTOnTvF4/bs2WPKD8qWLWvmKXnOYwoHAlkAAACb2D3Ryz3hS8Qs1qTZVNc2atQoW6758uXL8pe//MUsHJXSggsNGjQwc5cWLVpkVmY9cOCANG3aVH755RcJF0oLACAC6YIHqbXXYlEEILYcPnzYK9CM97GYU1rpxK+OHTuahaU0OE2JZ6lCjRo1TGCrvf+/+OIL6dmzp4QDgSwARChXoJo0oCWABWKTBrF2LlF77Y8gVnvtL1++PM3n1jKEChUq+F05NRQIZAHEHJ3A5aQ6WQJXAHa79kcQqzWv33zzjVlsKq10ldV9+/ZJly5dJFyokQUAP+hYACCtLIkLypaeIHPr1q1mU1rPqm/r5CwNYh966CHZuHGj/P3vf5fr16/LiRMnzHb16lX3OVq0aGG6GbgMHDhQVq5cKQcPHjQLTd1///2SMWNGU1sbLmRkAcSk1LKyBLEAnNx+a+PGjdK8eXP34wEDBpj/u3XrZhY2mD9/vnlcq1Ytr9dpdrZZs2bmbc22nj592v3ckSNHTNB65swZKVCggDRp0kTWrVtn3g4XAlkAMcszWNUMha5y858HBkrmzJnDel0AcKOaNWtmJnD5k9JzLpp59TRz5kyJNASyAAAA0ZWQjRnUyAIAAMCRyMgCAADYhZRsSJGRBQAAgCORkQUAALCJ55Kydp4TvpGRBQAAgCMRyAIAAMCRKC0AAACwC5O9QoqMLAAAAByJQBYAAACORCALAAAAR6JGFgAAwCaWBKH9ltB+yx8ysgAAAHAkMrIAAAB2oWtBSBHIAnCEsoPfMbeQMv7xM/03Edk/6vlwXxYAIIwIZAFEvHKD35F4EYnzqBPTH16VBr8jVwloAURcQtbuGln4Q40sgIjPxGYxIWzyXwwZJE6yiEjVwePCcm0A4Le0wO4NPhHIAohomolNiQazv0piiK4GABBJCGQBRHQ21lcmNinNygIAYg+BLAAAAByJQBYAAACORCALIGJpNwIrgFkO2rkAABB7aL8FIKJdEZGsKTyfKJZk429yAJGCBRFCip/+ACI+K3vF5GUtn0GsZmN3jOoflmsDAIQXGVkAEW/fqOel7HvvSNxxy/zQYmUvABHLivt9s/uc8IlAFoAj7O9H0AoA8EZpAQAAAByJjCwAAIBdmOwVUmRkAQAAEFTXr1+XVatWyblz52w9L4EsAAAAgipjxozSunVrOXv2rK3nJZAFAABA0FWrVk32798fnkBWI+i//vWvkpCQkOy58+fP+30OAAAg5mpk7d6iwGuvvSYDBw6Ur776So4fP27iRs8tqJO9JkyYIN9//70888wzyZ7LlSuXfPvtt+YiXnrppXRdCAAAAKLXXXfdZf6/5557JC7uf71xLcsyj7WONmiB7Jw5c+Sdd97x+/yTTz5pomwCWQAAELPoWuDXN998I3YLOJDdt2+flC9f3u/z+pweAwAAELs002j3SlzRsbLX7bffbvs5M6RlttmxY8f8Pq/PZcjA3DEAAAD4pqWojz76qDRq1EiOHj1q9n322WeyevVqSY+AI8/atWvLvHnz/D4/d+5ccwwAAEDMYrJXimWqbdq0kWzZssnmzZvlypUr7qYBb7zxhgQ1kO3bt6+pkdVJX57FuPq2diwYN26c9OnTJ10XAQAAgOj22muvyeTJk+XDDz+UzJkzu/c3btzYBLZBrZF98MEH5YUXXpB+/fqZCV1ly5Y1+7Uf2IULF2TQoEHy0EMPpesiAAAAEN127dolt912m8/uV+ld8SvgQFa9/vrrcu+998rf//532bt3r2mXoIW7jzzyiNx6663pugAAAABEv8KFC5v4sXTp0l77tT7WlSANaiCrNGAlaAUAAPCB9lt+9erVS5599lmZOnWq6RurjQLWrl1r2re+8sorEpJAdsOGDfL555/L7t27zeOKFStKp06dpF69eum6AAAAAES/F198URITE6VFixZy6dIlU2YQHx9vAllfC24FIk39srRGtkGDBvLRRx/JkSNHzDZlyhSz7y9/+Uu6LgAAACBqWHHB2aJAXFycmWf13//+V7Zv3y7r1q2TU6dOyciRI9N9zoAD2U8++cR0J3jvvffkzJkzsnXrVrPpxWjHAt3/6aefpvtCAAAAEL0ee+wx+eWXXyRLlixSpUoVU6p68803y8WLF81zQQ1kJ06caHp8aRsuz5YJ+rZ2MtCJYNqaK620Ga42xs2XL5/pK1a9enXZuHFjiq/RvmMa0ZcqVcqkpLVoWOstPM2ePVsqVaokWbNmNedcsGBBmq8NAAAgPet62b1Fg08++UR+/fXXZPt1X3qToQHXyO7YscN0LPDnvvvuS3Oh7tmzZ03vsObNm8vChQulQIECsmfPHsmTJ0+Kr+vYsaOcPHlSPv74YylXrpwcP37c1Fy4rFmzxtTtjho1Stq1ayczZsww16c9yqpVq5amawQAAAgYk72SSUhIMJ2udNOMrCYZPdcj0GRjwYIFJaiBrC5Re/XqVb/PX7t2zRyTFqNHj5YSJUrItGnT3PvKlCmT4msWLVokK1euNP1r8+bNa/YlbePw7rvvyp133ml62yqtvViyZInJGGsjXl8ZXtfqEq5PuOtj0i3cXNcQCdeCwDBmzsOYORPj5jzBHDO+DiJT7ty5TX2sbhUqVEj2vO4fPnx4cAPZOnXqmP6x/gpydZ1cPSYt5s+fb5Yq69ChgwlOixUrJr179zbtGVJ6jXZIeOutt8z7vOmmm+See+4x16WlCUpbOQwYMMDrdfp+/C2xq5lbX5/AxYsXS/bs2SVSaDAOZ2HMnIcxcybGzXmCMWY6Ex6/W7Vqlbz99tuyadMmc+d67ty55u60i2ZHhw4dalbZ0sUI9A75pEmTpHz58pJaqame98SJE1KzZk0zfyq1tqzffPONeX933HGHWabWlYhUWi+rpaJFixaVoAay2hpBPwGauXz++eelUKFCZr9+ILp07fjx480nKS00q6qfNA06hwwZYlp7ab2tflDdunXz+xptnKtpaX1/p0+fNsGvTkBzZXb1mlzX56KPdb8vgwcP9gp8NSOrmeLWrVtLzpw5Jdz0L0z9hm/VqpVXfTIiF2PmPIyZMzFuzhPMMXPdUYWYCVQaaOokqgceeCDZ85oQ1In6Wreqd8O1PFSTfj/88IPXrX9Ps2bNMvGS3t3WjlUa++lrdMWulEoDdPEsdeDAASlZsqTJwNol4EBWa021O4EGtBq46nJi6vz585IpUyYZM2aMOSYttK5Vs6s6iUzVrl3btGPQT5C/QFZfo58AzQ67rmHs2LFmedz333/fnZVNC50wpltS+g0WST8YI+16kDrGzHkYM2di3JwnGGMWCV8DwZiclZ7ztW3b1my+aHZUg9CXX37ZPf9JJ1tp0k/vXv/5z3/2+TqNt/SueY8ePcxjjde+/vprM+Fee8Sm5scff5TDhw9LkyZN3NldzQhrBwN9O7U5UjfcR1ab1e7bt88ErfpB6qZBrS43pis1pFWRIkXMxXuqXLmyHDp0KMXXaAmCK4h1vUYHRfvaupZA08lgnvSx7gcAAHAizTh7blc85vekhWZG9S51y5Yt3fs0rtIsq5Zn+qLzpLRMwfM1GTJkMI/9vSYpnbvkyppv27bNZHfvuusucz1JS0KDtrJX8eLFpX///sn2f//99ya7mtKEsKS0HkPT0Z50xTCtlUjpNdpa68KFC6b3mOs1+snUa1MNGzaUZcuWyXPPPed+nd7G0P0AnCnxRPIJAhkK/77CIADEQtcCLXv0NHToUBk2bFiaT+cqtUxLGaaWcmqHAV+v2blzZ0DvVwNWVwJTa2Xbt29v7sprVykNaNMjTRnZlGhGVD/AtNCAWFd10A9Cs7raJktXCuvTp49X/WrXrl3djx955BHTc1bT2lrHocXMGuFrDYirrECzw9rdQLPF+snVQdbetNoDF0B0BLGu/f6eA4Boo7fltaTTtQ0ePFicROdAuSbkLV261MxFUjr5K731zbYFsulRv359M2Hr888/N/1dtfOA1mx07tzZfYzOtPMsNdAsrGZXdYadZoD1WI3otWDZpVGjRu6gWAud//GPf5iaD3rIAs4TSKBKMAsg4jKydm8iZgK65xbvY35PIFyllmkpw8yfP79ps3ojpZtaG6slBBrvrV+/Xu6++273nXXXXfWglxbYTSeIpTRJbPr06cn26YpdqbXt0JZeugEAAOB/tEuBBp9ahlmrVi2zTzOi3333nTz99NPiL5tat25d8xpXGy+dgK+PA73jrf38tdOUJhi1a5XOeVK6KJb2/w9qIJtayldXagCAWLb8YBER0RKnjH/MM3alUi7KHaWPh/vyAMSQCxcumLJNz/rUrVu3mtv42gJL5xG99tprpm+sq/2W9nL17DXbokULuf/++92BqmZTtauU3hHX3rF6F13bfLm6GKRG3+9XX32VbL92xUqvTGldlSGlGlk7+4IBgPOCWJ2AGuejEU8OWX6wuNxR+vfOKgCiWIQsUbtx40Zp3ry5+7GrK4AGonq3+4UXXjBB6BNPPGHKNfW2v84v8uwhq52qdJKXy8MPPyynTp2SV1991UwK02yuvibpBDB/UupK5Qp0gxbI6qoMAAB/bkql22N2WX6wotxR2rtTCwAEQ7NmzUyS0R9NPo4YMcJs/hw8eDDZPs3OpnfyfOnSpVNMeqa1aUCaAlnXqgyBevPNN+Wpp54ymVwAiP5sbI4AjmQdeACxa8uWLclWedN9utDC66+/HlmTvbSlVseOHQlkAQRd+PvJZnFCoxgACCvtJJWU1ttqbe7bb7/tcyndsP1UTSmdDQDOCVIBIDLab0WrihUryoYNG5zZfgsAAg1mk/aLjZwgV1c0DKSfY2IIrgUAIlPSDlia9NT1AnThKu2ekB4EsgAcI3ICV2/aWmv5wXIB3OTKHKIrAhAucdbvm93njAa5fXTA0mBWl96dOXNmus5JIAsAtrjoo/2Wp1/ljtKHQ3xNAELP1XbP7nM63zdJOmBlyJBBChQoIOXKlZNMmdIXkgb8qmPHjpliXACAv6wsCyIAgF0dsGwNZKtWrSoTJ06URx55JKDjmzZtKtmy6Q90AIgNBKsAImVBhEgxf/78gI+95557ghfIan+vJ598UubOnSsffPCBWeIsJQsWLEjzxQAAACB63Oex5G1KtHY2PQsiBNx+q3fv3vL999/LmTNnpEqVKvKvf/0rze8MAAAAsSMxMTGgLT1BbJr7yJYpU0aWL18uL7/8smlaW6NGDalTp47XBgAAALho7KhJ0KTtt9T58+dN+eq3334r6ZHmKWI//fSTfPnll5InTx6599570z3LDAAAICo5uKY1GMaPHy+9evWSnDlzJnsuV65cpnRVl6nV+VVplaYo9MMPP5Tnn39eWrZsKTt27DAtEwAAAAB//vOf/8jo0aP9Pt+6dWsZM2aMpEfAgeydd94p69evlwkTJkjXrl3T9c4AAACiGQsiJHfy5EnJnNn/gjB6d//UqVMS1EBWi3B1slfx4sXT9Y4AAAAQe4oVKybbt283Cx/4ovFlkSLahzuIk72WLFlCEAsAAIA0ueuuu+SVV16Ry5cvJ3vu119/laFDh0q7du0kPZipBQAAYBcWREhGu11po4AKFSpI3759pWLFimb/zp07zWJbetf/pZdekvQgkAUAAEDQFCpUSNasWSNPP/20DB48WCzLci+C0KZNGxPM6jHpQSALAABgk7g/NrvP6XSlSpUyq76ePXtW9u7da4LZ8uXLm3auN4JAFgAAACGhgWv9+vVtO1+aVvYCAAAAIgWBLAAAAByJ0gIAAAC70LUgpAhkAQAA7EIgG1KUFgAAAMCRCGQBAADgSASyAAAAcCRqZAEAAOxCjWxIkZEFAACAI5GRBQAAsAlL1IYWGVkAAAA4EhlZAAAAu1AjG1IEsgAAAHYhkA0pSgsAAADgSASyAAAAcCQCWQAAADgSNbIAAAB2oUY2pMjIAgAAwJHIyAIAANiEBRFCi4wsAAAAHImMLAAAgF2okQ0pAlkAAAC7EMiGFKUFAAAAcCQysgAAADZiclbokJEFAACAI5GRBQAAsAs1siFFRhYAAACORCALAAAQRUqXLi1xcXHJtj59+vg8fvr06cmOzZo1qzgBpQUAAABRZMOGDXL9+nX34+3bt0urVq2kQ4cOfl+TM2dO2bVrl/uxBrNOQCALAADggBrZhIQEr93x8fFmS6pAgQJej99880255ZZb5Pbbb/f7LjRwLVy4sDhN2EsLjh49Ko8++qjky5dPsmXLJtWrV5eNGzf6PX7FihU+0+UnTpxwHzNs2LBkz1eqVClEHxEAAJBYD2Tt3kSkRIkSkitXLvc2atSoVC/n6tWr8re//U0ee+yxFLOsFy5ckFKlSpn3ce+998qOHTvECcKakT179qw0btxYmjdvLgsXLjR/QezZs0fy5MmT6ms1/a1pcJeCBQt6PV+1alVZunSp+3GmTCSfAQCAcx0+fNgr9on3kY1Nat68eXLu3Dnp3r2732MqVqwoU6dOlRo1asj58+dlzJgx0qhRIxPMFi9eXCJZWKO70aNHm8h/2rRp7n1lypQJ6LUauObOndvv8xq4OjFFDgAAnEtznnZXl7rOp0GsZyAbiI8//ljatm0rRYsW9XtMw4YNzeaiQWzlypXlgw8+kJEjR0okC2sgO3/+fGnTpo0pPl65cqUUK1ZMevfuLb169Ur1tbVq1ZIrV65ItWrVTCmBZnY9aWZXB01n3engaPq9ZMmSPs+l59HNxVWDcu3aNbOFm+saIuFaEBjGzHkYM2di3JwnmGPG14G3n376ydyd/vLLLyUtMmfOLLVr15a9e/dKpAtrILt//36ZNGmSDBgwQIYMGWJm2fXr10+yZMki3bp18/maIkWKyOTJk6VevXom+Pzoo4+kWbNm8t1330mdOnXMMQ0aNDCtJDRVfvz4cRk+fLg0bdrUzNrLkSNHsnNqkKvHJLV48WLJnj27RIolS5aE+xKQRoyZ8zBmzsS4OU8wxuzSpUu2n9PJpk2bZu5g33333Wl6nXY82LZtm9x1110S6eIsywrbehEasGpAumbNGvc+DWQ1oF27dm3A59FZeJpt/eyzz3w+r7UhWsA8duxY6dmzZ0AZWS15OH36dJpT+MGgf2HqN7y2ztC/khD5GDPnYcyciXFznmCOmf7+zp8/v6nzDPXvb33fOgFr8LR5kjX7Tbae+/KlizKqx31p+rgSExNNuWanTp1M1wJPXbt2NXfBXZPFRowYIX/605+kXLlyJmZ6++23TW3tpk2bpEqVKhLJwpqR1exq0k+Q1mTMmTMnTee59dZbZfXq1X6f11raChUq+E2R+2tfod9gkfSDMdKuB6ljzJyHMXMmxs15gjFmEfE1ECFL1C5dulQOHTpkuhUkpfszZMjgNfleyzq1A5ROuK9bt65JMkZ6EBv2QFbrWj2b76rdu3eb7GlabN261QTFKbWU2Ldvn3Tp0iXd1woAAOAUrVu3Fn833bWVqadx48aZzYnCGsj279/fzIx74403pGPHjrJ+/XqZMmWK2VwGDx5ses1++umn5vH48eNNqlzba12+fNnUyC5fvtzUs7oMHDhQ2rdvbwLiY8eOydChQyVjxowmvQ4AAIDoENZAtn79+jJ37lwTrGp9hgaoGqh27tzZfYxO1tIUuGdj3+eff94EtzoRS3ueafpce9G6HDlyxAStZ86cMb1pmzRpIuvWrUu20gUAAEA0lhbEirCvEtCuXTuz+aPdBzy98MILZkvJzJkzbbs+AAAARKawB7IAAADRIpgLIiC5/01ZAwAAAByEjCwAAIBdqJENKTKyAAAAcCQysgAAADaJs37f7D4nfCMjCwAAAEcikAUAAIAjEcgCAADAkaiRBQAAsAtdC0KKjCwAAAAciYwsYkKrDB187l+SODvk1wIAAOxBRhYxG8Sm9hwAADdUXmDXBr8IZBHVAglUCWYBAHAmSgsAAABswoIIoUVGFgAAAI5EIAsAAABHIpAFAACAI1EjCwAAYBfL+n2z+5zwiYwsologfWLpJQsAgDMRyCLqpRSoEsQCAOBclBYgJhCwAgBCgfZboUVGFgAAAI5ERhaAo93R6k2vx8uXvBi2awGAoCwrS0bWLzKyABwbwCYNYl37AQCxgUAWgOOkFqwSzAIIl7ggbfCNQBZAVCKYBYDoR40sgKgLULWc7LqINHlwjHvf6jkDg3xlAECNbKiRkQUQlb8/kt6K8wxqAQDRgUAWQFQIJGFBMAsA0YVAFoCjBNpeS0sLACBst4bs3uATgSyAqJOo/+RkCgAARDsCWQBRlZVNTCUbS3kBgFAsUWv3Bt8IZAFERTD7m4hc0yBWM7EpZGP9dS9o/vQEr/8BAJGPe28AoiKYTW+m9dbuY83/WTLFJdu3fvqAG75GAEDwkJEFEBXS0yfWFbCm93kAQHiRkQUQk8EuQSqAoGBBhJAiIwsgqgJVX5lZf/sDQcALAJGLjCyAqMNytAAQGwhkAQAAbBKX+Ptm9znhG6UFAAAAcCQCWQAxKdDWWrTgAoDIRSALAAAAR6JGFkDMcmVbfXUmIBMLID2CsaQsS9T6R0YWQMzToPWbSX3N2/o/QSwAJxs2bJjExcV5bZUqVUrxNbNnzzbHZM2aVapXry4LFiwQJyCQBQAAsH1FBLu3tKlataocP37cva1evdrvsWvWrJFOnTpJz549ZcuWLXLfffeZbfv27RLpCGQBAACiK46VTJkySeHChd1b/vz5/R777rvvyp133imDBg2SypUry8iRI6VOnToyYcIEiXQEsgAAAA6QkJDgtV25csXvsXv27JGiRYtK2bJlpXPnznLo0CG/x65du1Zatmzpta9NmzZmf6QjkAUAAHBARrZEiRKSK1cu9zZq1Cifl9CgQQOZPn26LFq0SCZNmiQHDhyQpk2byi+//OLz+BMnTkihQoW89ulj3R/p6FoAAADgAIcPH5acOXO6H8fHx/s8rm3btu63a9SoYQLbUqVKyRdffGHqYKMJgSwAAIBN4v7Y7D6n0iDWM5ANVO7cuaVChQqyd+9en89rDe3Jkye99ulj3R/pKC0AAACIYhcuXJB9+/ZJkSJFfD7fsGFDWbZsmde+JUuWmP2RjkAWAADALpYVnC0NBg4cKCtXrpSDBw+a1lr333+/ZMyY0bTYUl27dpXBgwe7j3/22WdNPe0777wjO3fuNH1oN27cKH37/t5fO5JRWoCwqfXMOPfbW//aP6zXAgBAtDhy5IgJWs+cOSMFChSQJk2ayLp168zbSjsYZMjwv1xmo0aNZMaMGfLyyy/LkCFDpHz58jJv3jypVq2aRDoCWYQ1gE26j4AWAIAbM3PmzBSfX7FiRbJ9HTp0MJvThL204OjRo/Loo49Kvnz5JFu2bGZZNE1np/TJT7rsmm5JW0RMnDhRSpcubZZa09l669evD8FHg/QEsWl5HgCAiBYhCyLEirBmZM+ePSuNGzeW5s2by8KFC03KWxv45smTJ9XX7tq1y2vmXsGCBd1vz5o1SwYMGCCTJ082Qez48eNNY199jedxCC2CVAAAEDUZ2dGjR5vmvtOmTZNbb71VypQpI61bt5Zbbrkl1ddqQOq59JpnrcfYsWOlV69e0qNHD6lSpYoJaLNnzy5Tp04N8kcEOxDwAgCcKs4KzoYIzMjOnz/fZEq1JkNn1xUrVkx69+5tgtDU1KpVyyzNpoXIOrtOM7vq6tWrsmnTJq/ZeBrk6tJr/pZa0/N4LvOmy76pa9eumS3cXNcQCddyI+IzBt5Zz+kfa7SMWSxhzJyJcXOeYI4ZXwexJ6yB7P79+83SaVoGoLPkNmzYIP369ZMsWbJIt27dfL5Ge6BphrVevXom+Pzoo4+kWbNm8t1330mdOnXk9OnTcv36dZ9LrWlLCV90ibfhw4cn27948WKTyY0U2tPNyYY0LxPwsQsWLJBo4PQxi0WMmTMxbs4TjDG7dOmShF0walrJyEZmIJuYmGgC0jfeeMM8rl27tmzfvt0Eqv4C2YoVK5rNs2WENvkdN26cfPbZZ+m6Ds3eajDtmZHVkgctc0jPChrB+AtTv+FbtWolmTNnFqdqMmhiQMetfruPOF20jFksYcyciXGzR7XP3vX73PYuzzpmzFx3VBE7whrIanZVa1g9Va5cWebMmZOm82h97erVq83b+fPnN01/07LUmq5V7Gu9Yv0Gi6QfjJF2PWl15Xpgf1I6+WOMtjGLRYyZMzFu6Vfq47dSfL7cp+Pkp54vOGLM+BqIPWGd7KV1rdpJwNPu3bulVKlSaTrP1q1b3cuuaVlC3bp1vZZa08yvPnbCUmvRLJAesfSRBQAAjghk+/fvb1aa0NKCvXv3mlUlpkyZIn369PG67a9LqbloK61//vOf5ngtQ3juuedk+fLlXq/RMoEPP/xQPvnkE/nxxx/l6aeflosXL5ouBgivlAJVglgAiKxsbFqPg4hOa7a9a0G4P6gIFtbSgvr168vcuXNNsDpixAjTfksD1c6dO7uPOX78uFlKzUW7Ejz//PNmIQWdiFWjRg1ZunSp6UXr8vDDD8upU6fk1VdfNQslaIcDXUM46QQwhAcBKwAgalnW75vd50RkLlHbrl07s/kzffp0r8cvvPCC2VLTt29fswEAACA6hX2JWgAAACA9CGQBAIhRgXYjCEbXAiAqSgsAAACiBgsihBQZWQAAYlhq2VaysYhkZGQBAIhxBKs2t98KwjnhGxlZAAAAOBIZWQAAALsk/rHZfU74RCALAABgK2ZnhQqlBQAAAHAkMrIAAAB2of1WSJGRBQAAgCORkQUAALANKdlQIiMLAAAARyIjCwAAYJM46/fN7nPCNwJZIAZ0W98z2b5Pbv04LNcCAIBdCGTD7M78TyTbt+j0lLBcC2IjgE36HAEtANiIEtmQokY2jAGsryDW9RwAAABSRiAbBoEEqgSzCGY2Nj3HAQACr5G1e4NvlBYAAADYhtqCUCIjG8HIygIAAPhHRhYAAMAuJGRDiowsEKXoRgAAiHZkZCMYbbgQCgS8AGAjMrIhRUY2DAhQESlBKkEsAMDJyMhGKIJd2MUVrHq22SKABYBgISUbSgSyIdSm/nD32//+I1BN2pmAABbBQvAKAIg2BLIhDmCT7StTTP69YWjoLwoAANiPhGxIEciGIYgFAADRKc6yzGb3OeEbk70iAMEuAABA2pGRDSICVAAAYgylBSFFRhYAAACOREYWAADANqRkQ4mMbBDRjQAAACB4yMgCAADYhYRsSJGRjYCsLJlbAACAtCOQDYGUAlWCWAAAojAja/cGnygtCBECVgAAYoAuXmD3AgZpPN+oUaPkyy+/lJ07d0q2bNmkUaNGMnr0aKlYsaLf10yfPl169OjhtS8+Pl4uX74skYyMLAAAQBRZuXKl9OnTR9atWydLliyRa9euSevWreXixYspvi5nzpxy/Phx9/bTTz9JpCMjCwAAEEWzvRYtWpQs21qwYEHZtGmT3HbbbX5fFxcXJ4ULFxYnISMLAADgAAkJCV7blStXAnrd+fPnzf958+ZN8bgLFy5IqVKlpESJEnLvvffKjh07JNIRyAIAADhgspcGmLly5XJvo0aNSvVyEhMT5bnnnpPGjRtLtWrV/B6n9bNTp06Vf/7zn/K3v/3NvE5ra48cOSKRjNICAAAABzh8+LCpY/WcjJUarZXdvn27rF69OsXjGjZsaDYXDWIrV64sH3zwgYwcOVIiFYFsjGm1or/P/UuajQv5tQAAEJWC1C5Lg1jPQDY1ffv2la+++kpWrVolxYsXl7TInDmz1K5dW/bu3SuRjNKCGOIviE3tOQAA4ByWZZkgdu7cubJ8+XIpU6ZMms9x/fp12bZtmxQpUkQiGYFsjAgkUCWYBQDgxsRZVlC2tOjTp4+pc50xY4bkyJFDTpw4YbZff/3VfUzXrl1l8ODB7scjRoyQxYsXy/79+2Xz5s3y6KOPmvZbjz/+uEQySgsAAACiyKRJk8z/zZo189o/bdo06d69u3n70KFDkiHD//KZZ8+elV69epmAN0+ePFK3bl1Zs2aNVKlSRSIZgSwAAECUlRakZsWKFV6Px40bZzanIZAFAACIoiVqYwk1sgAAAHAkMrIAAAB2ISMbUgSycKOXLAAgWGp9/Yr5P97KIEOkjjT592tyJS7R7Nt6d+Q23Edko7QgRqQWpBLEAgCCHcSm93lHCeIStUiOjGwM8QxWXT1jCWABAIBTEcjGKAJYAEAoBJpt1eOio8QgGClUUrIRW1pw9OhRs3pEvnz5JFu2bFK9enXZuHFjQK/9v//7P8mUKZPUqlXLa/+wYcMkLi7Oa6tUqVKQPgIAAIA/UFoQOxlZXUWicePG0rx5c1m4cKEUKFBA9uzZY1aUSM25c+fM8motWrSQkydPJnu+atWqsnTpUvdjDXgBAAAQPcIa3Y0ePVpKlChhlkxzKVOmTECvfeqpp+SRRx6RjBkzyrx585I9r4Fr4cKFbb1eAACAFFmJv292nxORF8jOnz9f2rRpIx06dJCVK1dKsWLFpHfv3mat35Ro4Lt//37529/+Jq+99prPYzSzW7RoUcmaNas0bNhQRo0aJSVLlvR57JUrV8zmkpCQYP6/du2a2cLNdQ2RcC0IDGPmPIyZMzFukW9D61dNqy2XLFYGr/9dVrd5+YbHka+D2BPWQFaD0UmTJsmAAQNkyJAhsmHDBunXr59kyZJFunXr5jdAffHFF+Xbb7/1Wy7QoEEDmT59ulSsWFGOHz8uw4cPl6ZNm8r27dslR44cyY7XIFePSWrx4sWSPXt2iRRLliwJ9yUgjRgz52HMnIlxi2zaNzapgYne81sWLFhww+/n0qVLEnbM9YqdQDYxMVHq1asnb7zxhnlcu3ZtE2xOnjzZZyB7/fp1U06gQWeFChX8nrdt27but2vUqGEC21KlSskXX3whPXv2THb84MGDTTDtmZHVkofWrVtLzpw5Jdz0L0z9Id2qVSvJnDlzuC8HAWDMnIcxcybGzTlcWVnNxGoQOybDVrn6x4IImo21g+uOKmJHWAPZIkWKSJUqVbz2Va5cWebMmePz+F9++cV0NNiyZYv07dvXHQxblmWys5pBveOOO5K9Lnfu3Cbw3bt3r8/zxsfHmy0p/aEYST8YI+16kDrGzHkYM2di3CLfd+2Gu//40Ozr8juH2D5mEfE1wBK1sRPIaseCXbt2ee3bvXu3yZ76otnRbdu2ee17//33Zfny5fKPf/zD70SxCxcuyL59+6RLly42Xj0AAABiNpDt37+/NGrUyJQWdOzYUdavXy9Tpkwxm+dtf+01++mnn0qGDBmkWrVqXucoWLCgmdDluX/gwIHSvn17ExAfO3ZMhg4darobdOrUKaQfHwAAAKI0kK1fv77MnTvXBKsjRowwGdXx48dL586d3cfoZK1Dhw6l6bxHjhwxQeuZM2dMb9omTZrIunXrzNsAAABBQ2lBSIV9lYB27dqZzR/tPpASXcVLN08zZ8607foAAAAQmcIeyAIAAEQN2m+FlHc3YgAAAMAhyMgCAADYhSVqQ4qMLAAAAByJQBYAAACORCALAAAAR6JGNoa1Lf+C1+OFe94K27UAABAV6CMbUgSyMShpAOu5n2AWAIAbQPutkKK0IMb4C2IDfR4AACBSEMgiGYJZAADSx7IssaxEmzdSsv4QyMYQAlQAABBNqJEFAACwCzWyIUVGFgAAAI5ERhYAAMAutN8KKTKyMSTQ1lq04AIAAE5ARhYAAMAuZGRDikA2xriyrb46GJCJBQDgRjHbK5QIZGMUQSsAAHA6AlkAAAA7ywASKS0IFSZ7AQAAwJEIZAEAAOBIBLIAAABwJGpkAQAA7EL7rZAiIwsAAABHIiMLAABgFzKyIUVGFgAAAI5ERhYAAMAmlmWZze5zwjcCWQAAALtQWhBSlBYAAADAkQhkAQAA7M7I2r2lw8SJE6V06dKSNWtWadCggaxfvz7F42fPni2VKlUyx1evXl0WLFggkY5AFgAAIMrMmjVLBgwYIEOHDpXNmzdLzZo1pU2bNvLzzz/7PH7NmjXSqVMn6dmzp2zZskXuu+8+s23fvl0iGYEsAABAlGVkx44dK7169ZIePXpIlSpVZPLkyZI9e3aZOnWqz+PfffddufPOO2XQoEFSuXJlGTlypNSpU0cmTJggkYzJXinMDkxISJBIcO3aNbl06ZK5nsyZM4f7chAAxsx5GDNnYtycJ5hj5vq9Hc5Z/pevXg7aOZPGJfHx8WZL6urVq7Jp0yYZPHiwe1+GDBmkZcuWsnbtWp/vQ/drBteTZnDnzZsnkYxA1odffvnF/F+iRIlwXwoAAEjH7/FcuXKF9H1myZJFChcuLMNn/C94tNPNN9+cLC4ZOnSoDBs2LNmxp0+fluvXr0uhQoW89uvjnTt3+jz/iRMnfB6v+yMZgawPRYsWlcOHD0uOHDkkLi4u3Jdj/gLTL169ppw5c4b7chAAxsx5GDNnYtycJ5hjpplYDWL193io6QSpAwcOmGxoMOjHljQmifeRjY01BLI+aPq9ePHiEmn0G54f1M7CmDkPY+ZMjJvzBGvMQp2JTRrM6hZu+fPnl4wZM8rJkye99utjzRr7ovvTcnykYLIXAABAFMmSJYvUrVtXli1b5t6XmJhoHjds2NDna3S/5/FqyZIlfo+PFGRkAQAAosyAAQOkW7duUq9ePbn11ltl/PjxcvHiRdPFQHXt2lWKFSsmo0aNMo+fffZZuf322+Wdd96Ru+++W2bOnCkbN26UKVOmSCQjkHUArYHRgm5qYZyDMXMexsyZGDfnYcxC4+GHH5ZTp07Jq6++aiZs1apVSxYtWuSe0HXo0CFTSunSqFEjmTFjhrz88ssyZMgQKV++vOlYUK1aNYlkcVY4e1QAAAAA6USNLAAAAByJQBYAAACORCALAAAARyKQBQAAgCMRyNrszTffNCtvPPfcc8me03l1bdu2Nc8nXbtYZw9qu4vs2bNLwYIFZdCgQfLbb795HbNixQqpU6eOmelZrlw5mT59erL3MXHiRCldurRpyNygQQNZv3691/OXL1+WPn36SL58+cxydw8++GCyBsixxt+Y6brTd9xxh9x0002mafdtt90mv/76q/v5//73v9K5c2fzXO7cuaVnz55y4cIFr3N8//330rRpUzMeupLNW2+9lez9z549WypVqmSOqV69uixYsCDZ143OOi1SpIhky5bNrJW9Z88eiXW+xk1n5nbp0sU08NZx0++XOXPmeL2OcQsdXTpTx8hz089ZWn4e8bMxssZNv3+eeeYZqVixovm6LlmypPTr10/Onz/vdQ7GDSGjXQtgj/Xr11ulS5e2atSoYT377LPJnh87dqzVtm1b7RJhzZ07173/t99+s6pVq2a1bNnS2rJli7VgwQIrf/781uDBg93H7N+/38qePbs1YMAA64cffrD++te/WhkzZrQWLVrkPmbmzJlWlixZrKlTp1o7duywevXqZeXOnds6efKk+5innnrKKlGihLVs2TJr48aN1p/+9CerUaNGVqzyN2Zr1qyxcubMaY0aNcravn27tXPnTmvWrFnW5cuX3cfceeedVs2aNa1169ZZ3377rVWuXDmrU6dO7ufPnz9vFSpUyOrcubM5x+eff25ly5bN+uCDD9zH/N///Z8Zx7feesuM68svv2xlzpzZ2rZtm/uYN99808qVK5c1b9486z//+Y91zz33WGXKlLF+/fVXK1b5G7dWrVpZ9evXt7777jtr37591siRI60MGTJYmzdvdh/DuIXO0KFDrapVq1rHjx93b6dOnQr45xE/GyNv3PRr/IEHHrDmz59v7d2713y+ypcvbz344IPu1zNuCCUCWZv88ssv5pt5yZIl1u23354skNVv5mLFipkfCEkDWf0m11+2J06ccO+bNGmSCaSuXLliHr/wwgvmB4unhx9+2GrTpo378a233mr16dPH/fj69etW0aJFTTCmzp07Z37Zzp49233Mjz/+aK5n7dq1VqxJacwaNGhgghN/9Aevft42bNjg3rdw4UIrLi7OOnr0qHn8/vvvW3ny5HGPofrLX/5iVaxY0f24Y8eO1t133+11bn3fTz75pHk7MTHRKly4sPX222+7n9dxjI+PNwFWLEpp3G666Sbr008/9To+b9681ocffmjeZtxCHxDpHw2+BPLziJ+NkTduvnzxxRcm4Lx27Zp5zLghlCgtsIne2tDbKHr7MKlLly7JI488Ym6R+FqzWG9h661JV5Ni1aZNG0lISJAdO3a4j0l6bj1G96urV6/Kpk2bvI7RRsf62HWMPn/t2jWvY/R2kd4ach0TS/yN2c8//yzfffeduR2mDaJ1XHS1k9WrV7uP0c+X3pbWFVNc9Dz6OdfXuo7RcgRdKtBzzHbt2iVnz54NaFwPHDhgbpd7HqPriOsttlgcs9S+13S8Zs2aZW5/6nKMujKN3nps1qyZeZ5xCz0tpyhatKiULVvWlHToLedAfx7xszHyxs0XLSvQUp1MmX5fY4lxQyixspcN9Jfl5s2bZcOGDT6f79+/v/kFe++99/p8Xn/heX7DK9djfS6lY/QHg9Zt6i/Y69ev+zxm586d7nPoL2f9RZ70GNf7iRUpjdn+/fvddWJjxowxq6F8+umn0qJFC9m+fbtZ7UQ/XxroetIf4nnz5vUaszJlyvgd1zx58vgdV89zeL7O1zGxJLXvtS+++MKsZqP1cjoeWp83d+5cU3+nGLfQ0sBd6x61nvL48eMyfPhwU3us30eB/DziZ2PkjVuOHDm8jj19+rSMHDlSnnjiCfc+xg2hRCB7gw4fPmzWJ16yZIkpRk9q/vz5snz5ctmyZUtYrg9pHzPN5Kknn3zSvSZ17dq1ZdmyZTJ16lT3utSIrHFTr7zyipw7d06WLl0q+fPnN5MqO3bsKN9++63JECG0dHKrS40aNUyAVKpUKfMHh04UgvPGTSdHumjQqXdHqlSpYv7wB8KB0oIbpLc29Fa0zrzUzI5uK1eulPfee8+8rb909+3bZ/5idD2vdGal63anlhsknWXpeuwqRfB3jN7O0V8I+ks7Y8aMPo/xPIfertFf9P6OiQWpjZkrA6A/nD1VrlzZfXtNP196Dk86I1dvaac2Zq7nUjrG83nP1/k6JlakNm76fTZhwgTzx4Zmz2vWrGnWc9cyAi3rUYxbeOnPwQoVKsjevXsD+nnEz8bIGzeXX375Re68806TodW7HpkzZ3Y/x7ghlAhkb5D+wty2bZts3brVvekvTq0p0rdfeukl08rH83k1btw4mTZtmnm7YcOG5hyev2A1ANZvaFcwpcdoRtCTHqP7ld5eqVu3rtcxmlnUx65j9Hn9YeN5jNb9aXDmOiYWpDZmWhOmtWH6ufG0e/duk5VQ+vnSH54aXLlo5l0/55q9cB2zatUqU8PlOWZ6u05vTwcyrnqLW38gex6jWRCt54ylMQtk3LQW3VVH50l/Gbqy7IxbeGmbM/2DQ1uSBfLziJ+NkTdurq/l1q1bm8+t3nVMeoeEcUNIhXRqWYzw1bXAk7/2W61bt7a2bt1q2o8UKFDAZ6uSQYMGmVmZEydO9NmqRGdFT58+3czOfuKJJ0yrEs+Zo9qqpGTJktby5ctNq5KGDRuaLdYlHbNx48aZGbY6G3bPnj2mg0HWrFlNuxnPNk61a9c2rZ5Wr15tZtJ7tnHSGbXaxqlLly6mjZOOj45h0jZOmTJlssaMGWPGVWcL+2rjpOP4z3/+0/r++++te++9N+baOAUyblevXjWttJo2bWrGRMdKP6/akeDrr792v4ZxC53nn3/eWrFihXXgwAHzOdN2TNqG6eeffw7o5xE/GyNv3LQ9nXboqF69uvke82zRpeOlGDeEEoFsBASy6uDBg6bHrPar1B8Y+oPE1crE5ZtvvrFq1apl2pyULVvWmjZtWrJzay8+/abWY7R1ifbK9KS/RHv37m3aC+kPkfvvv9/8AIp1vsZMW7wUL17cfJ70B6P2HPV05swZEwDdfPPNJujt0aOHaQ3lSfuHNmnSxPww1vZrGtz4al1ToUIFM2bajsYz6HK1cnrllVdMcKXnadGihbVr1y5bP/5oGbfdu3ebHpcFCxY046Z9ZpO242LcQkfbKRUpUsR8jvTzqI89/xgM5OcRPxsja9z0c62/w3xtGvi6MG4IlTj9J7Q5YAAAAODGUSMLAAAARyKQBQAAgCMRyAIAAMCRCGQBAADgSASyAAAAcCQCWQAAADgSgSwAAAAciUAWAAAAjkQgCwAAAEcikAUQsa5fvy6NGjWSBx54wGv/+fPnpUSJEvLSSy+l+PqDBw9KXFycbN261e8xa9askbvuukvy5MkjWbNmlerVq8vYsWPN+07qm2++Mcfmy5dPsmfPLlWqVJHnn39ejh49egMfJQAgvQhkAUSsjBkzyvTp02XRokXy97//3b3/mWeekbx588rQoUNv6Pxz586V22+/XYoXL26C1J07d8qzzz4rr732mvz5z38WzxW8P/jgA2nZsqUULlxY5syZIz/88INMnjzZBNXvvPPODV0HACB94izPn9QAEIHee+89GTZsmOzYsUPWr18vHTp0kA0bNkjNmjVTzciWKVNGtmzZIrVq1fJ67uLFi1KqVCkTyGpg6ulf//qX3HPPPTJz5kx5+OGH5ciRI3LLLbdI7969Zdy4ccnez7lz5yR37tw2fbQAgECRkQUQ8TQDq0Frly5d5IknnpBXX3011SA2NYsXL5YzZ87IwIEDkz3Xvn17qVChgnz++efm8ezZs+Xq1avywgsv+DwXQSwAhEemML1fAAiY1rlOmjRJKleubGpYX3zxxRs+5+7du83/ek5fKlWq5D5mz549kjNnTilSpMgNv18AgH3IyAJwhKlTp5oJVgcOHDC3+u0SSHWVHqPBNAAgshDIAoh42llAa1O/+uorufXWW6Vnz54BBaAp0dIB9eOPP/p8Xve7jtH/dVLX8ePHb+h9AgDsRSALIKJdunRJunfvLk8//bQ0b95cPv74YzPhSzsG3IjWrVubzge+Og7Mnz/flBN06tTJPH7ooYckS5Ys8tZbb/k8l072AgCEHjWyACLa4MGDTfb1zTffNI9Lly4tY8aMMZO02rZtax6nZteuXcn2Va1a1bTU0jZbOoGsb9++pg522bJlMmjQIBO8duzY0RyrPWs1I6zHJCQkSNeuXc371RKHTz/9VG6++WZacAFAGNB+C0DEWrlypbRo0UJWrFghTZo08XquTZs28ttvv8nSpUv91q+62m/5cvjwYdM/9ttvv5XXX39d1q5dK5cvX5by5ctLjx495LnnnjN9bD3p+9IgWjPCv/76qwlm27VrJwMGDGAiGACEAYEsAAAAHIkaWQAAADgSgSwAx3rqqadMfaqvTZ8DAEQ3SgsAONbPP/9sJl/5ohO3ChYsGPJrAgCEDoEsAAAAHInSAgAAADgSgSwAAAAciUAWAAAAjkQgCwAAAEcikAUAAIAjEcgCAADAkQhkAQAAIE70/ztcZ+iZoSYJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get indices of non-null X_LOC and Y_LOC values\n",
    "valid_indices = train_df[['X_LOC', 'Y_LOC']].dropna().index\n",
    "\n",
    "# Get X array for clustering\n",
    "X = train_df.loc[valid_indices, ['X_LOC', 'Y_LOC']].astype(int).values\n",
    "\n",
    "# Gunakan eps berdasarkan k-dist plot\n",
    "dbscan = DBSCAN(eps=1, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "# Tambahkan hasil klaster ke train_df\n",
    "train_df.loc[valid_indices, 'Cluster_DBSCAN'] = clusters\n",
    "\n",
    "# Plot hasil clustering\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', marker='o', alpha=0.6)\n",
    "plt.xlabel('X_LOC')\n",
    "plt.ylabel('Y_LOC')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5 SPLIT DATASET BY CLUSTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = train_df['Cluster_DBSCAN'].dropna().unique()  # Ambil semua cluster unik\n",
    "\n",
    "# Buat dictionary untuk menyimpan DataFrame tiap cluster\n",
    "cluster_dfs = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_dfs[cluster] = train_df[train_df['Cluster_DBSCAN'] == cluster].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat folder utama untuk menyimpan dataset per cluster\n",
    "output_folder = 'dataset_cluster'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterasi setiap cluster dan simpan sebagai file CSV\n",
    "for cluster, df in cluster_dfs.items():\n",
    "    # Tentukan nama file dengan format \"(nama_cluster)_dataset.csv\"\n",
    "    filename = f\"{cluster}_dataset.csv\"\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "    # Simpan DataFrame ke CSV\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.6 FILL NAN BY ORDERING DEPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, df in cluster_dfs.items():\n",
    "    # Urutkan data berdasarkan DEPT\n",
    "    df = df.sort_values(by='DEPT')\n",
    "    \n",
    "    # Reset index untuk memudahkan akses\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Ambil kolom numerik (kecuali Lithology_code)\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    \n",
    "    # Buat mask untuk melacak NaN awal\n",
    "    nan_mask = df[numeric_cols].isna()\n",
    "    \n",
    "    # Forward Fill (ffill)\n",
    "    for col in numeric_cols:\n",
    "        condition_ffill = (df['Lithology_code'].shift(-1) == df['Lithology_code'])\n",
    "        df[col] = df[col].where(~nan_mask[col] | ~condition_ffill, df[col].shift(-1))\n",
    "    \n",
    "    # Backward Fill (bfill)\n",
    "    for col in numeric_cols:\n",
    "        condition_bfill = (df['Lithology_code'].shift(1) == df['Lithology_code'])\n",
    "        df[col] = df[col].where(~nan_mask[col] | ~condition_bfill, df[col].shift(1))\n",
    "    \n",
    "    # Logging: Hitung jumlah NaN yang diisi dengan setiap metode\n",
    "    ffill_count = nan_mask.sum() - df[numeric_cols].isna().sum()\n",
    "    bfill_count = nan_mask.sum() - df[numeric_cols].isna().sum() - ffill_count\n",
    "    \n",
    "    # Simpan kembali ke cluster_dfs\n",
    "    cluster_dfs[cluster] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.7 SPLIT BY CLASS ON EACH CLUSTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary bertingkat untuk menyimpan data berdasarkan cluster dan lithology\n",
    "cluster_lithology_dfs = {}\n",
    "\n",
    "for cluster in cluster_dfs.keys():\n",
    "    # Split lagi berdasarkan Lithology_code\n",
    "    lithology_codes = cluster_dfs[cluster]['Lithology_code'].dropna().unique()\n",
    "    \n",
    "    # Dictionary dalam dictionary untuk Lithology_code per cluster\n",
    "    cluster_lithology_dfs[cluster] = {}\n",
    "\n",
    "    for litho in lithology_codes:\n",
    "        cluster_lithology_dfs[cluster][litho] = cluster_dfs[cluster][cluster_dfs[cluster]['Lithology_code'] == litho].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder utama untuk menyimpan dataset per cluster dan lithology\n",
    "main_folder = 'dataset_cluster_class'\n",
    "os.makedirs(main_folder, exist_ok=True)\n",
    "\n",
    "# Iterasi setiap cluster dan lithology\n",
    "for cluster, lithology_dict in cluster_lithology_dfs.items():\n",
    "    # Buat subfolder untuk cluster (misalnya \"1\", \"2\", dst.)\n",
    "    cluster_folder = os.path.join(main_folder, str(cluster))\n",
    "    os.makedirs(cluster_folder, exist_ok=True)\n",
    "    \n",
    "    for lithology_code, df in lithology_dict.items():\n",
    "        # Tentukan nama file sesuai lithology_code\n",
    "        filename = f\"{lithology_code}.csv\"\n",
    "        filepath = os.path.join(cluster_folder, filename)\n",
    "\n",
    "        # Simpan DataFrame ke CSV\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.8 INTERPOLATE OUTLIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder utama tempat dataset tersimpan\n",
    "main_folder = 'dataset_cluster_class'\n",
    "\n",
    "# Iterasi setiap subfolder (cluster)\n",
    "for cluster_folder in os.listdir(main_folder):\n",
    "    cluster_path = os.path.join(main_folder, cluster_folder)\n",
    "\n",
    "    # Periksa apakah path adalah folder\n",
    "    if os.path.isdir(cluster_path):\n",
    "        # print(f\"Opening folder: {cluster_folder}\")\n",
    "\n",
    "        # Iterasi setiap file dalam folder cluster\n",
    "        for filename in os.listdir(cluster_path):\n",
    "            file_path = os.path.join(cluster_path, filename)\n",
    "\n",
    "            # Periksa apakah file adalah CSV\n",
    "            if filename.endswith('.csv'):\n",
    "                # print(f\"Reading file: {filename}\")\n",
    "\n",
    "                # Buka file CSV sebagai DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Get list of outlier columns\n",
    "                outlier_cols = [col for col in df.columns if \"outlier\" in col]\n",
    "                \n",
    "                if outlier_cols:  # If there are outlier columns\n",
    "                    # Get corresponding feature columns (remove '_is_outlier' suffix)\n",
    "                    feature_cols = [col.replace('_is_outlier', '') for col in outlier_cols]\n",
    "                    \n",
    "                    for feature, outlier_col in zip(feature_cols, outlier_cols):\n",
    "                        if outlier_col in df.columns:\n",
    "                            # Simpan mask NaN asli sebelum mengganti outlier dengan NaN\n",
    "                            mask_nan_original = df[feature].isna()\n",
    "\n",
    "                            # Mask untuk outlier\n",
    "                            mask_outliers = df[outlier_col] == True  \n",
    "\n",
    "                            # Ganti hanya outlier dengan NaN\n",
    "                            df.loc[mask_outliers, feature] = None  \n",
    "\n",
    "                            # Lakukan interpolasi\n",
    "                            df[feature] = df[feature].interpolate(method='linear')\n",
    "\n",
    "                            # Kembalikan NaN asli ke posisi semula\n",
    "                            df.loc[mask_nan_original, feature] = None  \n",
    "                    \n",
    "                    # Save the updated DataFrame\n",
    "                    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. FILL NAN VALUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 FILL NAN VALUE WITH KNN IN EACH CLASS IN EACH CLUSTER** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Definisi hubungan fitur untuk imputasi\n",
    "imputation_dict = {\n",
    "    'DTC': ['RHOB', 'NPHI', 'DEPT'],\n",
    "    'RHOB': ['NPHI', 'DTC', 'DEPT'],\n",
    "    'GR': ['DEPT'],\n",
    "    'CALI': ['DEPT', 'BS'],\n",
    "    'DRHO' : ['NPHI', 'DEPT'],\n",
    "    'ROP' : ['NPHI','DEPT','CALI'],\n",
    "    'NPHI': ['RHOB', 'DTC', 'DEPT','CALI'],\n",
    "}\n",
    "\n",
    "def impute_feature(df, target_feature, predictor_features):\n",
    "    # Periksa apakah kolom target 100% NaN\n",
    "    if df[target_feature].isna().sum() == len(df):\n",
    "        print(f\"Skipping {target_feature}: 100% NaN.\")\n",
    "        return df  # Kembalikan DataFrame tanpa perubahan\n",
    "    \n",
    "    # Periksa apakah semua kolom prediktor 100% NaN\n",
    "    valid_predictors = [col for col in predictor_features if df[col].isna().sum() < len(df)]\n",
    "    \n",
    "    if len(valid_predictors) == 0:\n",
    "        print(f\"Skipping {target_feature}: All predictor columns are 100% NaN.\")\n",
    "        return df  # Kembalikan DataFrame tanpa perubahan\n",
    "    \n",
    "    # Jika target adalah CALI dan BS tersedia, gunakan regresi linear\n",
    "    if (target_feature == 'CALI' and 'BS' in valid_predictors) or (target_feature == 'NPHI' and ['RHOB', 'DTC', 'DEPT','CALI'] in valid_predictors):\n",
    "        print(\"Using Linear Regression for CALI imputations with BS...\")\n",
    "        \n",
    "        # Pisahkan data menjadi yang memiliki nilai dan yang tidak\n",
    "        known_data = df.dropna(subset=['CALI', 'BS'])\n",
    "        unknown_data = df[df['CALI'].isna() & df['BS'].notna()]\n",
    "        \n",
    "        if not known_data.empty and not unknown_data.empty:\n",
    "            # Latih model regresi\n",
    "            model = LinearRegression()\n",
    "            model.fit(known_data[['BS']], known_data['CALI'])\n",
    "            \n",
    "            # Prediksi nilai CALI yang hilang\n",
    "            df.loc[df['CALI'].isna() & df['BS'].notna(), 'CALI'] = model.predict(unknown_data[['BS']])\n",
    "    \n",
    "    # Cek apakah masih ada NaN yang perlu diimputasi di target\n",
    "    if df[target_feature].isna().sum() > 0:\n",
    "        print(f\"Imputing {target_feature} using {valid_predictors} with KNN...\")\n",
    "\n",
    "        # Ambil subset data dengan fitur prediktor valid dan target\n",
    "        imputation_data = df[valid_predictors + [target_feature]].copy()\n",
    "\n",
    "        # Standarisasi data\n",
    "        scaler = StandardScaler()\n",
    "        imputation_data_scaled = scaler.fit_transform(imputation_data)\n",
    "\n",
    "        # Terapkan KNN Imputer\n",
    "        imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "        imputed_data_scaled = imputer.fit_transform(imputation_data_scaled)\n",
    "\n",
    "        # Kembalikan ke skala asli\n",
    "        imputed_data = scaler.inverse_transform(imputed_data_scaled)\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=valid_predictors + [target_feature], index=df.index)\n",
    "\n",
    "        # Update DataFrame asli\n",
    "        df[target_feature] = imputed_df[target_feature]\n",
    "    else:\n",
    "        print(f\"No NaN values in {target_feature}. Skipping imputation.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 0.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Processing folder: 1.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 10.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Processing folder: 11.0\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Processing folder: 12.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Processing folder: 13.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 88000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 88000.0.csv\n",
      "Processing folder: 14.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Processing folder: 15.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 16.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 17.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "Skipping ROP: 100% NaN.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 18.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "Imputing DTC using ['DEPT'] with KNN...\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 19.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Skipping CALI: 100% NaN.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 2.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 88000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 88000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 20.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Processing folder: 21.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['DEPT'] with KNN...\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "Imputing CALI using ['DEPT', 'BS'] with KNN...\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['DEPT'] with KNN...\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Processing folder: 3.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "Skipping DTC: 100% NaN.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "Skipping DTC: 100% NaN.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 4.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 5.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 6.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 7.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 93000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 93000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 8.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 9.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n"
     ]
    }
   ],
   "source": [
    "# Path ke folder utama yang berisi subfolder cluster\n",
    "main_folder = 'dataset_cluster_class'  # Ganti dengan path folder utama Anda\n",
    "\n",
    "# Iterasi setiap subfolder (cluster)\n",
    "for cluster_folder in os.listdir(main_folder):\n",
    "    cluster_path = os.path.join(main_folder, cluster_folder)\n",
    "\n",
    "    # Periksa apakah path adalah folder\n",
    "    if os.path.isdir(cluster_path):\n",
    "        print(f\"Processing folder: {cluster_folder}\")\n",
    "\n",
    "        # Iterasi setiap file dalam folder cluster\n",
    "        for filename in os.listdir(cluster_path):\n",
    "            file_path = os.path.join(cluster_path, filename)\n",
    "\n",
    "            # Periksa apakah file adalah CSV\n",
    "            if filename.endswith('.csv'):\n",
    "                print(f\"Reading file: {filename}\")\n",
    "\n",
    "                # Buka file CSV sebagai DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Lakukan imputasi untuk setiap fitur target\n",
    "                for target_feature, predictor_features in imputation_dict.items():\n",
    "                    # Pastikan semua fitur prediktor ada di DataFrame\n",
    "                    if all(feature in df.columns for feature in predictor_features):\n",
    "                        df = impute_feature(df, target_feature, predictor_features)\n",
    "                    else:\n",
    "                        print(f\"Skipping imputation for {target_feature}: missing predictors in {filename}\")\n",
    "\n",
    "                # Simpan kembali file CSV yang telah diimputasi\n",
    "                df.to_csv(file_path, index=False)\n",
    "                print(f\"Saved imputed file: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 JOIN EACH CLUSTER DATASET TO EACH CLASS DATASET** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged dataset: dataset_cluster_class\\merged_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "main_folder = \"dataset_cluster_class\"  # Ganti dengan nama folder utama jika berbeda\n",
    "merged_df_list = []  # List untuk menyimpan DataFrame sebelum digabung\n",
    "\n",
    "# Iterasi setiap subfolder (cluster)\n",
    "for cluster_folder in os.listdir(main_folder):\n",
    "    cluster_path = os.path.join(main_folder, cluster_folder)\n",
    "\n",
    "    # Periksa apakah path adalah folder\n",
    "    if os.path.isdir(cluster_path):\n",
    "        # print(f\"Processing folder: {cluster_folder}\")\n",
    "\n",
    "        # Iterasi setiap file dalam folder cluster\n",
    "        for filename in os.listdir(cluster_path):\n",
    "            file_path = os.path.join(cluster_path, filename)\n",
    "\n",
    "            # Periksa apakah file adalah CSV\n",
    "            if filename.endswith('.csv'):\n",
    "                # print(f\"Reading file: {filename}\")\n",
    "\n",
    "                # Buka file CSV sebagai DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Tambahkan ke daftar DataFrame\n",
    "                merged_df_list.append(df)\n",
    "\n",
    "# Gabungkan semua DataFrame dalam daftar\n",
    "if merged_df_list:\n",
    "    merged_df = pd.concat(merged_df_list, ignore_index=True)\n",
    "\n",
    "    # Simpan sebagai satu file CSV gabungan\n",
    "    merged_csv_path = os.path.join(main_folder, \"merged_dataset.csv\")\n",
    "    merged_df.to_csv(merged_csv_path, index=False)\n",
    "    print(f\"Saved merged dataset: {merged_csv_path}\")\n",
    "else:\n",
    "    print(\"No CSV files found to merge.\")\n",
    "\n",
    "merged_df = merged_df[[i for i in merged_df.columns if \"outlier\" not in i]]\n",
    "\n",
    "lithology_code = merged_df['Lithology_code'].dropna().unique()  # Ambil semua cluster unik\n",
    "\n",
    "# Buat dictionary untuk menyimpan DataFrame tiap cluster\n",
    "lithology_df = {}\n",
    "\n",
    "for code in lithology_code:\n",
    "    lithology_df[code] = merged_df[merged_df['Lithology_code'] == code].copy()\n",
    "    \n",
    "# Buat folder utama untuk menyimpan dataset per cluster\n",
    "output_folder = 'dataset_lithology'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterasi setiap cluster dan simpan sebagai file CSV\n",
    "for code, df in lithology_df.items():\n",
    "    # Tentukan nama file dengan format \"(nama_code)_dataset.csv\"\n",
    "    filename = f\"{code}_dataset.csv\"\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "    # Simpan DataFrame ke CSV\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 FILL NAN VALUE WITH KNN IN EACH CLASS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: 30000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0_dataset.csv\n",
      "Reading file: 65000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0_dataset.csv\n",
      "Reading file: 65030.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0_dataset.csv\n",
      "Reading file: 70000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0_dataset.csv\n",
      "Reading file: 70032.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70032.0_dataset.csv\n",
      "Reading file: 74000.0_dataset.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 74000.0_dataset.csv\n",
      "Reading file: 80000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0_dataset.csv\n",
      "Reading file: 86000.0_dataset.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0_dataset.csv\n",
      "Reading file: 88000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 88000.0_dataset.csv\n",
      "Reading file: 90000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 90000.0_dataset.csv\n",
      "Reading file: 93000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 93000.0_dataset.csv\n",
      "Reading file: 99000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 99000.0_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "main_folder = 'dataset_lithology'\n",
    "\n",
    "# Iterate through files in the main folder\n",
    "for filename in os.listdir(main_folder):\n",
    "    file_path = os.path.join(main_folder, filename)\n",
    "    \n",
    "    # Check if file is CSV\n",
    "    if filename.endswith('.csv'):\n",
    "        print(f\"Reading file: {filename}\")\n",
    "\n",
    "        # Read CSV as DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Perform imputation for each target feature\n",
    "        for target_feature, predictor_features in imputation_dict.items():\n",
    "            # Make sure all predictor features exist in DataFrame\n",
    "            if all(feature in df.columns for feature in predictor_features):\n",
    "                df = impute_feature(df, target_feature, predictor_features)\n",
    "            else:\n",
    "                print(f\"Skipping imputation for {target_feature}: missing predictors in {filename}\")\n",
    "\n",
    "        # Save back the imputed CSV file\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Saved imputed file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged dataset: ./dataset/cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "main_folder = \"dataset_lithology\"  # Main folder containing lithology CSV files\n",
    "merged_df_list = []  # List to store DataFrames before merging\n",
    "\n",
    "# Iterate through files in the main folder\n",
    "for filename in os.listdir(main_folder):\n",
    "    file_path = os.path.join(main_folder, filename)\n",
    "\n",
    "    # Check if file is CSV\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read CSV as DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        merged_df_list.append(df)\n",
    "\n",
    "# Merge all DataFrames in the list\n",
    "if merged_df_list:\n",
    "    merged_df = pd.concat(merged_df_list, ignore_index=True)\n",
    "\n",
    "    # Save as one merged CSV file\n",
    "    merged_csv_path = \"./dataset/cleaned_dataset.csv\"\n",
    "    merged_df.to_csv(merged_csv_path, index=False)\n",
    "    merged_df.to_csv(\"./dataset/cleaned_dataset.csv\", index=False)\n",
    "    print(f\"Saved merged dataset: {merged_csv_path}\")\n",
    "else:\n",
    "    print(\"No CSV files found to merge.\")\n",
    "merged_df.to_csv(merged_csv_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.4 CLEANING ALL NAN VALUE IN ALL DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n"
     ]
    }
   ],
   "source": [
    "# Lakukan imputasi untuk setiap fitur target\n",
    "for target_feature, predictor_features in imputation_dict.items():\n",
    "    # Pastikan semua fitur prediktor ada di DataFrame\n",
    "    if all(feature in df.columns for feature in predictor_features):\n",
    "        cleaned_dataset = impute_feature(merged_df, target_feature, predictor_features)\n",
    "    else:\n",
    "        print(f\"Skipping imputation for {target_feature}: missing predictors in {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. MODELLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "X_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DEPT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DTC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CALI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lithology_code",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5d435809-ea48-4511-957b-d951e82d373f",
       "rows": [
        [
         "0",
         "455221.34375",
         "6533321.5",
         "2712.4600015",
         "0.2183177024",
         "71.954612732",
         "2.2572171688",
         "58.311519623",
         "14.6664505",
         "30000.0"
        ],
        [
         "1",
         "455221.34375",
         "6533321.5",
         "2726.5960015",
         "0.0854552164999999",
         "59.16765213",
         "2.5486149788",
         "88.030212402",
         "12.509160042",
         "30000.0"
        ],
        [
         "2",
         "455221.34375",
         "6533321.5",
         "2726.7480015",
         "0.1140174568",
         "60.975471497",
         "2.5182976723",
         "86.302810669",
         "12.547708511",
         "30000.0"
        ],
        [
         "3",
         "455221.34375",
         "6533321.5",
         "2726.9000015",
         "0.1478745788",
         "62.972198486",
         "2.4923596382",
         "79.648368835",
         "12.620093346",
         "30000.0"
        ],
        [
         "4",
         "455221.34375",
         "6533321.5",
         "2727.0520015",
         "0.1808652878",
         "64.157539368",
         "2.4702837467",
         "67.485961914",
         "12.537360191",
         "30000.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>DTC</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>CALI</th>\n",
       "      <th>Lithology_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2712.460002</td>\n",
       "      <td>0.218318</td>\n",
       "      <td>71.954613</td>\n",
       "      <td>2.257217</td>\n",
       "      <td>58.311520</td>\n",
       "      <td>14.666450</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2726.596002</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>59.167652</td>\n",
       "      <td>2.548615</td>\n",
       "      <td>88.030212</td>\n",
       "      <td>12.509160</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2726.748002</td>\n",
       "      <td>0.114017</td>\n",
       "      <td>60.975471</td>\n",
       "      <td>2.518298</td>\n",
       "      <td>86.302811</td>\n",
       "      <td>12.547709</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2726.900002</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>62.972198</td>\n",
       "      <td>2.492360</td>\n",
       "      <td>79.648369</td>\n",
       "      <td>12.620093</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2727.052002</td>\n",
       "      <td>0.180865</td>\n",
       "      <td>64.157539</td>\n",
       "      <td>2.470284</td>\n",
       "      <td>67.485962</td>\n",
       "      <td>12.537360</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X_LOC      Y_LOC         DEPT      NPHI        DTC      RHOB  \\\n",
       "0  455221.34375  6533321.5  2712.460002  0.218318  71.954613  2.257217   \n",
       "1  455221.34375  6533321.5  2726.596002  0.085455  59.167652  2.548615   \n",
       "2  455221.34375  6533321.5  2726.748002  0.114017  60.975471  2.518298   \n",
       "3  455221.34375  6533321.5  2726.900002  0.147875  62.972198  2.492360   \n",
       "4  455221.34375  6533321.5  2727.052002  0.180865  64.157539  2.470284   \n",
       "\n",
       "          GR       CALI  Lithology_code  \n",
       "0  58.311520  14.666450         30000.0  \n",
       "1  88.030212  12.509160         30000.0  \n",
       "2  86.302811  12.547709         30000.0  \n",
       "3  79.648369  12.620093         30000.0  \n",
       "4  67.485962  12.537360         30000.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_dataset = pd.read_csv(\"./dataset/cleaned_dataset.csv\")\n",
    "training_dataset = training_dataset[['X_LOC','Y_LOC','DEPT','NPHI','DTC','RHOB','GR','CALI','Lithology_code']]\n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0414_row9_col1, #T_f0414_row13_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0414\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f0414_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_f0414_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f0414_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_f0414_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f0414_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_f0414_row1_col1\" class=\"data row1 col1\" >Lithology_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f0414_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_f0414_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f0414_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_f0414_row3_col1\" class=\"data row3 col1\" >30000.0: 0, 65000.0: 1, 65030.0: 2, 70000.0: 3, 70032.0: 4, 74000.0: 5, 80000.0: 6, 86000.0: 7, 88000.0: 8, 90000.0: 9, 93000.0: 10, 99000.0: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f0414_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_f0414_row4_col1\" class=\"data row4 col1\" >(203789, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f0414_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_f0414_row5_col1\" class=\"data row5 col1\" >(203789, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f0414_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_f0414_row6_col1\" class=\"data row6 col1\" >(142652, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f0414_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_f0414_row7_col1\" class=\"data row7 col1\" >(61137, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f0414_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_f0414_row8_col1\" class=\"data row8 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f0414_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_f0414_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f0414_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_f0414_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f0414_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_f0414_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f0414_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_f0414_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f0414_row13_col0\" class=\"data row13 col0\" >Normalize</td>\n",
       "      <td id=\"T_f0414_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f0414_row14_col0\" class=\"data row14 col0\" >Normalize method</td>\n",
       "      <td id=\"T_f0414_row14_col1\" class=\"data row14 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f0414_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_f0414_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f0414_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_f0414_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f0414_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_f0414_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f0414_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_f0414_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_f0414_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_f0414_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_f0414_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_f0414_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0414_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_f0414_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_f0414_row21_col1\" class=\"data row21 col1\" >1ea2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29b18641730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4f91d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4f91d_row0_col0, #T_4f91d_row1_col0, #T_4f91d_row1_col1, #T_4f91d_row1_col2, #T_4f91d_row1_col3, #T_4f91d_row1_col4, #T_4f91d_row1_col5, #T_4f91d_row1_col6, #T_4f91d_row1_col7, #T_4f91d_row2_col0, #T_4f91d_row2_col1, #T_4f91d_row2_col2, #T_4f91d_row2_col3, #T_4f91d_row2_col4, #T_4f91d_row2_col5, #T_4f91d_row2_col6, #T_4f91d_row2_col7, #T_4f91d_row3_col0, #T_4f91d_row3_col1, #T_4f91d_row3_col2, #T_4f91d_row3_col3, #T_4f91d_row3_col4, #T_4f91d_row3_col5, #T_4f91d_row3_col6, #T_4f91d_row3_col7, #T_4f91d_row4_col0, #T_4f91d_row4_col1, #T_4f91d_row4_col2, #T_4f91d_row4_col3, #T_4f91d_row4_col4, #T_4f91d_row4_col5, #T_4f91d_row4_col6, #T_4f91d_row4_col7, #T_4f91d_row5_col0, #T_4f91d_row5_col1, #T_4f91d_row5_col2, #T_4f91d_row5_col3, #T_4f91d_row5_col4, #T_4f91d_row5_col5, #T_4f91d_row5_col6, #T_4f91d_row5_col7, #T_4f91d_row6_col0, #T_4f91d_row6_col1, #T_4f91d_row6_col2, #T_4f91d_row6_col3, #T_4f91d_row6_col4, #T_4f91d_row6_col5, #T_4f91d_row6_col6, #T_4f91d_row6_col7, #T_4f91d_row7_col0, #T_4f91d_row7_col1, #T_4f91d_row7_col2, #T_4f91d_row7_col3, #T_4f91d_row7_col4, #T_4f91d_row7_col5, #T_4f91d_row7_col6, #T_4f91d_row7_col7, #T_4f91d_row8_col0, #T_4f91d_row8_col1, #T_4f91d_row8_col2, #T_4f91d_row8_col3, #T_4f91d_row8_col4, #T_4f91d_row8_col5, #T_4f91d_row8_col6, #T_4f91d_row8_col7, #T_4f91d_row9_col0, #T_4f91d_row9_col1, #T_4f91d_row9_col2, #T_4f91d_row9_col3, #T_4f91d_row9_col4, #T_4f91d_row9_col5, #T_4f91d_row9_col6, #T_4f91d_row9_col7, #T_4f91d_row10_col0, #T_4f91d_row10_col1, #T_4f91d_row10_col2, #T_4f91d_row10_col3, #T_4f91d_row10_col4, #T_4f91d_row10_col5, #T_4f91d_row10_col6, #T_4f91d_row10_col7, #T_4f91d_row11_col0, #T_4f91d_row11_col1, #T_4f91d_row11_col2, #T_4f91d_row11_col3, #T_4f91d_row11_col4, #T_4f91d_row11_col5, #T_4f91d_row11_col6, #T_4f91d_row11_col7, #T_4f91d_row12_col0, #T_4f91d_row12_col1, #T_4f91d_row12_col2, #T_4f91d_row12_col3, #T_4f91d_row12_col4, #T_4f91d_row12_col5, #T_4f91d_row12_col6, #T_4f91d_row12_col7, #T_4f91d_row13_col0, #T_4f91d_row13_col1, #T_4f91d_row13_col2, #T_4f91d_row13_col3, #T_4f91d_row13_col4, #T_4f91d_row13_col5, #T_4f91d_row13_col6, #T_4f91d_row13_col7, #T_4f91d_row14_col0, #T_4f91d_row14_col1, #T_4f91d_row14_col2, #T_4f91d_row14_col3, #T_4f91d_row14_col4, #T_4f91d_row14_col5, #T_4f91d_row14_col6, #T_4f91d_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4f91d_row0_col1, #T_4f91d_row0_col2, #T_4f91d_row0_col3, #T_4f91d_row0_col4, #T_4f91d_row0_col5, #T_4f91d_row0_col6, #T_4f91d_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_4f91d_row0_col8, #T_4f91d_row1_col8, #T_4f91d_row2_col8, #T_4f91d_row3_col8, #T_4f91d_row4_col8, #T_4f91d_row5_col8, #T_4f91d_row6_col8, #T_4f91d_row7_col8, #T_4f91d_row8_col8, #T_4f91d_row9_col8, #T_4f91d_row10_col8, #T_4f91d_row11_col8, #T_4f91d_row13_col8, #T_4f91d_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_4f91d_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4f91d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4f91d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_4f91d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_4f91d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_4f91d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_4f91d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_4f91d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_4f91d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_4f91d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_4f91d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_4f91d_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_4f91d_row0_col1\" class=\"data row0 col1\" >0.9692</td>\n",
       "      <td id=\"T_4f91d_row0_col2\" class=\"data row0 col2\" >0.9981</td>\n",
       "      <td id=\"T_4f91d_row0_col3\" class=\"data row0 col3\" >0.9692</td>\n",
       "      <td id=\"T_4f91d_row0_col4\" class=\"data row0 col4\" >0.9690</td>\n",
       "      <td id=\"T_4f91d_row0_col5\" class=\"data row0 col5\" >0.9689</td>\n",
       "      <td id=\"T_4f91d_row0_col6\" class=\"data row0 col6\" >0.9498</td>\n",
       "      <td id=\"T_4f91d_row0_col7\" class=\"data row0 col7\" >0.9499</td>\n",
       "      <td id=\"T_4f91d_row0_col8\" class=\"data row0 col8\" >1.4340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_4f91d_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_4f91d_row1_col1\" class=\"data row1 col1\" >0.9656</td>\n",
       "      <td id=\"T_4f91d_row1_col2\" class=\"data row1 col2\" >0.9976</td>\n",
       "      <td id=\"T_4f91d_row1_col3\" class=\"data row1 col3\" >0.9656</td>\n",
       "      <td id=\"T_4f91d_row1_col4\" class=\"data row1 col4\" >0.9653</td>\n",
       "      <td id=\"T_4f91d_row1_col5\" class=\"data row1 col5\" >0.9651</td>\n",
       "      <td id=\"T_4f91d_row1_col6\" class=\"data row1 col6\" >0.9438</td>\n",
       "      <td id=\"T_4f91d_row1_col7\" class=\"data row1 col7\" >0.9439</td>\n",
       "      <td id=\"T_4f91d_row1_col8\" class=\"data row1 col8\" >4.5440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row2\" class=\"row_heading level0 row2\" >xgboost</th>\n",
       "      <td id=\"T_4f91d_row2_col0\" class=\"data row2 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_4f91d_row2_col1\" class=\"data row2 col1\" >0.9557</td>\n",
       "      <td id=\"T_4f91d_row2_col2\" class=\"data row2 col2\" >0.9962</td>\n",
       "      <td id=\"T_4f91d_row2_col3\" class=\"data row2 col3\" >0.9557</td>\n",
       "      <td id=\"T_4f91d_row2_col4\" class=\"data row2 col4\" >0.9552</td>\n",
       "      <td id=\"T_4f91d_row2_col5\" class=\"data row2 col5\" >0.9551</td>\n",
       "      <td id=\"T_4f91d_row2_col6\" class=\"data row2 col6\" >0.9277</td>\n",
       "      <td id=\"T_4f91d_row2_col7\" class=\"data row2 col7\" >0.9279</td>\n",
       "      <td id=\"T_4f91d_row2_col8\" class=\"data row2 col8\" >3.9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_4f91d_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_4f91d_row3_col1\" class=\"data row3 col1\" >0.9396</td>\n",
       "      <td id=\"T_4f91d_row3_col2\" class=\"data row3 col2\" >0.9537</td>\n",
       "      <td id=\"T_4f91d_row3_col3\" class=\"data row3 col3\" >0.9396</td>\n",
       "      <td id=\"T_4f91d_row3_col4\" class=\"data row3 col4\" >0.9397</td>\n",
       "      <td id=\"T_4f91d_row3_col5\" class=\"data row3 col5\" >0.9396</td>\n",
       "      <td id=\"T_4f91d_row3_col6\" class=\"data row3 col6\" >0.9022</td>\n",
       "      <td id=\"T_4f91d_row3_col7\" class=\"data row3 col7\" >0.9022</td>\n",
       "      <td id=\"T_4f91d_row3_col8\" class=\"data row3 col8\" >0.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row4\" class=\"row_heading level0 row4\" >knn</th>\n",
       "      <td id=\"T_4f91d_row4_col0\" class=\"data row4 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_4f91d_row4_col1\" class=\"data row4 col1\" >0.9296</td>\n",
       "      <td id=\"T_4f91d_row4_col2\" class=\"data row4 col2\" >0.9807</td>\n",
       "      <td id=\"T_4f91d_row4_col3\" class=\"data row4 col3\" >0.9296</td>\n",
       "      <td id=\"T_4f91d_row4_col4\" class=\"data row4 col4\" >0.9284</td>\n",
       "      <td id=\"T_4f91d_row4_col5\" class=\"data row4 col5\" >0.9284</td>\n",
       "      <td id=\"T_4f91d_row4_col6\" class=\"data row4 col6\" >0.8847</td>\n",
       "      <td id=\"T_4f91d_row4_col7\" class=\"data row4 col7\" >0.8850</td>\n",
       "      <td id=\"T_4f91d_row4_col8\" class=\"data row4 col8\" >0.5870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row5\" class=\"row_heading level0 row5\" >gbc</th>\n",
       "      <td id=\"T_4f91d_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_4f91d_row5_col1\" class=\"data row5 col1\" >0.9029</td>\n",
       "      <td id=\"T_4f91d_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row5_col3\" class=\"data row5 col3\" >0.9029</td>\n",
       "      <td id=\"T_4f91d_row5_col4\" class=\"data row5 col4\" >0.9017</td>\n",
       "      <td id=\"T_4f91d_row5_col5\" class=\"data row5 col5\" >0.8978</td>\n",
       "      <td id=\"T_4f91d_row5_col6\" class=\"data row5 col6\" >0.8370</td>\n",
       "      <td id=\"T_4f91d_row5_col7\" class=\"data row5 col7\" >0.8396</td>\n",
       "      <td id=\"T_4f91d_row5_col8\" class=\"data row5 col8\" >110.9310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row6\" class=\"row_heading level0 row6\" >lightgbm</th>\n",
       "      <td id=\"T_4f91d_row6_col0\" class=\"data row6 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_4f91d_row6_col1\" class=\"data row6 col1\" >0.8572</td>\n",
       "      <td id=\"T_4f91d_row6_col2\" class=\"data row6 col2\" >0.8929</td>\n",
       "      <td id=\"T_4f91d_row6_col3\" class=\"data row6 col3\" >0.8572</td>\n",
       "      <td id=\"T_4f91d_row6_col4\" class=\"data row6 col4\" >0.8651</td>\n",
       "      <td id=\"T_4f91d_row6_col5\" class=\"data row6 col5\" >0.8577</td>\n",
       "      <td id=\"T_4f91d_row6_col6\" class=\"data row6 col6\" >0.7648</td>\n",
       "      <td id=\"T_4f91d_row6_col7\" class=\"data row6 col7\" >0.7663</td>\n",
       "      <td id=\"T_4f91d_row6_col8\" class=\"data row6 col8\" >8.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row7\" class=\"row_heading level0 row7\" >qda</th>\n",
       "      <td id=\"T_4f91d_row7_col0\" class=\"data row7 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_4f91d_row7_col1\" class=\"data row7 col1\" >0.7181</td>\n",
       "      <td id=\"T_4f91d_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row7_col3\" class=\"data row7 col3\" >0.7181</td>\n",
       "      <td id=\"T_4f91d_row7_col4\" class=\"data row7 col4\" >0.7023</td>\n",
       "      <td id=\"T_4f91d_row7_col5\" class=\"data row7 col5\" >0.7009</td>\n",
       "      <td id=\"T_4f91d_row7_col6\" class=\"data row7 col6\" >0.5214</td>\n",
       "      <td id=\"T_4f91d_row7_col7\" class=\"data row7 col7\" >0.5259</td>\n",
       "      <td id=\"T_4f91d_row7_col8\" class=\"data row7 col8\" >0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_4f91d_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_4f91d_row8_col1\" class=\"data row8 col1\" >0.7032</td>\n",
       "      <td id=\"T_4f91d_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row8_col3\" class=\"data row8 col3\" >0.7032</td>\n",
       "      <td id=\"T_4f91d_row8_col4\" class=\"data row8 col4\" >0.6638</td>\n",
       "      <td id=\"T_4f91d_row8_col5\" class=\"data row8 col5\" >0.6522</td>\n",
       "      <td id=\"T_4f91d_row8_col6\" class=\"data row8 col6\" >0.4527</td>\n",
       "      <td id=\"T_4f91d_row8_col7\" class=\"data row8 col7\" >0.4757</td>\n",
       "      <td id=\"T_4f91d_row8_col8\" class=\"data row8 col8\" >0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row9\" class=\"row_heading level0 row9\" >lr</th>\n",
       "      <td id=\"T_4f91d_row9_col0\" class=\"data row9 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_4f91d_row9_col1\" class=\"data row9 col1\" >0.7002</td>\n",
       "      <td id=\"T_4f91d_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row9_col3\" class=\"data row9 col3\" >0.7002</td>\n",
       "      <td id=\"T_4f91d_row9_col4\" class=\"data row9 col4\" >0.6558</td>\n",
       "      <td id=\"T_4f91d_row9_col5\" class=\"data row9 col5\" >0.6471</td>\n",
       "      <td id=\"T_4f91d_row9_col6\" class=\"data row9 col6\" >0.4403</td>\n",
       "      <td id=\"T_4f91d_row9_col7\" class=\"data row9 col7\" >0.4643</td>\n",
       "      <td id=\"T_4f91d_row9_col8\" class=\"data row9 col8\" >1.8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_4f91d_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_4f91d_row10_col1\" class=\"data row10 col1\" >0.6759</td>\n",
       "      <td id=\"T_4f91d_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row10_col3\" class=\"data row10 col3\" >0.6759</td>\n",
       "      <td id=\"T_4f91d_row10_col4\" class=\"data row10 col4\" >0.5969</td>\n",
       "      <td id=\"T_4f91d_row10_col5\" class=\"data row10 col5\" >0.6080</td>\n",
       "      <td id=\"T_4f91d_row10_col6\" class=\"data row10 col6\" >0.3719</td>\n",
       "      <td id=\"T_4f91d_row10_col7\" class=\"data row10 col7\" >0.4102</td>\n",
       "      <td id=\"T_4f91d_row10_col8\" class=\"data row10 col8\" >0.1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row11\" class=\"row_heading level0 row11\" >ada</th>\n",
       "      <td id=\"T_4f91d_row11_col0\" class=\"data row11 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_4f91d_row11_col1\" class=\"data row11 col1\" >0.6528</td>\n",
       "      <td id=\"T_4f91d_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row11_col3\" class=\"data row11 col3\" >0.6528</td>\n",
       "      <td id=\"T_4f91d_row11_col4\" class=\"data row11 col4\" >0.5005</td>\n",
       "      <td id=\"T_4f91d_row11_col5\" class=\"data row11 col5\" >0.5638</td>\n",
       "      <td id=\"T_4f91d_row11_col6\" class=\"data row11 col6\" >0.3160</td>\n",
       "      <td id=\"T_4f91d_row11_col7\" class=\"data row11 col7\" >0.3489</td>\n",
       "      <td id=\"T_4f91d_row11_col8\" class=\"data row11 col8\" >1.9370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row12\" class=\"row_heading level0 row12\" >ridge</th>\n",
       "      <td id=\"T_4f91d_row12_col0\" class=\"data row12 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_4f91d_row12_col1\" class=\"data row12 col1\" >0.6451</td>\n",
       "      <td id=\"T_4f91d_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row12_col3\" class=\"data row12 col3\" >0.6451</td>\n",
       "      <td id=\"T_4f91d_row12_col4\" class=\"data row12 col4\" >0.5188</td>\n",
       "      <td id=\"T_4f91d_row12_col5\" class=\"data row12 col5\" >0.5640</td>\n",
       "      <td id=\"T_4f91d_row12_col6\" class=\"data row12 col6\" >0.2915</td>\n",
       "      <td id=\"T_4f91d_row12_col7\" class=\"data row12 col7\" >0.3275</td>\n",
       "      <td id=\"T_4f91d_row12_col8\" class=\"data row12 col8\" >0.0620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "      <td id=\"T_4f91d_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_4f91d_row13_col1\" class=\"data row13 col1\" >0.6222</td>\n",
       "      <td id=\"T_4f91d_row13_col2\" class=\"data row13 col2\" >0.7911</td>\n",
       "      <td id=\"T_4f91d_row13_col3\" class=\"data row13 col3\" >0.6222</td>\n",
       "      <td id=\"T_4f91d_row13_col4\" class=\"data row13 col4\" >0.6482</td>\n",
       "      <td id=\"T_4f91d_row13_col5\" class=\"data row13 col5\" >0.5947</td>\n",
       "      <td id=\"T_4f91d_row13_col6\" class=\"data row13 col6\" >0.3667</td>\n",
       "      <td id=\"T_4f91d_row13_col7\" class=\"data row13 col7\" >0.3789</td>\n",
       "      <td id=\"T_4f91d_row13_col8\" class=\"data row13 col8\" >0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f91d_level0_row14\" class=\"row_heading level0 row14\" >dummy</th>\n",
       "      <td id=\"T_4f91d_row14_col0\" class=\"data row14 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_4f91d_row14_col1\" class=\"data row14 col1\" >0.5825</td>\n",
       "      <td id=\"T_4f91d_row14_col2\" class=\"data row14 col2\" >0.5000</td>\n",
       "      <td id=\"T_4f91d_row14_col3\" class=\"data row14 col3\" >0.5825</td>\n",
       "      <td id=\"T_4f91d_row14_col4\" class=\"data row14 col4\" >0.3393</td>\n",
       "      <td id=\"T_4f91d_row14_col5\" class=\"data row14 col5\" >0.4288</td>\n",
       "      <td id=\"T_4f91d_row14_col6\" class=\"data row14 col6\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row14_col7\" class=\"data row14 col7\" >0.0000</td>\n",
       "      <td id=\"T_4f91d_row14_col8\" class=\"data row14 col8\" >0.0970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29b1901a8e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset (ganti dengan dataset yang sesuai)\n",
    "data = training_dataset.copy()\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "target_column = \"Lithology_code\"  # Ganti dengan nama kolom target\n",
    "\n",
    "# Split dataset into train and test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setup PyCaret\n",
    "clf = setup(train_data, target=target_column, normalize=True, session_id=42)\n",
    "\n",
    "# Compare models and find the best one\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. EVALUATION AND TUNNING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a05cd_row10_col0, #T_a05cd_row10_col1, #T_a05cd_row10_col2, #T_a05cd_row10_col3, #T_a05cd_row10_col4, #T_a05cd_row10_col5, #T_a05cd_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a05cd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a05cd_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_a05cd_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_a05cd_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_a05cd_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_a05cd_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_a05cd_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_a05cd_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a05cd_row0_col0\" class=\"data row0 col0\" >0.7976</td>\n",
       "      <td id=\"T_a05cd_row0_col1\" class=\"data row0 col1\" >0.9595</td>\n",
       "      <td id=\"T_a05cd_row0_col2\" class=\"data row0 col2\" >0.7976</td>\n",
       "      <td id=\"T_a05cd_row0_col3\" class=\"data row0 col3\" >0.8059</td>\n",
       "      <td id=\"T_a05cd_row0_col4\" class=\"data row0 col4\" >0.7600</td>\n",
       "      <td id=\"T_a05cd_row0_col5\" class=\"data row0 col5\" >0.6223</td>\n",
       "      <td id=\"T_a05cd_row0_col6\" class=\"data row0 col6\" >0.6541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a05cd_row1_col0\" class=\"data row1 col0\" >0.7974</td>\n",
       "      <td id=\"T_a05cd_row1_col1\" class=\"data row1 col1\" >0.9587</td>\n",
       "      <td id=\"T_a05cd_row1_col2\" class=\"data row1 col2\" >0.7974</td>\n",
       "      <td id=\"T_a05cd_row1_col3\" class=\"data row1 col3\" >0.8054</td>\n",
       "      <td id=\"T_a05cd_row1_col4\" class=\"data row1 col4\" >0.7598</td>\n",
       "      <td id=\"T_a05cd_row1_col5\" class=\"data row1 col5\" >0.6219</td>\n",
       "      <td id=\"T_a05cd_row1_col6\" class=\"data row1 col6\" >0.6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a05cd_row2_col0\" class=\"data row2 col0\" >0.7982</td>\n",
       "      <td id=\"T_a05cd_row2_col1\" class=\"data row2 col1\" >0.9571</td>\n",
       "      <td id=\"T_a05cd_row2_col2\" class=\"data row2 col2\" >0.7982</td>\n",
       "      <td id=\"T_a05cd_row2_col3\" class=\"data row2 col3\" >0.8054</td>\n",
       "      <td id=\"T_a05cd_row2_col4\" class=\"data row2 col4\" >0.7634</td>\n",
       "      <td id=\"T_a05cd_row2_col5\" class=\"data row2 col5\" >0.6249</td>\n",
       "      <td id=\"T_a05cd_row2_col6\" class=\"data row2 col6\" >0.6548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a05cd_row3_col0\" class=\"data row3 col0\" >0.7956</td>\n",
       "      <td id=\"T_a05cd_row3_col1\" class=\"data row3 col1\" >0.9580</td>\n",
       "      <td id=\"T_a05cd_row3_col2\" class=\"data row3 col2\" >0.7956</td>\n",
       "      <td id=\"T_a05cd_row3_col3\" class=\"data row3 col3\" >0.8032</td>\n",
       "      <td id=\"T_a05cd_row3_col4\" class=\"data row3 col4\" >0.7586</td>\n",
       "      <td id=\"T_a05cd_row3_col5\" class=\"data row3 col5\" >0.6187</td>\n",
       "      <td id=\"T_a05cd_row3_col6\" class=\"data row3 col6\" >0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a05cd_row4_col0\" class=\"data row4 col0\" >0.7959</td>\n",
       "      <td id=\"T_a05cd_row4_col1\" class=\"data row4 col1\" >0.9579</td>\n",
       "      <td id=\"T_a05cd_row4_col2\" class=\"data row4 col2\" >0.7959</td>\n",
       "      <td id=\"T_a05cd_row4_col3\" class=\"data row4 col3\" >0.8029</td>\n",
       "      <td id=\"T_a05cd_row4_col4\" class=\"data row4 col4\" >0.7576</td>\n",
       "      <td id=\"T_a05cd_row4_col5\" class=\"data row4 col5\" >0.6205</td>\n",
       "      <td id=\"T_a05cd_row4_col6\" class=\"data row4 col6\" >0.6504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a05cd_row5_col0\" class=\"data row5 col0\" >0.7938</td>\n",
       "      <td id=\"T_a05cd_row5_col1\" class=\"data row5 col1\" >0.9571</td>\n",
       "      <td id=\"T_a05cd_row5_col2\" class=\"data row5 col2\" >0.7938</td>\n",
       "      <td id=\"T_a05cd_row5_col3\" class=\"data row5 col3\" >0.8016</td>\n",
       "      <td id=\"T_a05cd_row5_col4\" class=\"data row5 col4\" >0.7550</td>\n",
       "      <td id=\"T_a05cd_row5_col5\" class=\"data row5 col5\" >0.6154</td>\n",
       "      <td id=\"T_a05cd_row5_col6\" class=\"data row5 col6\" >0.6464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a05cd_row6_col0\" class=\"data row6 col0\" >0.7948</td>\n",
       "      <td id=\"T_a05cd_row6_col1\" class=\"data row6 col1\" >0.9580</td>\n",
       "      <td id=\"T_a05cd_row6_col2\" class=\"data row6 col2\" >0.7948</td>\n",
       "      <td id=\"T_a05cd_row6_col3\" class=\"data row6 col3\" >0.8026</td>\n",
       "      <td id=\"T_a05cd_row6_col4\" class=\"data row6 col4\" >0.7560</td>\n",
       "      <td id=\"T_a05cd_row6_col5\" class=\"data row6 col5\" >0.6175</td>\n",
       "      <td id=\"T_a05cd_row6_col6\" class=\"data row6 col6\" >0.6482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a05cd_row7_col0\" class=\"data row7 col0\" >0.7890</td>\n",
       "      <td id=\"T_a05cd_row7_col1\" class=\"data row7 col1\" >0.9554</td>\n",
       "      <td id=\"T_a05cd_row7_col2\" class=\"data row7 col2\" >0.7890</td>\n",
       "      <td id=\"T_a05cd_row7_col3\" class=\"data row7 col3\" >0.7987</td>\n",
       "      <td id=\"T_a05cd_row7_col4\" class=\"data row7 col4\" >0.7481</td>\n",
       "      <td id=\"T_a05cd_row7_col5\" class=\"data row7 col5\" >0.6052</td>\n",
       "      <td id=\"T_a05cd_row7_col6\" class=\"data row7 col6\" >0.6376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a05cd_row8_col0\" class=\"data row8 col0\" >0.7970</td>\n",
       "      <td id=\"T_a05cd_row8_col1\" class=\"data row8 col1\" >0.9587</td>\n",
       "      <td id=\"T_a05cd_row8_col2\" class=\"data row8 col2\" >0.7970</td>\n",
       "      <td id=\"T_a05cd_row8_col3\" class=\"data row8 col3\" >0.8037</td>\n",
       "      <td id=\"T_a05cd_row8_col4\" class=\"data row8 col4\" >0.7619</td>\n",
       "      <td id=\"T_a05cd_row8_col5\" class=\"data row8 col5\" >0.6223</td>\n",
       "      <td id=\"T_a05cd_row8_col6\" class=\"data row8 col6\" >0.6526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a05cd_row9_col0\" class=\"data row9 col0\" >0.7955</td>\n",
       "      <td id=\"T_a05cd_row9_col1\" class=\"data row9 col1\" >0.9553</td>\n",
       "      <td id=\"T_a05cd_row9_col2\" class=\"data row9 col2\" >0.7955</td>\n",
       "      <td id=\"T_a05cd_row9_col3\" class=\"data row9 col3\" >0.8028</td>\n",
       "      <td id=\"T_a05cd_row9_col4\" class=\"data row9 col4\" >0.7571</td>\n",
       "      <td id=\"T_a05cd_row9_col5\" class=\"data row9 col5\" >0.6196</td>\n",
       "      <td id=\"T_a05cd_row9_col6\" class=\"data row9 col6\" >0.6496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_a05cd_row10_col0\" class=\"data row10 col0\" >0.7955</td>\n",
       "      <td id=\"T_a05cd_row10_col1\" class=\"data row10 col1\" >0.9576</td>\n",
       "      <td id=\"T_a05cd_row10_col2\" class=\"data row10 col2\" >0.7955</td>\n",
       "      <td id=\"T_a05cd_row10_col3\" class=\"data row10 col3\" >0.8032</td>\n",
       "      <td id=\"T_a05cd_row10_col4\" class=\"data row10 col4\" >0.7577</td>\n",
       "      <td id=\"T_a05cd_row10_col5\" class=\"data row10 col5\" >0.6188</td>\n",
       "      <td id=\"T_a05cd_row10_col6\" class=\"data row10 col6\" >0.6497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a05cd_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_a05cd_row11_col0\" class=\"data row11 col0\" >0.0025</td>\n",
       "      <td id=\"T_a05cd_row11_col1\" class=\"data row11 col1\" >0.0013</td>\n",
       "      <td id=\"T_a05cd_row11_col2\" class=\"data row11 col2\" >0.0025</td>\n",
       "      <td id=\"T_a05cd_row11_col3\" class=\"data row11 col3\" >0.0020</td>\n",
       "      <td id=\"T_a05cd_row11_col4\" class=\"data row11 col4\" >0.0040</td>\n",
       "      <td id=\"T_a05cd_row11_col5\" class=\"data row11 col5\" >0.0052</td>\n",
       "      <td id=\"T_a05cd_row11_col6\" class=\"data row11 col6\" >0.0048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29b1849c790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bf807a042b498ea441c55453fcfa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7581f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7581f_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_7581f_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_7581f_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_7581f_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_7581f_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_7581f_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_7581f_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_7581f_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7581f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7581f_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_7581f_row0_col1\" class=\"data row0 col1\" >0.9745</td>\n",
       "      <td id=\"T_7581f_row0_col2\" class=\"data row0 col2\" >0.9989</td>\n",
       "      <td id=\"T_7581f_row0_col3\" class=\"data row0 col3\" >0.9745</td>\n",
       "      <td id=\"T_7581f_row0_col4\" class=\"data row0 col4\" >0.9744</td>\n",
       "      <td id=\"T_7581f_row0_col5\" class=\"data row0 col5\" >0.9743</td>\n",
       "      <td id=\"T_7581f_row0_col6\" class=\"data row0 col6\" >0.9584</td>\n",
       "      <td id=\"T_7581f_row0_col7\" class=\"data row0 col7\" >0.9585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29b19033940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               X_LOC      Y_LOC         DEPT      NPHI         DTC      RHOB  \\\n",
      "111878  442439.71875  6759337.0  3628.305908  0.267848   78.389526  2.675912   \n",
      "78161   520153.18750  6452287.5  2161.697021  0.424427  123.719910  2.290416   \n",
      "76220   520153.18750  6452287.5  1812.704956  0.389822  115.962715  2.316001   \n",
      "90584   497352.43750  6737314.5  1613.750000  0.494470  146.163330  2.112000   \n",
      "16658   442442.84375  6759398.5   887.442017  0.324526  151.318893  2.186882   \n",
      "...              ...        ...          ...       ...         ...       ...   \n",
      "33476   449950.62500  6500259.0   768.489624  0.452436  149.884308  2.049571   \n",
      "87538   497358.62500  6737310.5   633.349976  0.391190  134.840363  2.105914   \n",
      "107104  442427.75000  6759350.0  2691.530029  0.286219  106.284653  2.514788   \n",
      "228522  487274.43750  6643962.5  2641.112061  0.143584   60.896545  2.615238   \n",
      "223073  477771.87500  6520630.0  1799.034790  0.195466   89.917854  2.472843   \n",
      "\n",
      "                 GR       CALI  Lithology_code  prediction_label  \\\n",
      "111878    79.836243   8.582466         65000.0             65000   \n",
      "78161    161.955612  12.766086         65000.0             65000   \n",
      "76220     85.029190  12.651608         65000.0             65000   \n",
      "90584     27.180473  17.906300         65000.0             65000   \n",
      "16658     32.511078  17.420935         30000.0             30000   \n",
      "...             ...        ...             ...               ...   \n",
      "33476     72.498650  21.588655         30000.0             30000   \n",
      "87538   3488.515625  10.735394         65000.0             65000   \n",
      "107104    46.661823  12.180359         65000.0             65000   \n",
      "228522    10.040184  12.453993         70000.0             70000   \n",
      "223073    37.338928  12.737169         70000.0             70000   \n",
      "\n",
      "        prediction_score  \n",
      "111878              0.70  \n",
      "78161               1.00  \n",
      "76220               0.89  \n",
      "90584               1.00  \n",
      "16658               1.00  \n",
      "...                  ...  \n",
      "33476               1.00  \n",
      "87538               1.00  \n",
      "107104              1.00  \n",
      "228522              1.00  \n",
      "223073              1.00  \n",
      "\n",
      "[50948 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "tuned_model = tune_model(best_model)\n",
    "\n",
    "# Evaluate tuned model\n",
    "evaluate_model(tuned_model)\n",
    "\n",
    "# Finalize the model (optional, jika ingin digunakan untuk prediksi lebih lanjut)\n",
    "final_model = finalize_model(tuned_model)\n",
    "\n",
    "# Predict on test data\n",
    "predictions = predict_model(final_model, data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "save_model(final_model, \"final_lithology_model_2\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEST DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RUL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
