{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. LOAD DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/combined_train_dataset.csv\")\n",
    "test_df = pd.read_csv(\"./dataset/Test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. PREPROCESSING TRAIN DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 DROP UNRELEVANT FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=['Lithology_code'],inplace=True)\n",
    "train_df = train_df.drop(columns=['DTS','SGR','ROPA','RMIC','RXO','DCAL','RSHA','file_name','filename','DEPTH_MD','Z_LOC','MUDWEIGHT','PEF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 CLEANING DTC AND CONVERT TO NUMBER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghapus 'val:' dan '[UNIT]' serta konversi ke float\n",
    "def clean_value(value):\n",
    "    if isinstance(value, str):  # Pastikan nilai adalah string\n",
    "        # Hapus 'val:' jika ada\n",
    "        if 'val:' in value:\n",
    "            value = value.replace('val:', '').strip()\n",
    "        # Hapus '[UNIT]' jika ada\n",
    "        if '[UNIT]' in value:\n",
    "            value = value.replace('[UNIT]', '').strip()\n",
    "        # Coba konversi ke float\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return value  # Kembalikan asli jika gagal konversi\n",
    "    # Jika bukan string (misalnya sudah float), kembalikan apa adanya\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return value  # Kembalikan asli jika gagal konversi\n",
    "\n",
    "# Terapkan fungsi ke kolom DTC\n",
    "train_df['DTC'] = train_df['DTC'].apply(clean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 FILL NAN LOCATION FEATURE WITH CDKTREE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# Ensure X_LOC and Y_LOC have no missing values\n",
    "train_df = train_df.dropna(subset=['X_LOC', 'Y_LOC'])\n",
    "\n",
    "# Create KDTree using valid spatial coordinates\n",
    "coords = train_df[['X_LOC', 'Y_LOC']].values\n",
    "tree = cKDTree(coords)\n",
    "\n",
    "# Find the 2 nearest neighbors (excluding itself)\n",
    "_, idx = tree.query(coords, k=3)  # k=3 for backup if the first neighbor is missing\n",
    "\n",
    "# Fill missing values using nearest neighbor\n",
    "for col in ['NPHI', 'DTC', 'SP', 'GR', 'RHOB', 'CALI']:\n",
    "    missing_mask = train_df[col].isna()  # Find missing values\n",
    "    \n",
    "    # Create an empty array to store filled values\n",
    "    filled_values = train_df[col].values.copy()\n",
    "    \n",
    "    for i, is_missing in enumerate(missing_mask):\n",
    "        if is_missing:\n",
    "            # Check nearest neighbors\n",
    "            for neighbor_idx in idx[i, 1:]:  # Skip self (idx[i, 0] is the same point)\n",
    "                if not np.isnan(train_df.iloc[neighbor_idx][col]):  # Use first non-NaN neighbor\n",
    "                    filled_values[i] = train_df.iloc[neighbor_idx][col]\n",
    "                    break  # Stop after finding the first valid neighbor\n",
    "    \n",
    "    # Assign the new filled values\n",
    "    train_df[col] = filled_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4 CREATE CLUSTER FEATURE BY (X_LOC AND Y_LOC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get indices of non-null X_LOC and Y_LOC values\n",
    "valid_indices = train_df[['X_LOC', 'Y_LOC']].dropna().index\n",
    "\n",
    "# Get X array for clustering\n",
    "X = train_df.loc[valid_indices, ['X_LOC', 'Y_LOC']].astype(int).values\n",
    "\n",
    "# Gunakan eps berdasarkan k-dist plot\n",
    "dbscan = DBSCAN(eps=1, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "# Tambahkan hasil klaster ke train_df\n",
    "train_df.loc[valid_indices, 'Cluster_DBSCAN'] = clusters\n",
    "\n",
    "# Plot hasil clustering\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', marker='o', alpha=0.6)\n",
    "plt.xlabel('X_LOC')\n",
    "plt.ylabel('Y_LOC')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5 SPLIT DATASET BY CLUSTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = train_df['Cluster_DBSCAN'].dropna().unique()  # Ambil semua cluster unik\n",
    "\n",
    "# Buat dictionary untuk menyimpan DataFrame tiap cluster\n",
    "cluster_dfs = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    cluster_dfs[cluster] = train_df[train_df['Cluster_DBSCAN'] == cluster].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat folder utama untuk menyimpan dataset per cluster\n",
    "output_folder = 'dataset_cluster'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterasi setiap cluster dan simpan sebagai file CSV\n",
    "for cluster, df in cluster_dfs.items():\n",
    "    # Tentukan nama file dengan format \"(nama_cluster)_dataset.csv\"\n",
    "    filename = f\"{cluster}_dataset.csv\"\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "    # Simpan DataFrame ke CSV\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.6 FILL NAN BY ORDERING DEPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, df in cluster_dfs.items():\n",
    "    # Urutkan data berdasarkan DEPT\n",
    "    df = df.sort_values(by='DEPT')\n",
    "    \n",
    "    # Reset index untuk memudahkan akses\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Ambil kolom numerik (kecuali Lithology_code)\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    \n",
    "    # Buat mask untuk melacak NaN awal\n",
    "    nan_mask = df[numeric_cols].isna()\n",
    "    \n",
    "    # Forward Fill (ffill)\n",
    "    for col in numeric_cols:\n",
    "        condition_ffill = (df['Lithology_code'].shift(-1) == df['Lithology_code'])\n",
    "        df[col] = df[col].where(~nan_mask[col] | ~condition_ffill, df[col].shift(-1))\n",
    "    \n",
    "    # Backward Fill (bfill)\n",
    "    for col in numeric_cols:\n",
    "        condition_bfill = (df['Lithology_code'].shift(1) == df['Lithology_code'])\n",
    "        df[col] = df[col].where(~nan_mask[col] | ~condition_bfill, df[col].shift(1))\n",
    "    \n",
    "    # Logging: Hitung jumlah NaN yang diisi dengan setiap metode\n",
    "    ffill_count = nan_mask.sum() - df[numeric_cols].isna().sum()\n",
    "    bfill_count = nan_mask.sum() - df[numeric_cols].isna().sum() - ffill_count\n",
    "    \n",
    "    # Simpan kembali ke cluster_dfs\n",
    "    cluster_dfs[cluster] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.7 LABELLING OUTLIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pilih fitur untuk analisis (exclude specified columns)\n",
    "exclude_cols = ['Lithology_code', 'X_LOC', 'Y_LOC', 'DEPT', 'Cluster_DBSCAN']\n",
    "numeric_cols = [col for col in train_df.select_dtypes('number').columns if col not in exclude_cols]\n",
    "\n",
    "# Daftar fitur yang TIDAK BOLEH negatif\n",
    "cannot_be_negative = ['NPHI', 'RHOB', 'GR', 'PEF', 'CALI', 'BS', 'ROP', 'MUDWEIGHT', 'RDEP', 'RMED', 'DTC', 'DEPT', 'DEPTH_MD']\n",
    "\n",
    "# Daftar fitur yang BOLEH negatif\n",
    "can_be_negative = ['SP', 'DRHO', 'Z_LOC', 'X_LOC', 'Y_LOC', 'Cluster_DBSCAN']\n",
    "\n",
    "# 2. Definisikan fungsi untuk mendeteksi outlier\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Tentukan lower_bound berdasarkan apakah fitur boleh negatif atau tidak\n",
    "    if column in cannot_be_negative:\n",
    "        # Untuk fitur yang tidak boleh negatif, lower_bound minimal 0\n",
    "        lower_bound = max(Q1 - 1.5 * IQR, 0)\n",
    "    elif column in can_be_negative:\n",
    "        # Untuk fitur yang boleh negatif, lower_bound = Q1 - 1.5 * IQR\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "    else:\n",
    "        # Default: anggap tidak boleh negatif jika tidak diketahui\n",
    "        lower_bound = max(Q1 - 1.5 * IQR, 0)\n",
    "    \n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    is_outlier = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    return is_outlier, lower_bound, upper_bound\n",
    "\n",
    "# 3. Labeling outlier untuk setiap cluster\n",
    "for cluster, df_cluster in cluster_dfs.items():\n",
    "    # Buat DataFrame untuk menyimpan status outlier\n",
    "    outlier_mask = pd.DataFrame(index=df_cluster.index)\n",
    "    \n",
    "    # Deteksi outlier untuk setiap kolom numerik\n",
    "    for col in numeric_cols:\n",
    "        if df_cluster[col].notna().any():  # Only process columns with non-null values\n",
    "            is_outlier, lower_bound, upper_bound = detect_outliers(df_cluster, col)\n",
    "            outlier_mask[f'{col}_is_outlier'] = is_outlier\n",
    "         \n",
    "    # Tambahkan status outlier ke DataFrame cluster\n",
    "    cluster_dfs[cluster] = df_cluster.join(outlier_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.8 SPLIT BY CLASS ON EACH CLUSTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary bertingkat untuk menyimpan data berdasarkan cluster dan lithology\n",
    "cluster_lithology_dfs = {}\n",
    "\n",
    "for cluster in cluster_dfs.keys():\n",
    "    # Split lagi berdasarkan Lithology_code\n",
    "    lithology_codes = cluster_dfs[cluster]['Lithology_code'].dropna().unique()\n",
    "    \n",
    "    # Dictionary dalam dictionary untuk Lithology_code per cluster\n",
    "    cluster_lithology_dfs[cluster] = {}\n",
    "\n",
    "    for litho in lithology_codes:\n",
    "        cluster_lithology_dfs[cluster][litho] = cluster_dfs[cluster][cluster_dfs[cluster]['Lithology_code'] == litho].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder utama untuk menyimpan dataset per cluster dan lithology\n",
    "main_folder = 'dataset_cluster_class'\n",
    "os.makedirs(main_folder, exist_ok=True)\n",
    "\n",
    "# Iterasi setiap cluster dan lithology\n",
    "for cluster, lithology_dict in cluster_lithology_dfs.items():\n",
    "    # Buat subfolder untuk cluster (misalnya \"1\", \"2\", dst.)\n",
    "    cluster_folder = os.path.join(main_folder, str(cluster))\n",
    "    os.makedirs(cluster_folder, exist_ok=True)\n",
    "    \n",
    "    for lithology_code, df in lithology_dict.items():\n",
    "        # Tentukan nama file sesuai lithology_code\n",
    "        filename = f\"{lithology_code}.csv\"\n",
    "        filepath = os.path.join(cluster_folder, filename)\n",
    "\n",
    "        # Simpan DataFrame ke CSV\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.9 INTERPOLATE OUTLIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder utama tempat dataset tersimpan\n",
    "main_folder = 'dataset_cluster_class'\n",
    "\n",
    "# Iterasi setiap subfolder (cluster)\n",
    "for cluster_folder in os.listdir(main_folder):\n",
    "    cluster_path = os.path.join(main_folder, cluster_folder)\n",
    "\n",
    "    # Periksa apakah path adalah folder\n",
    "    if os.path.isdir(cluster_path):\n",
    "        # print(f\"Opening folder: {cluster_folder}\")\n",
    "\n",
    "        # Iterasi setiap file dalam folder cluster\n",
    "        for filename in os.listdir(cluster_path):\n",
    "            file_path = os.path.join(cluster_path, filename)\n",
    "\n",
    "            # Periksa apakah file adalah CSV\n",
    "            if filename.endswith('.csv'):\n",
    "                # print(f\"Reading file: {filename}\")\n",
    "\n",
    "                # Buka file CSV sebagai DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Get list of outlier columns\n",
    "                outlier_cols = [col for col in df.columns if \"outlier\" in col]\n",
    "                \n",
    "                if outlier_cols:  # If there are outlier columns\n",
    "                    # Get corresponding feature columns (remove '_is_outlier' suffix)\n",
    "                    feature_cols = [col.replace('_is_outlier', '') for col in outlier_cols]\n",
    "                    \n",
    "                    for feature, outlier_col in zip(feature_cols, outlier_cols):\n",
    "                        if outlier_col in df.columns:\n",
    "                            # Simpan mask NaN asli sebelum mengganti outlier dengan NaN\n",
    "                            mask_nan_original = df[feature].isna()\n",
    "\n",
    "                            # Mask untuk outlier\n",
    "                            mask_outliers = df[outlier_col] == True  \n",
    "\n",
    "                            # Ganti hanya outlier dengan NaN\n",
    "                            df.loc[mask_outliers, feature] = None  \n",
    "\n",
    "                            # Lakukan interpolasi\n",
    "                            df[feature] = df[feature].interpolate(method='linear')\n",
    "\n",
    "                            # Kembalikan NaN asli ke posisi semula\n",
    "                            df.loc[mask_nan_original, feature] = None  \n",
    "                    \n",
    "                    # Save the updated DataFrame\n",
    "                    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. FILL NAN VALUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 FILL NAN VALUE WITH KNN IN EACH CLASS IN EACH CLUSTER** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Definisi hubungan fitur untuk imputasi\n",
    "imputation_dict = {\n",
    "    'DTC': ['RHOB', 'NPHI', 'DEPT'],\n",
    "    'RHOB': ['NPHI', 'DTC', 'DEPT'],\n",
    "    'GR': ['DEPT'],\n",
    "    'CALI': ['DEPT', 'BS'],\n",
    "    'DRHO' : ['NPHI', 'DEPT'],\n",
    "    'ROP' : ['NPHI','DEPT','CALI'],\n",
    "    'NPHI': ['RHOB', 'DTC', 'DEPT','CALI'],\n",
    "}\n",
    "\n",
    "def impute_feature(df, target_feature, predictor_features):\n",
    "    # Periksa apakah kolom target 100% NaN\n",
    "    if df[target_feature].isna().sum() == len(df):\n",
    "        print(f\"Skipping {target_feature}: 100% NaN.\")\n",
    "        return df  # Kembalikan DataFrame tanpa perubahan\n",
    "    \n",
    "    # Periksa apakah semua kolom prediktor 100% NaN\n",
    "    valid_predictors = [col for col in predictor_features if df[col].isna().sum() < len(df)]\n",
    "    \n",
    "    if len(valid_predictors) == 0:\n",
    "        print(f\"Skipping {target_feature}: All predictor columns are 100% NaN.\")\n",
    "        return df  # Kembalikan DataFrame tanpa perubahan\n",
    "    \n",
    "    # Jika target adalah CALI dan BS tersedia, gunakan regresi linear\n",
    "    if (target_feature == 'CALI' and 'BS' in valid_predictors) or (target_feature == 'NPHI' and ['RHOB', 'DTC', 'DEPT','CALI'] in valid_predictors):\n",
    "        print(\"Using Linear Regression for CALI imputations with BS...\")\n",
    "        \n",
    "        # Pisahkan data menjadi yang memiliki nilai dan yang tidak\n",
    "        known_data = df.dropna(subset=['CALI', 'BS'])\n",
    "        unknown_data = df[df['CALI'].isna() & df['BS'].notna()]\n",
    "        \n",
    "        if not known_data.empty and not unknown_data.empty:\n",
    "            # Latih model regresi\n",
    "            model = LinearRegression()\n",
    "            model.fit(known_data[['BS']], known_data['CALI'])\n",
    "            \n",
    "            # Prediksi nilai CALI yang hilang\n",
    "            df.loc[df['CALI'].isna() & df['BS'].notna(), 'CALI'] = model.predict(unknown_data[['BS']])\n",
    "    \n",
    "    # Cek apakah masih ada NaN yang perlu diimputasi di target\n",
    "    if df[target_feature].isna().sum() > 0:\n",
    "        print(f\"Imputing {target_feature} using {valid_predictors} with KNN...\")\n",
    "\n",
    "        # Ambil subset data dengan fitur prediktor valid dan target\n",
    "        imputation_data = df[valid_predictors + [target_feature]].copy()\n",
    "\n",
    "        # Standarisasi data\n",
    "        scaler = StandardScaler()\n",
    "        imputation_data_scaled = scaler.fit_transform(imputation_data)\n",
    "\n",
    "        # Terapkan KNN Imputer\n",
    "        imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "        imputed_data_scaled = imputer.fit_transform(imputation_data_scaled)\n",
    "\n",
    "        # Kembalikan ke skala asli\n",
    "        imputed_data = scaler.inverse_transform(imputed_data_scaled)\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=valid_predictors + [target_feature], index=df.index)\n",
    "\n",
    "        # Update DataFrame asli\n",
    "        df[target_feature] = imputed_df[target_feature]\n",
    "    else:\n",
    "        print(f\"No NaN values in {target_feature}. Skipping imputation.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 0.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Processing folder: 1.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 10.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Skipping CALI: 100% NaN.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Processing folder: 11.0\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Processing folder: 12.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['DEPT'] with KNN...\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['RHOB', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "Imputing DTC using ['RHOB', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['DEPT', 'CALI'] with KNN...\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Skipping CALI: 100% NaN.\n",
      "Imputing DRHO using ['DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Processing folder: 13.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 88000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 88000.0.csv\n",
      "Processing folder: 14.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Processing folder: 15.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 16.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 17.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Imputing CALI using ['DEPT'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Skipping ROP: 100% NaN.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "Skipping ROP: 100% NaN.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 18.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Skipping CALI: 100% NaN.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "Imputing DTC using ['DEPT'] with KNN...\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 19.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 90000.0.csv\n",
      "Processing folder: 2.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 70032.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70032.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 88000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 88000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 20.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['DEPT'] with KNN...\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "Imputing CALI using ['DEPT', 'BS'] with KNN...\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['DEPT'] with KNN...\n",
      "Skipping RHOB: 100% NaN.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Skipping RHOB: 100% NaN.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Skipping DRHO: 100% NaN.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Processing folder: 3.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "Skipping DTC: 100% NaN.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "Skipping DTC: 100% NaN.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 4.0\n",
      "Reading file: 30000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "Imputing CALI using ['DEPT', 'BS'] with KNN...\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Skipping CALI: 100% NaN.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT'] with KNN...\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 5.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 6.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 7.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 86000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0.csv\n",
      "Reading file: 93000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 93000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 8.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n",
      "Processing folder: 9.0\n",
      "Reading file: 30000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "Imputing GR using ['DEPT'] with KNN...\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0.csv\n",
      "Reading file: 65000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0.csv\n",
      "Reading file: 65030.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0.csv\n",
      "Reading file: 70000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0.csv\n",
      "Reading file: 74000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['DEPT'] with KNN...\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 74000.0.csv\n",
      "Reading file: 80000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0.csv\n",
      "Reading file: 90000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 90000.0.csv\n",
      "Reading file: 99000.0.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Skipping NPHI: 100% NaN.\n",
      "Saved imputed file: 99000.0.csv\n"
     ]
    }
   ],
   "source": [
    "# Path ke folder utama yang berisi subfolder cluster\n",
    "main_folder = 'dataset_cluster_class'  # Ganti dengan path folder utama Anda\n",
    "\n",
    "# Iterasi setiap subfolder (cluster)\n",
    "for cluster_folder in os.listdir(main_folder):\n",
    "    cluster_path = os.path.join(main_folder, cluster_folder)\n",
    "\n",
    "    # Periksa apakah path adalah folder\n",
    "    if os.path.isdir(cluster_path):\n",
    "        print(f\"Processing folder: {cluster_folder}\")\n",
    "\n",
    "        # Iterasi setiap file dalam folder cluster\n",
    "        for filename in os.listdir(cluster_path):\n",
    "            file_path = os.path.join(cluster_path, filename)\n",
    "\n",
    "            # Periksa apakah file adalah CSV\n",
    "            if filename.endswith('.csv'):\n",
    "                print(f\"Reading file: {filename}\")\n",
    "\n",
    "                # Buka file CSV sebagai DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Lakukan imputasi untuk setiap fitur target\n",
    "                for target_feature, predictor_features in imputation_dict.items():\n",
    "                    # Pastikan semua fitur prediktor ada di DataFrame\n",
    "                    if all(feature in df.columns for feature in predictor_features):\n",
    "                        df = impute_feature(df, target_feature, predictor_features)\n",
    "                    else:\n",
    "                        print(f\"Skipping imputation for {target_feature}: missing predictors in {filename}\")\n",
    "\n",
    "                # Simpan kembali file CSV yang telah diimputasi\n",
    "                df.to_csv(file_path, index=False)\n",
    "                print(f\"Saved imputed file: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 JOIN EACH CLUSTER DATASET TO EACH CLASS DATASET** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged dataset: dataset_cluster_class\\merged_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "main_folder = \"dataset_cluster_class\"  # Ganti dengan nama folder utama jika berbeda\n",
    "merged_df_list = []  # List untuk menyimpan DataFrame sebelum digabung\n",
    "\n",
    "# Iterasi setiap subfolder (cluster)\n",
    "for cluster_folder in os.listdir(main_folder):\n",
    "    cluster_path = os.path.join(main_folder, cluster_folder)\n",
    "\n",
    "    # Periksa apakah path adalah folder\n",
    "    if os.path.isdir(cluster_path):\n",
    "        # print(f\"Processing folder: {cluster_folder}\")\n",
    "\n",
    "        # Iterasi setiap file dalam folder cluster\n",
    "        for filename in os.listdir(cluster_path):\n",
    "            file_path = os.path.join(cluster_path, filename)\n",
    "\n",
    "            # Periksa apakah file adalah CSV\n",
    "            if filename.endswith('.csv'):\n",
    "                # print(f\"Reading file: {filename}\")\n",
    "\n",
    "                # Buka file CSV sebagai DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Tambahkan ke daftar DataFrame\n",
    "                merged_df_list.append(df)\n",
    "\n",
    "# Gabungkan semua DataFrame dalam daftar\n",
    "if merged_df_list:\n",
    "    merged_df = pd.concat(merged_df_list, ignore_index=True)\n",
    "\n",
    "    # Simpan sebagai satu file CSV gabungan\n",
    "    merged_csv_path = os.path.join(main_folder, \"merged_dataset.csv\")\n",
    "    merged_df.to_csv(merged_csv_path, index=False)\n",
    "    print(f\"Saved merged dataset: {merged_csv_path}\")\n",
    "else:\n",
    "    print(\"No CSV files found to merge.\")\n",
    "\n",
    "merged_df = merged_df[[i for i in merged_df.columns if \"outlier\" not in i]]\n",
    "\n",
    "lithology_code = merged_df['Lithology_code'].dropna().unique()  # Ambil semua cluster unik\n",
    "\n",
    "# Buat dictionary untuk menyimpan DataFrame tiap cluster\n",
    "lithology_df = {}\n",
    "\n",
    "for code in lithology_code:\n",
    "    lithology_df[code] = merged_df[merged_df['Lithology_code'] == code].copy()\n",
    "    \n",
    "# Buat folder utama untuk menyimpan dataset per cluster\n",
    "output_folder = 'dataset_lithology'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterasi setiap cluster dan simpan sebagai file CSV\n",
    "for code, df in lithology_df.items():\n",
    "    # Tentukan nama file dengan format \"(nama_code)_dataset.csv\"\n",
    "    filename = f\"{code}_dataset.csv\"\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "    # Simpan DataFrame ke CSV\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 FILL NAN VALUE WITH KNN IN EACH CLASS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: 30000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 30000.0_dataset.csv\n",
      "Reading file: 65000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65000.0_dataset.csv\n",
      "Reading file: 65030.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 65030.0_dataset.csv\n",
      "Reading file: 70000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70000.0_dataset.csv\n",
      "Reading file: 70032.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 70032.0_dataset.csv\n",
      "Reading file: 74000.0_dataset.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 74000.0_dataset.csv\n",
      "Reading file: 80000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 80000.0_dataset.csv\n",
      "Reading file: 86000.0_dataset.csv\n",
      "Imputing DTC using ['RHOB', 'NPHI', 'DEPT'] with KNN...\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "Imputing CALI using ['DEPT', 'BS'] with KNN...\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 86000.0_dataset.csv\n",
      "Reading file: 88000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "No NaN values in ROP. Skipping imputation.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 88000.0_dataset.csv\n",
      "Reading file: 90000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "Imputing CALI using ['DEPT', 'BS'] with KNN...\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 90000.0_dataset.csv\n",
      "Reading file: 93000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Skipping ROP: 100% NaN.\n",
      "No NaN values in NPHI. Skipping imputation.\n",
      "Saved imputed file: 93000.0_dataset.csv\n",
      "Reading file: 99000.0_dataset.csv\n",
      "No NaN values in DTC. Skipping imputation.\n",
      "Imputing RHOB using ['NPHI', 'DTC', 'DEPT'] with KNN...\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "Imputing DRHO using ['NPHI', 'DEPT'] with KNN...\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "Imputing NPHI using ['RHOB', 'DTC', 'DEPT', 'CALI'] with KNN...\n",
      "Saved imputed file: 99000.0_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "main_folder = 'dataset_lithology'\n",
    "\n",
    "# Iterate through files in the main folder\n",
    "for filename in os.listdir(main_folder):\n",
    "    file_path = os.path.join(main_folder, filename)\n",
    "    \n",
    "    # Check if file is CSV\n",
    "    if filename.endswith('.csv'):\n",
    "        print(f\"Reading file: {filename}\")\n",
    "\n",
    "        # Read CSV as DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Perform imputation for each target feature\n",
    "        for target_feature, predictor_features in imputation_dict.items():\n",
    "            # Make sure all predictor features exist in DataFrame\n",
    "            if all(feature in df.columns for feature in predictor_features):\n",
    "                df = impute_feature(df, target_feature, predictor_features)\n",
    "            else:\n",
    "                print(f\"Skipping imputation for {target_feature}: missing predictors in {filename}\")\n",
    "\n",
    "        # Save back the imputed CSV file\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Saved imputed file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged dataset: ./dataset/cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "main_folder = \"dataset_lithology\"  # Main folder containing lithology CSV files\n",
    "merged_df_list = []  # List to store DataFrames before merging\n",
    "\n",
    "# Iterate through files in the main folder\n",
    "for filename in os.listdir(main_folder):\n",
    "    file_path = os.path.join(main_folder, filename)\n",
    "\n",
    "    # Check if file is CSV\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read CSV as DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        merged_df_list.append(df)\n",
    "\n",
    "# Merge all DataFrames in the list\n",
    "if merged_df_list:\n",
    "    merged_df = pd.concat(merged_df_list, ignore_index=True)\n",
    "\n",
    "    # Save as one merged CSV file\n",
    "    merged_csv_path = \"./dataset/cleaned_dataset.csv\"\n",
    "    merged_df.to_csv(merged_csv_path, index=False)\n",
    "    merged_df.to_csv(\"./dataset/cleaned_dataset.csv\", index=False)\n",
    "    print(f\"Saved merged dataset: {merged_csv_path}\")\n",
    "else:\n",
    "    print(\"No CSV files found to merge.\")\n",
    "merged_df.to_csv(merged_csv_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.4 CLEANING ALL NAN VALUE IN ALL DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values in DTC. Skipping imputation.\n",
      "No NaN values in RHOB. Skipping imputation.\n",
      "No NaN values in GR. Skipping imputation.\n",
      "Using Linear Regression for CALI imputations with BS...\n",
      "No NaN values in CALI. Skipping imputation.\n",
      "No NaN values in DRHO. Skipping imputation.\n",
      "Imputing ROP using ['NPHI', 'DEPT', 'CALI'] with KNN...\n",
      "No NaN values in NPHI. Skipping imputation.\n"
     ]
    }
   ],
   "source": [
    "# Lakukan imputasi untuk setiap fitur target\n",
    "for target_feature, predictor_features in imputation_dict.items():\n",
    "    # Pastikan semua fitur prediktor ada di DataFrame\n",
    "    if all(feature in df.columns for feature in predictor_features):\n",
    "        cleaned_dataset = impute_feature(merged_df, target_feature, predictor_features)\n",
    "    else:\n",
    "        print(f\"Skipping imputation for {target_feature}: missing predictors in {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. MODELLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "X_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DEPT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DTC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CALI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lithology_code",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e7c94363-6a59-42a0-973e-c00f81089cf0",
       "rows": [
        [
         "0",
         "455221.34375",
         "6533321.5",
         "2712.4600015",
         "0.2183177024",
         "71.954612732",
         "2.2572171688",
         "58.311519623",
         "14.6664505",
         "30000.0"
        ],
        [
         "1",
         "455221.34375",
         "6533321.5",
         "2726.5960015",
         "0.0854552164999999",
         "59.16765213",
         "2.5486149788",
         "88.030212402",
         "12.509160042",
         "30000.0"
        ],
        [
         "2",
         "455221.34375",
         "6533321.5",
         "2726.7480015",
         "0.1140174568",
         "60.975471497",
         "2.5182976723",
         "86.302810669",
         "12.547708511",
         "30000.0"
        ],
        [
         "3",
         "455221.34375",
         "6533321.5",
         "2726.9000015",
         "0.1478745787999999",
         "62.972198486",
         "2.4923596382",
         "79.648368835",
         "12.620093346",
         "30000.0"
        ],
        [
         "4",
         "455221.34375",
         "6533321.5",
         "2727.0520015",
         "0.1808652878",
         "64.157539368",
         "2.4702837467",
         "67.485961914",
         "12.537360191",
         "30000.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>DTC</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>CALI</th>\n",
       "      <th>Lithology_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2712.460002</td>\n",
       "      <td>0.218318</td>\n",
       "      <td>71.954613</td>\n",
       "      <td>2.257217</td>\n",
       "      <td>58.311520</td>\n",
       "      <td>14.666450</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2726.596002</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>59.167652</td>\n",
       "      <td>2.548615</td>\n",
       "      <td>88.030212</td>\n",
       "      <td>12.509160</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2726.748002</td>\n",
       "      <td>0.114017</td>\n",
       "      <td>60.975471</td>\n",
       "      <td>2.518298</td>\n",
       "      <td>86.302811</td>\n",
       "      <td>12.547709</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2726.900002</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>62.972198</td>\n",
       "      <td>2.492360</td>\n",
       "      <td>79.648369</td>\n",
       "      <td>12.620093</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>455221.34375</td>\n",
       "      <td>6533321.5</td>\n",
       "      <td>2727.052002</td>\n",
       "      <td>0.180865</td>\n",
       "      <td>64.157539</td>\n",
       "      <td>2.470284</td>\n",
       "      <td>67.485962</td>\n",
       "      <td>12.537360</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X_LOC      Y_LOC         DEPT      NPHI        DTC      RHOB  \\\n",
       "0  455221.34375  6533321.5  2712.460002  0.218318  71.954613  2.257217   \n",
       "1  455221.34375  6533321.5  2726.596002  0.085455  59.167652  2.548615   \n",
       "2  455221.34375  6533321.5  2726.748002  0.114017  60.975471  2.518298   \n",
       "3  455221.34375  6533321.5  2726.900002  0.147875  62.972198  2.492360   \n",
       "4  455221.34375  6533321.5  2727.052002  0.180865  64.157539  2.470284   \n",
       "\n",
       "          GR       CALI  Lithology_code  \n",
       "0  58.311520  14.666450         30000.0  \n",
       "1  88.030212  12.509160         30000.0  \n",
       "2  86.302811  12.547709         30000.0  \n",
       "3  79.648369  12.620093         30000.0  \n",
       "4  67.485962  12.537360         30000.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_dataset = pd.read_csv(\"./dataset/cleaned_dataset.csv\")\n",
    "training_dataset = training_dataset[['X_LOC','Y_LOC','DEPT','NPHI','DTC','RHOB','GR','CALI','Lithology_code']]\n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83012_row9_col1, #T_83012_row13_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83012\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_83012_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_83012_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_83012_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_83012_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_83012_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_83012_row1_col1\" class=\"data row1 col1\" >Lithology_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_83012_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_83012_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_83012_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_83012_row3_col1\" class=\"data row3 col1\" >30000.0: 0, 65000.0: 1, 65030.0: 2, 70000.0: 3, 70032.0: 4, 74000.0: 5, 80000.0: 6, 86000.0: 7, 88000.0: 8, 90000.0: 9, 93000.0: 10, 99000.0: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_83012_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_83012_row4_col1\" class=\"data row4 col1\" >(199740, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_83012_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_83012_row5_col1\" class=\"data row5 col1\" >(199740, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_83012_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_83012_row6_col1\" class=\"data row6 col1\" >(139818, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_83012_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_83012_row7_col1\" class=\"data row7 col1\" >(59922, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_83012_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_83012_row8_col1\" class=\"data row8 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_83012_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_83012_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_83012_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_83012_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_83012_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_83012_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_83012_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_83012_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_83012_row13_col0\" class=\"data row13 col0\" >Normalize</td>\n",
       "      <td id=\"T_83012_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_83012_row14_col0\" class=\"data row14 col0\" >Normalize method</td>\n",
       "      <td id=\"T_83012_row14_col1\" class=\"data row14 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_83012_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_83012_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_83012_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_83012_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_83012_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_83012_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_83012_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_83012_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_83012_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_83012_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_83012_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_83012_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83012_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_83012_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_83012_row21_col1\" class=\"data row21 col1\" >5e47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19911baf8b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9458 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a9458_row0_col0, #T_a9458_row1_col0, #T_a9458_row1_col1, #T_a9458_row1_col2, #T_a9458_row1_col3, #T_a9458_row1_col4, #T_a9458_row1_col5, #T_a9458_row1_col6, #T_a9458_row1_col7, #T_a9458_row2_col0, #T_a9458_row2_col1, #T_a9458_row2_col2, #T_a9458_row2_col3, #T_a9458_row2_col4, #T_a9458_row2_col5, #T_a9458_row2_col6, #T_a9458_row2_col7, #T_a9458_row3_col0, #T_a9458_row3_col1, #T_a9458_row3_col2, #T_a9458_row3_col3, #T_a9458_row3_col4, #T_a9458_row3_col5, #T_a9458_row3_col6, #T_a9458_row3_col7, #T_a9458_row4_col0, #T_a9458_row4_col1, #T_a9458_row4_col2, #T_a9458_row4_col3, #T_a9458_row4_col4, #T_a9458_row4_col5, #T_a9458_row4_col6, #T_a9458_row4_col7, #T_a9458_row5_col0, #T_a9458_row5_col1, #T_a9458_row5_col2, #T_a9458_row5_col3, #T_a9458_row5_col4, #T_a9458_row5_col5, #T_a9458_row5_col6, #T_a9458_row5_col7, #T_a9458_row6_col0, #T_a9458_row6_col1, #T_a9458_row6_col2, #T_a9458_row6_col3, #T_a9458_row6_col4, #T_a9458_row6_col5, #T_a9458_row6_col6, #T_a9458_row6_col7, #T_a9458_row7_col0, #T_a9458_row7_col1, #T_a9458_row7_col2, #T_a9458_row7_col3, #T_a9458_row7_col4, #T_a9458_row7_col5, #T_a9458_row7_col6, #T_a9458_row7_col7, #T_a9458_row8_col0, #T_a9458_row8_col1, #T_a9458_row8_col2, #T_a9458_row8_col3, #T_a9458_row8_col4, #T_a9458_row8_col5, #T_a9458_row8_col6, #T_a9458_row8_col7, #T_a9458_row9_col0, #T_a9458_row9_col1, #T_a9458_row9_col2, #T_a9458_row9_col3, #T_a9458_row9_col4, #T_a9458_row9_col5, #T_a9458_row9_col6, #T_a9458_row9_col7, #T_a9458_row10_col0, #T_a9458_row10_col1, #T_a9458_row10_col2, #T_a9458_row10_col3, #T_a9458_row10_col4, #T_a9458_row10_col5, #T_a9458_row10_col6, #T_a9458_row10_col7, #T_a9458_row11_col0, #T_a9458_row11_col1, #T_a9458_row11_col2, #T_a9458_row11_col3, #T_a9458_row11_col4, #T_a9458_row11_col5, #T_a9458_row11_col6, #T_a9458_row11_col7, #T_a9458_row12_col0, #T_a9458_row12_col1, #T_a9458_row12_col2, #T_a9458_row12_col3, #T_a9458_row12_col4, #T_a9458_row12_col5, #T_a9458_row12_col6, #T_a9458_row12_col7, #T_a9458_row13_col0, #T_a9458_row13_col1, #T_a9458_row13_col2, #T_a9458_row13_col3, #T_a9458_row13_col4, #T_a9458_row13_col5, #T_a9458_row13_col6, #T_a9458_row13_col7, #T_a9458_row14_col0, #T_a9458_row14_col1, #T_a9458_row14_col2, #T_a9458_row14_col3, #T_a9458_row14_col4, #T_a9458_row14_col5, #T_a9458_row14_col6, #T_a9458_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a9458_row0_col1, #T_a9458_row0_col2, #T_a9458_row0_col3, #T_a9458_row0_col4, #T_a9458_row0_col5, #T_a9458_row0_col6, #T_a9458_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_a9458_row0_col8, #T_a9458_row1_col8, #T_a9458_row2_col8, #T_a9458_row3_col8, #T_a9458_row4_col8, #T_a9458_row5_col8, #T_a9458_row6_col8, #T_a9458_row7_col8, #T_a9458_row8_col8, #T_a9458_row9_col8, #T_a9458_row10_col8, #T_a9458_row11_col8, #T_a9458_row12_col8, #T_a9458_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_a9458_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9458\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9458_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_a9458_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_a9458_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_a9458_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_a9458_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_a9458_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_a9458_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_a9458_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_a9458_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_a9458_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_a9458_row0_col1\" class=\"data row0 col1\" >0.9743</td>\n",
       "      <td id=\"T_a9458_row0_col2\" class=\"data row0 col2\" >0.9986</td>\n",
       "      <td id=\"T_a9458_row0_col3\" class=\"data row0 col3\" >0.9743</td>\n",
       "      <td id=\"T_a9458_row0_col4\" class=\"data row0 col4\" >0.9741</td>\n",
       "      <td id=\"T_a9458_row0_col5\" class=\"data row0 col5\" >0.9740</td>\n",
       "      <td id=\"T_a9458_row0_col6\" class=\"data row0 col6\" >0.9582</td>\n",
       "      <td id=\"T_a9458_row0_col7\" class=\"data row0 col7\" >0.9582</td>\n",
       "      <td id=\"T_a9458_row0_col8\" class=\"data row0 col8\" >1.2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_a9458_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_a9458_row1_col1\" class=\"data row1 col1\" >0.9710</td>\n",
       "      <td id=\"T_a9458_row1_col2\" class=\"data row1 col2\" >0.9981</td>\n",
       "      <td id=\"T_a9458_row1_col3\" class=\"data row1 col3\" >0.9710</td>\n",
       "      <td id=\"T_a9458_row1_col4\" class=\"data row1 col4\" >0.9709</td>\n",
       "      <td id=\"T_a9458_row1_col5\" class=\"data row1 col5\" >0.9708</td>\n",
       "      <td id=\"T_a9458_row1_col6\" class=\"data row1 col6\" >0.9529</td>\n",
       "      <td id=\"T_a9458_row1_col7\" class=\"data row1 col7\" >0.9530</td>\n",
       "      <td id=\"T_a9458_row1_col8\" class=\"data row1 col8\" >4.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row2\" class=\"row_heading level0 row2\" >xgboost</th>\n",
       "      <td id=\"T_a9458_row2_col0\" class=\"data row2 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_a9458_row2_col1\" class=\"data row2 col1\" >0.9610</td>\n",
       "      <td id=\"T_a9458_row2_col2\" class=\"data row2 col2\" >0.9969</td>\n",
       "      <td id=\"T_a9458_row2_col3\" class=\"data row2 col3\" >0.9610</td>\n",
       "      <td id=\"T_a9458_row2_col4\" class=\"data row2 col4\" >0.9606</td>\n",
       "      <td id=\"T_a9458_row2_col5\" class=\"data row2 col5\" >0.9605</td>\n",
       "      <td id=\"T_a9458_row2_col6\" class=\"data row2 col6\" >0.9365</td>\n",
       "      <td id=\"T_a9458_row2_col7\" class=\"data row2 col7\" >0.9366</td>\n",
       "      <td id=\"T_a9458_row2_col8\" class=\"data row2 col8\" >2.6550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row3\" class=\"row_heading level0 row3\" >knn</th>\n",
       "      <td id=\"T_a9458_row3_col0\" class=\"data row3 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_a9458_row3_col1\" class=\"data row3 col1\" >0.9514</td>\n",
       "      <td id=\"T_a9458_row3_col2\" class=\"data row3 col2\" >0.9890</td>\n",
       "      <td id=\"T_a9458_row3_col3\" class=\"data row3 col3\" >0.9514</td>\n",
       "      <td id=\"T_a9458_row3_col4\" class=\"data row3 col4\" >0.9508</td>\n",
       "      <td id=\"T_a9458_row3_col5\" class=\"data row3 col5\" >0.9509</td>\n",
       "      <td id=\"T_a9458_row3_col6\" class=\"data row3 col6\" >0.9208</td>\n",
       "      <td id=\"T_a9458_row3_col7\" class=\"data row3 col7\" >0.9209</td>\n",
       "      <td id=\"T_a9458_row3_col8\" class=\"data row3 col8\" >1.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row4\" class=\"row_heading level0 row4\" >dt</th>\n",
       "      <td id=\"T_a9458_row4_col0\" class=\"data row4 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_a9458_row4_col1\" class=\"data row4 col1\" >0.9499</td>\n",
       "      <td id=\"T_a9458_row4_col2\" class=\"data row4 col2\" >0.9620</td>\n",
       "      <td id=\"T_a9458_row4_col3\" class=\"data row4 col3\" >0.9499</td>\n",
       "      <td id=\"T_a9458_row4_col4\" class=\"data row4 col4\" >0.9500</td>\n",
       "      <td id=\"T_a9458_row4_col5\" class=\"data row4 col5\" >0.9499</td>\n",
       "      <td id=\"T_a9458_row4_col6\" class=\"data row4 col6\" >0.9191</td>\n",
       "      <td id=\"T_a9458_row4_col7\" class=\"data row4 col7\" >0.9191</td>\n",
       "      <td id=\"T_a9458_row4_col8\" class=\"data row4 col8\" >0.3620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row5\" class=\"row_heading level0 row5\" >lightgbm</th>\n",
       "      <td id=\"T_a9458_row5_col0\" class=\"data row5 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_a9458_row5_col1\" class=\"data row5 col1\" >0.8812</td>\n",
       "      <td id=\"T_a9458_row5_col2\" class=\"data row5 col2\" >0.9301</td>\n",
       "      <td id=\"T_a9458_row5_col3\" class=\"data row5 col3\" >0.8812</td>\n",
       "      <td id=\"T_a9458_row5_col4\" class=\"data row5 col4\" >0.8825</td>\n",
       "      <td id=\"T_a9458_row5_col5\" class=\"data row5 col5\" >0.8808</td>\n",
       "      <td id=\"T_a9458_row5_col6\" class=\"data row5 col6\" >0.8083</td>\n",
       "      <td id=\"T_a9458_row5_col7\" class=\"data row5 col7\" >0.8086</td>\n",
       "      <td id=\"T_a9458_row5_col8\" class=\"data row5 col8\" >3.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row6\" class=\"row_heading level0 row6\" >gbc</th>\n",
       "      <td id=\"T_a9458_row6_col0\" class=\"data row6 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_a9458_row6_col1\" class=\"data row6 col1\" >0.8221</td>\n",
       "      <td id=\"T_a9458_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row6_col3\" class=\"data row6 col3\" >0.8221</td>\n",
       "      <td id=\"T_a9458_row6_col4\" class=\"data row6 col4\" >0.8299</td>\n",
       "      <td id=\"T_a9458_row6_col5\" class=\"data row6 col5\" >0.8191</td>\n",
       "      <td id=\"T_a9458_row6_col6\" class=\"data row6 col6\" >0.7643</td>\n",
       "      <td id=\"T_a9458_row6_col7\" class=\"data row6 col7\" >0.7644</td>\n",
       "      <td id=\"T_a9458_row6_col8\" class=\"data row6 col8\" >78.6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row7\" class=\"row_heading level0 row7\" >qda</th>\n",
       "      <td id=\"T_a9458_row7_col0\" class=\"data row7 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_a9458_row7_col1\" class=\"data row7 col1\" >0.7654</td>\n",
       "      <td id=\"T_a9458_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row7_col3\" class=\"data row7 col3\" >0.7654</td>\n",
       "      <td id=\"T_a9458_row7_col4\" class=\"data row7 col4\" >0.7549</td>\n",
       "      <td id=\"T_a9458_row7_col5\" class=\"data row7 col5\" >0.7537</td>\n",
       "      <td id=\"T_a9458_row7_col6\" class=\"data row7 col6\" >0.6087</td>\n",
       "      <td id=\"T_a9458_row7_col7\" class=\"data row7 col7\" >0.6112</td>\n",
       "      <td id=\"T_a9458_row7_col8\" class=\"data row7 col8\" >0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row8\" class=\"row_heading level0 row8\" >lr</th>\n",
       "      <td id=\"T_a9458_row8_col0\" class=\"data row8 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_a9458_row8_col1\" class=\"data row8 col1\" >0.7569</td>\n",
       "      <td id=\"T_a9458_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row8_col3\" class=\"data row8 col3\" >0.7569</td>\n",
       "      <td id=\"T_a9458_row8_col4\" class=\"data row8 col4\" >0.7149</td>\n",
       "      <td id=\"T_a9458_row8_col5\" class=\"data row8 col5\" >0.7193</td>\n",
       "      <td id=\"T_a9458_row8_col6\" class=\"data row8 col6\" >0.5680</td>\n",
       "      <td id=\"T_a9458_row8_col7\" class=\"data row8 col7\" >0.5801</td>\n",
       "      <td id=\"T_a9458_row8_col8\" class=\"data row8 col8\" >3.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row9\" class=\"row_heading level0 row9\" >lda</th>\n",
       "      <td id=\"T_a9458_row9_col0\" class=\"data row9 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_a9458_row9_col1\" class=\"data row9 col1\" >0.7427</td>\n",
       "      <td id=\"T_a9458_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row9_col3\" class=\"data row9 col3\" >0.7427</td>\n",
       "      <td id=\"T_a9458_row9_col4\" class=\"data row9 col4\" >0.6971</td>\n",
       "      <td id=\"T_a9458_row9_col5\" class=\"data row9 col5\" >0.7057</td>\n",
       "      <td id=\"T_a9458_row9_col6\" class=\"data row9 col6\" >0.5441</td>\n",
       "      <td id=\"T_a9458_row9_col7\" class=\"data row9 col7\" >0.5562</td>\n",
       "      <td id=\"T_a9458_row9_col8\" class=\"data row9 col8\" >0.0820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_a9458_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_a9458_row10_col1\" class=\"data row10 col1\" >0.7237</td>\n",
       "      <td id=\"T_a9458_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row10_col3\" class=\"data row10 col3\" >0.7237</td>\n",
       "      <td id=\"T_a9458_row10_col4\" class=\"data row10 col4\" >0.6943</td>\n",
       "      <td id=\"T_a9458_row10_col5\" class=\"data row10 col5\" >0.6753</td>\n",
       "      <td id=\"T_a9458_row10_col6\" class=\"data row10 col6\" >0.4869</td>\n",
       "      <td id=\"T_a9458_row10_col7\" class=\"data row10 col7\" >0.5176</td>\n",
       "      <td id=\"T_a9458_row10_col8\" class=\"data row10 col8\" >0.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row11\" class=\"row_heading level0 row11\" >ada</th>\n",
       "      <td id=\"T_a9458_row11_col0\" class=\"data row11 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_a9458_row11_col1\" class=\"data row11 col1\" >0.6741</td>\n",
       "      <td id=\"T_a9458_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row11_col3\" class=\"data row11 col3\" >0.6741</td>\n",
       "      <td id=\"T_a9458_row11_col4\" class=\"data row11 col4\" >0.5772</td>\n",
       "      <td id=\"T_a9458_row11_col5\" class=\"data row11 col5\" >0.6075</td>\n",
       "      <td id=\"T_a9458_row11_col6\" class=\"data row11 col6\" >0.3790</td>\n",
       "      <td id=\"T_a9458_row11_col7\" class=\"data row11 col7\" >0.4058</td>\n",
       "      <td id=\"T_a9458_row11_col8\" class=\"data row11 col8\" >1.9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row12\" class=\"row_heading level0 row12\" >ridge</th>\n",
       "      <td id=\"T_a9458_row12_col0\" class=\"data row12 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_a9458_row12_col1\" class=\"data row12 col1\" >0.6711</td>\n",
       "      <td id=\"T_a9458_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row12_col3\" class=\"data row12 col3\" >0.6711</td>\n",
       "      <td id=\"T_a9458_row12_col4\" class=\"data row12 col4\" >0.5473</td>\n",
       "      <td id=\"T_a9458_row12_col5\" class=\"data row12 col5\" >0.5916</td>\n",
       "      <td id=\"T_a9458_row12_col6\" class=\"data row12 col6\" >0.3497</td>\n",
       "      <td id=\"T_a9458_row12_col7\" class=\"data row12 col7\" >0.3892</td>\n",
       "      <td id=\"T_a9458_row12_col8\" class=\"data row12 col8\" >0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "      <td id=\"T_a9458_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_a9458_row13_col1\" class=\"data row13 col1\" >0.6592</td>\n",
       "      <td id=\"T_a9458_row13_col2\" class=\"data row13 col2\" >0.8477</td>\n",
       "      <td id=\"T_a9458_row13_col3\" class=\"data row13 col3\" >0.6592</td>\n",
       "      <td id=\"T_a9458_row13_col4\" class=\"data row13 col4\" >0.6822</td>\n",
       "      <td id=\"T_a9458_row13_col5\" class=\"data row13 col5\" >0.6486</td>\n",
       "      <td id=\"T_a9458_row13_col6\" class=\"data row13 col6\" >0.4435</td>\n",
       "      <td id=\"T_a9458_row13_col7\" class=\"data row13 col7\" >0.4498</td>\n",
       "      <td id=\"T_a9458_row13_col8\" class=\"data row13 col8\" >0.0650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9458_level0_row14\" class=\"row_heading level0 row14\" >dummy</th>\n",
       "      <td id=\"T_a9458_row14_col0\" class=\"data row14 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_a9458_row14_col1\" class=\"data row14 col1\" >0.5810</td>\n",
       "      <td id=\"T_a9458_row14_col2\" class=\"data row14 col2\" >0.5000</td>\n",
       "      <td id=\"T_a9458_row14_col3\" class=\"data row14 col3\" >0.5810</td>\n",
       "      <td id=\"T_a9458_row14_col4\" class=\"data row14 col4\" >0.3376</td>\n",
       "      <td id=\"T_a9458_row14_col5\" class=\"data row14 col5\" >0.4270</td>\n",
       "      <td id=\"T_a9458_row14_col6\" class=\"data row14 col6\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row14_col7\" class=\"data row14 col7\" >0.0000</td>\n",
       "      <td id=\"T_a9458_row14_col8\" class=\"data row14 col8\" >0.0620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19913c129d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset (ganti dengan dataset yang sesuai)\n",
    "data = training_dataset.copy()\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "target_column = \"Lithology_code\"  # Ganti dengan nama kolom target\n",
    "\n",
    "# Split dataset into train and test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setup PyCaret\n",
    "clf = setup(train_data, target=target_column, normalize=True, session_id=42)\n",
    "\n",
    "# Compare models and find the best one\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. EVALUATION AND TUNNING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd03a_row10_col0, #T_fd03a_row10_col1, #T_fd03a_row10_col2, #T_fd03a_row10_col3, #T_fd03a_row10_col4, #T_fd03a_row10_col5, #T_fd03a_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd03a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd03a_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_fd03a_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_fd03a_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_fd03a_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_fd03a_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_fd03a_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_fd03a_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fd03a_row0_col0\" class=\"data row0 col0\" >0.8214</td>\n",
       "      <td id=\"T_fd03a_row0_col1\" class=\"data row0 col1\" >0.9719</td>\n",
       "      <td id=\"T_fd03a_row0_col2\" class=\"data row0 col2\" >0.8214</td>\n",
       "      <td id=\"T_fd03a_row0_col3\" class=\"data row0 col3\" >0.8449</td>\n",
       "      <td id=\"T_fd03a_row0_col4\" class=\"data row0 col4\" >0.7894</td>\n",
       "      <td id=\"T_fd03a_row0_col5\" class=\"data row0 col5\" >0.6747</td>\n",
       "      <td id=\"T_fd03a_row0_col6\" class=\"data row0 col6\" >0.6979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fd03a_row1_col0\" class=\"data row1 col0\" >0.8288</td>\n",
       "      <td id=\"T_fd03a_row1_col1\" class=\"data row1 col1\" >0.9723</td>\n",
       "      <td id=\"T_fd03a_row1_col2\" class=\"data row1 col2\" >0.8288</td>\n",
       "      <td id=\"T_fd03a_row1_col3\" class=\"data row1 col3\" >0.8514</td>\n",
       "      <td id=\"T_fd03a_row1_col4\" class=\"data row1 col4\" >0.7970</td>\n",
       "      <td id=\"T_fd03a_row1_col5\" class=\"data row1 col5\" >0.6892</td>\n",
       "      <td id=\"T_fd03a_row1_col6\" class=\"data row1 col6\" >0.7114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fd03a_row2_col0\" class=\"data row2 col0\" >0.8228</td>\n",
       "      <td id=\"T_fd03a_row2_col1\" class=\"data row2 col1\" >0.9723</td>\n",
       "      <td id=\"T_fd03a_row2_col2\" class=\"data row2 col2\" >0.8228</td>\n",
       "      <td id=\"T_fd03a_row2_col3\" class=\"data row2 col3\" >0.8265</td>\n",
       "      <td id=\"T_fd03a_row2_col4\" class=\"data row2 col4\" >0.7879</td>\n",
       "      <td id=\"T_fd03a_row2_col5\" class=\"data row2 col5\" >0.6773</td>\n",
       "      <td id=\"T_fd03a_row2_col6\" class=\"data row2 col6\" >0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fd03a_row3_col0\" class=\"data row3 col0\" >0.8246</td>\n",
       "      <td id=\"T_fd03a_row3_col1\" class=\"data row3 col1\" >0.9730</td>\n",
       "      <td id=\"T_fd03a_row3_col2\" class=\"data row3 col2\" >0.8246</td>\n",
       "      <td id=\"T_fd03a_row3_col3\" class=\"data row3 col3\" >0.8436</td>\n",
       "      <td id=\"T_fd03a_row3_col4\" class=\"data row3 col4\" >0.7916</td>\n",
       "      <td id=\"T_fd03a_row3_col5\" class=\"data row3 col5\" >0.6801</td>\n",
       "      <td id=\"T_fd03a_row3_col6\" class=\"data row3 col6\" >0.7038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fd03a_row4_col0\" class=\"data row4 col0\" >0.8253</td>\n",
       "      <td id=\"T_fd03a_row4_col1\" class=\"data row4 col1\" >0.9721</td>\n",
       "      <td id=\"T_fd03a_row4_col2\" class=\"data row4 col2\" >0.8253</td>\n",
       "      <td id=\"T_fd03a_row4_col3\" class=\"data row4 col3\" >0.8337</td>\n",
       "      <td id=\"T_fd03a_row4_col4\" class=\"data row4 col4\" >0.7920</td>\n",
       "      <td id=\"T_fd03a_row4_col5\" class=\"data row4 col5\" >0.6819</td>\n",
       "      <td id=\"T_fd03a_row4_col6\" class=\"data row4 col6\" >0.7053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fd03a_row5_col0\" class=\"data row5 col0\" >0.8235</td>\n",
       "      <td id=\"T_fd03a_row5_col1\" class=\"data row5 col1\" >0.9724</td>\n",
       "      <td id=\"T_fd03a_row5_col2\" class=\"data row5 col2\" >0.8235</td>\n",
       "      <td id=\"T_fd03a_row5_col3\" class=\"data row5 col3\" >0.8430</td>\n",
       "      <td id=\"T_fd03a_row5_col4\" class=\"data row5 col4\" >0.7903</td>\n",
       "      <td id=\"T_fd03a_row5_col5\" class=\"data row5 col5\" >0.6778</td>\n",
       "      <td id=\"T_fd03a_row5_col6\" class=\"data row5 col6\" >0.7019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_fd03a_row6_col0\" class=\"data row6 col0\" >0.8249</td>\n",
       "      <td id=\"T_fd03a_row6_col1\" class=\"data row6 col1\" >0.9729</td>\n",
       "      <td id=\"T_fd03a_row6_col2\" class=\"data row6 col2\" >0.8249</td>\n",
       "      <td id=\"T_fd03a_row6_col3\" class=\"data row6 col3\" >0.8430</td>\n",
       "      <td id=\"T_fd03a_row6_col4\" class=\"data row6 col4\" >0.7912</td>\n",
       "      <td id=\"T_fd03a_row6_col5\" class=\"data row6 col5\" >0.6811</td>\n",
       "      <td id=\"T_fd03a_row6_col6\" class=\"data row6 col6\" >0.7044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_fd03a_row7_col0\" class=\"data row7 col0\" >0.8218</td>\n",
       "      <td id=\"T_fd03a_row7_col1\" class=\"data row7 col1\" >0.9720</td>\n",
       "      <td id=\"T_fd03a_row7_col2\" class=\"data row7 col2\" >0.8218</td>\n",
       "      <td id=\"T_fd03a_row7_col3\" class=\"data row7 col3\" >0.8416</td>\n",
       "      <td id=\"T_fd03a_row7_col4\" class=\"data row7 col4\" >0.7896</td>\n",
       "      <td id=\"T_fd03a_row7_col5\" class=\"data row7 col5\" >0.6746</td>\n",
       "      <td id=\"T_fd03a_row7_col6\" class=\"data row7 col6\" >0.6987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_fd03a_row8_col0\" class=\"data row8 col0\" >0.8269</td>\n",
       "      <td id=\"T_fd03a_row8_col1\" class=\"data row8 col1\" >0.9748</td>\n",
       "      <td id=\"T_fd03a_row8_col2\" class=\"data row8 col2\" >0.8269</td>\n",
       "      <td id=\"T_fd03a_row8_col3\" class=\"data row8 col3\" >0.8449</td>\n",
       "      <td id=\"T_fd03a_row8_col4\" class=\"data row8 col4\" >0.7942</td>\n",
       "      <td id=\"T_fd03a_row8_col5\" class=\"data row8 col5\" >0.6857</td>\n",
       "      <td id=\"T_fd03a_row8_col6\" class=\"data row8 col6\" >0.7078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_fd03a_row9_col0\" class=\"data row9 col0\" >0.8233</td>\n",
       "      <td id=\"T_fd03a_row9_col1\" class=\"data row9 col1\" >0.9731</td>\n",
       "      <td id=\"T_fd03a_row9_col2\" class=\"data row9 col2\" >0.8233</td>\n",
       "      <td id=\"T_fd03a_row9_col3\" class=\"data row9 col3\" >0.8430</td>\n",
       "      <td id=\"T_fd03a_row9_col4\" class=\"data row9 col4\" >0.7896</td>\n",
       "      <td id=\"T_fd03a_row9_col5\" class=\"data row9 col5\" >0.6773</td>\n",
       "      <td id=\"T_fd03a_row9_col6\" class=\"data row9 col6\" >0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_fd03a_row10_col0\" class=\"data row10 col0\" >0.8243</td>\n",
       "      <td id=\"T_fd03a_row10_col1\" class=\"data row10 col1\" >0.9727</td>\n",
       "      <td id=\"T_fd03a_row10_col2\" class=\"data row10 col2\" >0.8243</td>\n",
       "      <td id=\"T_fd03a_row10_col3\" class=\"data row10 col3\" >0.8416</td>\n",
       "      <td id=\"T_fd03a_row10_col4\" class=\"data row10 col4\" >0.7913</td>\n",
       "      <td id=\"T_fd03a_row10_col5\" class=\"data row10 col5\" >0.6800</td>\n",
       "      <td id=\"T_fd03a_row10_col6\" class=\"data row10 col6\" >0.7033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd03a_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_fd03a_row11_col0\" class=\"data row11 col0\" >0.0022</td>\n",
       "      <td id=\"T_fd03a_row11_col1\" class=\"data row11 col1\" >0.0008</td>\n",
       "      <td id=\"T_fd03a_row11_col2\" class=\"data row11 col2\" >0.0022</td>\n",
       "      <td id=\"T_fd03a_row11_col3\" class=\"data row11 col3\" >0.0065</td>\n",
       "      <td id=\"T_fd03a_row11_col4\" class=\"data row11 col4\" >0.0025</td>\n",
       "      <td id=\"T_fd03a_row11_col5\" class=\"data row11 col5\" >0.0044</td>\n",
       "      <td id=\"T_fd03a_row11_col6\" class=\"data row11 col6\" >0.0039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19913e11f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5a505f31bd48baab69d32ddf8d86db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6f8e9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6f8e9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6f8e9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_6f8e9_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_6f8e9_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_6f8e9_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_6f8e9_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_6f8e9_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_6f8e9_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6f8e9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6f8e9_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_6f8e9_row0_col1\" class=\"data row0 col1\" >0.9794</td>\n",
       "      <td id=\"T_6f8e9_row0_col2\" class=\"data row0 col2\" >0.9991</td>\n",
       "      <td id=\"T_6f8e9_row0_col3\" class=\"data row0 col3\" >0.9794</td>\n",
       "      <td id=\"T_6f8e9_row0_col4\" class=\"data row0 col4\" >0.9792</td>\n",
       "      <td id=\"T_6f8e9_row0_col5\" class=\"data row0 col5\" >0.9792</td>\n",
       "      <td id=\"T_6f8e9_row0_col6\" class=\"data row0 col6\" >0.9666</td>\n",
       "      <td id=\"T_6f8e9_row0_col7\" class=\"data row0 col7\" >0.9667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x199136d6490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "tuned_model = tune_model(best_model)\n",
    "\n",
    "# Evaluate tuned model\n",
    "evaluate_model(tuned_model)\n",
    "\n",
    "# Finalize the model (optional, jika ingin digunakan untuk prediksi lebih lanjut)\n",
    "final_model = finalize_model(tuned_model)\n",
    "\n",
    "# Predict on test data\n",
    "predictions = predict_model(final_model, data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "save_model(final_model, \"final_lithology_model_2\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEST DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./dataset/Test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pilih fitur untuk analisis (exclude specified columns)\n",
    "exclude_cols = ['Lithology_code', 'X_LOC', 'Y_LOC', 'DEPT', 'Cluster_DBSCAN']\n",
    "numeric_cols = [col for col in test_df.select_dtypes('number').columns if col not in exclude_cols]\n",
    "\n",
    "# Daftar fitur yang TIDAK BOLEH negatif\n",
    "cannot_be_negative = ['NPHI', 'RHOB', 'GR', 'PEF', 'CALI', 'BS', 'ROP', 'MUDWEIGHT', 'RDEP', 'RMED', 'DTC', 'DEPT', 'DEPTH_MD']\n",
    "\n",
    "# Daftar fitur yang BOLEH negatif\n",
    "can_be_negative = ['SP', 'DRHO', 'Z_LOC', 'X_LOC', 'Y_LOC', 'Cluster_DBSCAN']\n",
    "\n",
    "# 2. Definisikan fungsi untuk mendeteksi outlier\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Tentukan lower_bound berdasarkan apakah fitur boleh negatif atau tidak\n",
    "    if column in cannot_be_negative:\n",
    "        # Untuk fitur yang tidak boleh negatif, lower_bound minimal 0\n",
    "        lower_bound = max(Q1 - 1.5 * IQR, 0)\n",
    "    elif column in can_be_negative:\n",
    "        # Untuk fitur yang boleh negatif, lower_bound = Q1 - 1.5 * IQR\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "    else:\n",
    "        # Default: anggap tidak boleh negatif jika tidak diketahui\n",
    "        lower_bound = max(Q1 - 1.5 * IQR, 0)\n",
    "    \n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    is_outlier = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    return is_outlier, lower_bound, upper_bound\n",
    "\n",
    "# Initialize outlier_mask DataFrame\n",
    "outlier_mask = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "# Deteksi outlier untuk setiap kolom numerik\n",
    "for col in numeric_cols:\n",
    "    if test_df[col].notna().any():  # Only process columns with non-null values\n",
    "        is_outlier, lower_bound, upper_bound = detect_outliers(test_df, col)\n",
    "        outlier_mask[f'{col}_is_outlier'] = is_outlier\n",
    "        \n",
    "# Tambahkan status outlier ke DataFrame cluster\n",
    "test_df = test_df.join(outlier_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop melalui semua kolom numerik dan setel nilai outlier menjadi NaN\n",
    "for col in numeric_cols:\n",
    "    outlier_col = f'{col}_is_outlier'\n",
    "    if outlier_col in outlier_mask.columns:\n",
    "        test_df.loc[outlier_mask[outlier_col], col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df = pd.read_csv(\"./dataset/cleaned_dataset.csv\")\n",
    "summary_stats = clean_train_df[['DEPT', 'RHOB', 'GR', 'SP', 'CALI', 'Lithology_code']].groupby(\"Lithology_code\").agg(['mean', 'min', 'max'])\n",
    "summary_stats\n",
    "\n",
    "summary_stats.columns = ['_'.join(col) for col in summary_stats.columns]\n",
    "summary_stats = summary_stats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gr(gr, dept, cali):\n",
    "    for idx, stats in summary_stats.iterrows():\n",
    "        if pd.isna(gr) and (stats['DEPT_min'] <= dept <= stats['DEPT_max'] and stats['CALI_min'] <= cali <= stats['CALI_max']):\n",
    "            return stats['GR_mean']\n",
    "        elif pd.isna(gr) and stats['DEPT_min'] <= dept <= stats['DEPT_max']:\n",
    "            return stats['GR_mean']\n",
    "        else:\n",
    "            return gr\n",
    "        \n",
    "for index, row in test_df.iterrows():\n",
    "    test_df.at[index, \"GR\"] = estimate_gr(\n",
    "        gr = row[\"GR\"], \n",
    "        dept = row[\"DEPT\"], \n",
    "        cali = row[\"CALI\"])\n",
    "    \n",
    "test_df[\"GR\"] = test_df[\"GR\"].fillna(75.091179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cali(gr, dept, cali):\n",
    "    for idx, stats in summary_stats.iterrows():\n",
    "        if pd.isna(cali) and (stats['DEPT_min'] <= dept <= stats['DEPT_max'] and stats['GR_min'] <= gr <= stats['GR_max']):\n",
    "            return stats['CALI_mean']\n",
    "        elif pd.isna(cali) and stats['DEPT_min'] <= dept <= stats['DEPT_max']:\n",
    "            return stats['CALI_mean']\n",
    "        else:\n",
    "            return cali\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    test_df.at[index, \"CALI\"] = estimate_gr(\n",
    "        gr = row[\"GR\"], \n",
    "        dept = row[\"DEPT\"], \n",
    "        cali = row[\"CALI\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definisi hubungan fitur untuk imputasi\n",
    "imputation_dict = {\n",
    "    'DTC': ['RHOB', 'DEPT'],\n",
    "    'RHOB': ['DTC', 'DEPT'],\n",
    "}\n",
    "\n",
    "def impute_feature(df, target_feature, predictor_features):\n",
    "    # Periksa apakah kolom target 100% NaN\n",
    "    if df[target_feature].isna().sum() == len(df):\n",
    "        print(f\"Skipping {target_feature}: 100% NaN.\")\n",
    "        return df  # Kembalikan DataFrame tanpa perubahan\n",
    "    \n",
    "    # Periksa apakah semua kolom prediktor 100% NaN\n",
    "    valid_predictors = [col for col in predictor_features if df[col].isna().sum() < len(df)]\n",
    "    \n",
    "    if len(valid_predictors) == 0:\n",
    "        print(f\"Skipping {target_feature}: All predictor columns are 100% NaN.\")\n",
    "        return df  # Kembalikan DataFrame tanpa perubahan\n",
    "\n",
    "    # Cek apakah ada NaN yang perlu diimputasi di target\n",
    "    if df[target_feature].isna().sum() > 0:\n",
    "        print(f\"Imputing {target_feature} using {valid_predictors}...\")\n",
    "\n",
    "        # Ambil subset data dengan fitur prediktor valid dan target\n",
    "        imputation_data = df[valid_predictors + [target_feature]].copy()\n",
    "\n",
    "        # Standarisasi data\n",
    "        scaler = StandardScaler()\n",
    "        imputation_data_scaled = scaler.fit_transform(imputation_data)\n",
    "\n",
    "        # Terapkan KNN Imputer\n",
    "        imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "        imputed_data_scaled = imputer.fit_transform(imputation_data_scaled)\n",
    "\n",
    "        # Kembalikan ke skala asli\n",
    "        imputed_data = scaler.inverse_transform(imputed_data_scaled)\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=valid_predictors + [target_feature], index=df.index)\n",
    "\n",
    "        # Update DataFrame asli\n",
    "        df[target_feature] = imputed_df[target_feature]\n",
    "    else:\n",
    "        print(f\"No NaN values in {target_feature}. Skipping imputation.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing DTC using ['RHOB', 'DEPT']...\n",
      "Imputing RHOB using ['DTC', 'DEPT']...\n"
     ]
    }
   ],
   "source": [
    "# Lakukan imputasi untuk setiap fitur target\n",
    "for target_feature, predictor_features in imputation_dict.items():\n",
    "    # Pastikan semua fitur prediktor ada di DataFrame\n",
    "    if all(feature in test_df.columns for feature in predictor_features):\n",
    "        df = impute_feature(test_df, target_feature, predictor_features)\n",
    "    else:\n",
    "        print(f\"Skipping imputation for {target_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train_df = df.dropna(subset=['NPHI'])\n",
    "test_df = df[df['NPHI'].isna()]\n",
    "\n",
    "if not test_df.empty:\n",
    "    model = LinearRegression()\n",
    "    predictors = ['RHOB', 'GR', 'DTC', 'CALI']\n",
    "    model.fit(train_df[predictors], train_df['NPHI'])\n",
    "    df.loc[df['NPHI'].isna(), 'NPHI'] = model.predict(test_df[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# Ensure X_LOC and Y_LOC have no missing values\n",
    "df = df.dropna(subset=['X_LOC', 'Y_LOC'])\n",
    "\n",
    "# Create KDTree using valid spatial coordinates\n",
    "coords = df[['X_LOC', 'Y_LOC']].values\n",
    "tree = cKDTree(coords)\n",
    "\n",
    "# Find the 2 nearest neighbors (excluding itself)\n",
    "_, idx = tree.query(coords, k=3)  # k=3 for backup if the first neighbor is missing\n",
    "\n",
    "# Fill missing values using nearest neighbor\n",
    "for col in ['NPHI', 'DTC', 'SP', 'GR', 'RHOB', 'CALI']:\n",
    "    missing_mask = df[col].isna()  # Find missing values\n",
    "    \n",
    "    # Create an empty array to store filled values\n",
    "    filled_values = df[col].values.copy()\n",
    "    \n",
    "    for i, is_missing in enumerate(missing_mask):\n",
    "        if is_missing:\n",
    "            # Check nearest neighbors\n",
    "            for neighbor_idx in idx[i, 1:]:  # Skip self (idx[i, 0] is the same point)\n",
    "                if not np.isnan(df.iloc[neighbor_idx][col]):  # Use first non-NaN neighbor\n",
    "                    filled_values[i] = df.iloc[neighbor_idx][col]\n",
    "                    break  # Stop after finding the first valid neighbor\n",
    "    \n",
    "    # Assign the new filled values\n",
    "    df[col] = filled_values\n",
    "    \n",
    "df.drop(columns='SP', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "X_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DEPT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DTC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CALI",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "64dc9fab-eb02-418c-979f-b446c0381d3d",
       "rows": [
        [
         "0",
         "459853.34375",
         "6560993.0",
         "1348.3104",
         "0.3982659876",
         "133.53703308",
         "2.1313185692",
         "61.177398682",
         "61.177398682"
        ],
        [
         "1",
         "459853.34375",
         "6560993.0",
         "1348.4624",
         "0.3894604743",
         "133.52554321",
         "2.1297767162",
         "63.512332916000005",
         "63.512332916000005"
        ],
        [
         "2",
         "459853.34375",
         "6560993.0",
         "1348.6144",
         "0.3948676586",
         "130.73962402",
         "2.1380815506",
         "63.515834808",
         "63.515834808"
        ],
        [
         "3",
         "459853.34375",
         "6560993.0",
         "1348.7664",
         "0.3893553019",
         "128.07424927",
         "2.1539993286000003",
         "63.15305709800001",
         "63.15305709800001"
        ],
        [
         "4",
         "459853.34375",
         "6560993.0",
         "1348.9184",
         "0.3658084869",
         "121.45492554",
         "2.1409196854",
         "60.224147797",
         "60.224147797"
        ],
        [
         "5",
         "459853.34375",
         "6560993.0",
         "1349.0704",
         "0.3367009759",
         "120.31077576",
         "2.1274247169",
         "54.953533173",
         "54.953533173"
        ],
        [
         "6",
         "459853.375",
         "6560993.0",
         "1349.2224",
         "0.3281388283",
         "120.4462738",
         "2.1274459362",
         "50.045619965",
         "50.045619965"
        ],
        [
         "7",
         "459853.375",
         "6560993.0",
         "1349.3744",
         "0.332711786",
         "124.95762634",
         "2.143819809",
         "47.84729385399999",
         "47.84729385399999"
        ],
        [
         "8",
         "459853.375",
         "6560993.0",
         "1349.5264",
         "0.331598103",
         "130.22608948",
         "2.1541986465000003",
         "47.848007202",
         "47.848007202"
        ],
        [
         "9",
         "459853.375",
         "6560993.0",
         "1349.6784",
         "0.336897254",
         "131.1940918",
         "2.1653189659",
         "47.562538147",
         "47.562538147"
        ],
        [
         "10",
         "459853.375",
         "6560993.0",
         "1349.8304",
         "0.3415088952",
         "133.54637146",
         "2.1555874348",
         "47.310577393",
         "47.310577393"
        ],
        [
         "11",
         "459853.375",
         "6560993.0",
         "1349.9824",
         "0.3569356501",
         "135.83502197",
         "2.1636233330000003",
         "50.139259338",
         "50.139259338"
        ],
        [
         "12",
         "459853.375",
         "6560993.0",
         "1350.1344",
         "0.3640506566",
         "135.23410034",
         "2.1692695618",
         "55.057125092",
         "55.057125092"
        ],
        [
         "13",
         "459853.375",
         "6560993.0",
         "1350.2864",
         "0.3777217865",
         "136.38166809",
         "2.1681799889",
         "61.066688538",
         "61.066688538"
        ],
        [
         "14",
         "459853.375",
         "6560993.0",
         "1350.4384",
         "0.3702547252",
         "136.04484558",
         "2.1472620964",
         "68.219764709",
         "68.219764709"
        ],
        [
         "15",
         "459853.375",
         "6560993.0",
         "1350.5904",
         "0.387018919",
         "135.29240417",
         "2.1279294491",
         "71.350227356",
         "71.350227356"
        ],
        [
         "16",
         "459853.375",
         "6560993.0",
         "1350.7424",
         "0.3726579249000001",
         "134.97872925",
         "2.1302735806",
         "68.68754577600001",
         "68.68754577600001"
        ],
        [
         "17",
         "459853.375",
         "6560993.0",
         "1350.8944",
         "0.3703979254",
         "134.42980957",
         "2.1368122101",
         "64.10558319100001",
         "64.10558319100001"
        ],
        [
         "18",
         "459853.375",
         "6560993.0",
         "1351.0464",
         "0.3488942981",
         "133.99488831",
         "2.1392214298",
         "61.90290451",
         "61.90290451"
        ],
        [
         "19",
         "459853.375",
         "6560993.0",
         "1351.1984",
         "0.3583524227",
         "134.46812439",
         "2.1399059296000003",
         "63.378376007",
         "63.378376007"
        ],
        [
         "20",
         "459853.375",
         "6560993.0",
         "1351.3504",
         "0.3691430688",
         "134.87770081",
         "2.1434788704",
         "65.544189453",
         "65.544189453"
        ],
        [
         "21",
         "459853.375",
         "6560993.0",
         "1351.5024",
         "0.3699320555",
         "135.89590454",
         "2.1366369724000003",
         "65.525527954",
         "65.525527954"
        ],
        [
         "22",
         "459853.375",
         "6560993.0",
         "1351.6544",
         "0.376531601",
         "136.0561676",
         "2.1315047741",
         "65.224250793",
         "65.224250793"
        ],
        [
         "23",
         "459853.375",
         "6560993.0",
         "1351.8064",
         "0.3888573647",
         "136.77656555",
         "2.1170778275",
         "67.432472229",
         "67.432472229"
        ],
        [
         "24",
         "459853.375",
         "6560993.0",
         "1351.9584",
         "0.4035559595",
         "136.97128296",
         "2.1257557869",
         "71.382446289",
         "71.382446289"
        ],
        [
         "25",
         "459853.375",
         "6560993.0",
         "1352.1104",
         "0.3970481157",
         "133.90948486",
         "2.1320636272",
         "74.586830139",
         "74.586830139"
        ],
        [
         "26",
         "459853.375",
         "6560993.0",
         "1352.2624",
         "0.3950758576",
         "130.73629761",
         "2.1388483047",
         "74.639160156",
         "74.639160156"
        ],
        [
         "27",
         "459853.375",
         "6560993.0",
         "1352.4144",
         "0.3800980747",
         "133.38554382",
         "2.1259307861",
         "72.286888123",
         "72.286888123"
        ],
        [
         "28",
         "459853.375",
         "6560993.0",
         "1352.5664",
         "0.3775979877",
         "135.25822449",
         "2.1213116646",
         "69.851913452",
         "69.851913452"
        ],
        [
         "29",
         "459853.375",
         "6560993.0",
         "1352.7184",
         "0.3798067272",
         "136.22349548",
         "2.1317045689",
         "68.37222290000001",
         "68.37222290000001"
        ],
        [
         "30",
         "459853.375",
         "6560993.0",
         "1352.8704",
         "0.3761495352000001",
         "136.71385193",
         "2.1488525867",
         "67.777084351",
         "67.777084351"
        ],
        [
         "31",
         "459853.375",
         "6560993.0",
         "1353.0224",
         "0.3659493923",
         "136.40425109999998",
         "2.1524097919",
         "68.616630554",
         "68.616630554"
        ],
        [
         "32",
         "459853.375",
         "6560993.0",
         "1353.1744",
         "0.3562443256",
         "136.55058289",
         "2.1803004742",
         "69.01183319100001",
         "69.01183319100001"
        ],
        [
         "33",
         "459853.375",
         "6560993.0",
         "1353.3264",
         "0.3530376256",
         "137.61798096",
         "2.1823329926",
         "65.164634705",
         "65.164634705"
        ],
        [
         "34",
         "459853.375",
         "6560993.0",
         "1353.4784",
         "0.3427350223",
         "138.98330688",
         "2.177123785",
         "60.08247757",
         "60.08247757"
        ],
        [
         "35",
         "459853.375",
         "6560993.0",
         "1353.6304",
         "0.3317191303",
         "138.75721741",
         "2.1381585598",
         "58.023643494",
         "58.023643494"
        ],
        [
         "36",
         "459853.375",
         "6560993.0",
         "1353.7824",
         "0.3286095262",
         "138.60649109",
         "2.1212763786",
         "59.19609832800001",
         "59.19609832800001"
        ],
        [
         "37",
         "459853.375",
         "6560993.0",
         "1353.9344",
         "0.3426159024",
         "138.82510376",
         "2.1280837059",
         "62.127174377",
         "62.127174377"
        ],
        [
         "38",
         "459853.375",
         "6560993.0",
         "1354.0864",
         "0.353856653",
         "137.55877686",
         "2.1374804974",
         "63.730678558",
         "63.730678558"
        ],
        [
         "39",
         "459853.375",
         "6560993.0",
         "1354.2384",
         "0.3659427166",
         "137.06524658",
         "2.1614587307",
         "64.551246643",
         "64.551246643"
        ],
        [
         "40",
         "459853.375",
         "6560993.0",
         "1354.3904",
         "0.3696295917",
         "136.28569031",
         "2.1639363766",
         "66.470542908",
         "66.470542908"
        ],
        [
         "41",
         "459853.375",
         "6560993.0",
         "1354.5424",
         "0.3754525483",
         "134.6550293",
         "2.1576011181",
         "69.15342712399999",
         "69.15342712399999"
        ],
        [
         "42",
         "459853.375",
         "6560993.0",
         "1354.6944",
         "0.3690365553",
         "131.21073914",
         "2.1394731998",
         "72.483062744",
         "72.483062744"
        ],
        [
         "43",
         "459853.375",
         "6560993.0",
         "1354.8464",
         "0.3468268812",
         "128.81359863",
         "2.1296560764",
         "73.59035491899999",
         "73.59035491899999"
        ],
        [
         "44",
         "459853.375",
         "6560993.0",
         "1354.9984",
         "0.3191104233",
         "128.87138367",
         "2.1466288567",
         "71.156440735",
         "71.156440735"
        ],
        [
         "45",
         "459853.375",
         "6560993.0",
         "1355.1504",
         "0.297324419",
         "128.31060791",
         "2.1661372185",
         "71.570167542",
         "71.570167542"
        ],
        [
         "46",
         "459853.375",
         "6560993.0",
         "1355.3024",
         "0.3054862618",
         "127.12030792",
         "2.182182312",
         "77.01872253399999",
         "77.01872253399999"
        ],
        [
         "47",
         "459853.375",
         "6560993.0",
         "1355.4544",
         "0.3203628957",
         "127.28440857",
         "2.1794073582",
         "79.360626221",
         "79.360626221"
        ],
        [
         "48",
         "459853.375",
         "6560993.0",
         "1355.6064",
         "0.3359884918",
         "128.11279297",
         "2.1593482494",
         "77.185691833",
         "77.185691833"
        ],
        [
         "49",
         "459853.375",
         "6560993.0",
         "1355.7584",
         "0.3281318247",
         "129.75352478",
         "2.1442036629",
         "76.80357360800001",
         "76.80357360800001"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 114368
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>DTC</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>CALI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459853.34375</td>\n",
       "      <td>6560993.0</td>\n",
       "      <td>1348.310400</td>\n",
       "      <td>0.398266</td>\n",
       "      <td>133.537033</td>\n",
       "      <td>2.131319</td>\n",
       "      <td>61.177399</td>\n",
       "      <td>61.177399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459853.34375</td>\n",
       "      <td>6560993.0</td>\n",
       "      <td>1348.462400</td>\n",
       "      <td>0.389460</td>\n",
       "      <td>133.525543</td>\n",
       "      <td>2.129777</td>\n",
       "      <td>63.512333</td>\n",
       "      <td>63.512333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459853.34375</td>\n",
       "      <td>6560993.0</td>\n",
       "      <td>1348.614400</td>\n",
       "      <td>0.394868</td>\n",
       "      <td>130.739624</td>\n",
       "      <td>2.138082</td>\n",
       "      <td>63.515835</td>\n",
       "      <td>63.515835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459853.34375</td>\n",
       "      <td>6560993.0</td>\n",
       "      <td>1348.766400</td>\n",
       "      <td>0.389355</td>\n",
       "      <td>128.074249</td>\n",
       "      <td>2.153999</td>\n",
       "      <td>63.153057</td>\n",
       "      <td>63.153057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459853.34375</td>\n",
       "      <td>6560993.0</td>\n",
       "      <td>1348.918400</td>\n",
       "      <td>0.365808</td>\n",
       "      <td>121.454926</td>\n",
       "      <td>2.140920</td>\n",
       "      <td>60.224148</td>\n",
       "      <td>60.224148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121782</th>\n",
       "      <td>486205.25000</td>\n",
       "      <td>6853315.0</td>\n",
       "      <td>5005.289975</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>78.761744</td>\n",
       "      <td>2.470152</td>\n",
       "      <td>66.890999</td>\n",
       "      <td>66.890999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121783</th>\n",
       "      <td>486205.31250</td>\n",
       "      <td>6853315.0</td>\n",
       "      <td>5005.441975</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>78.112534</td>\n",
       "      <td>2.479506</td>\n",
       "      <td>66.629593</td>\n",
       "      <td>66.629593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121784</th>\n",
       "      <td>486205.37500</td>\n",
       "      <td>6853315.0</td>\n",
       "      <td>5005.593975</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>77.348389</td>\n",
       "      <td>2.476743</td>\n",
       "      <td>65.412140</td>\n",
       "      <td>65.412140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121785</th>\n",
       "      <td>486205.43750</td>\n",
       "      <td>6853315.0</td>\n",
       "      <td>5005.745975</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>77.315188</td>\n",
       "      <td>2.473132</td>\n",
       "      <td>65.491470</td>\n",
       "      <td>65.491470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121786</th>\n",
       "      <td>486205.50000</td>\n",
       "      <td>6853315.0</td>\n",
       "      <td>5005.897976</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>81.180422</td>\n",
       "      <td>2.459101</td>\n",
       "      <td>64.528580</td>\n",
       "      <td>64.528580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114368 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_LOC      Y_LOC         DEPT      NPHI         DTC      RHOB  \\\n",
       "0       459853.34375  6560993.0  1348.310400  0.398266  133.537033  2.131319   \n",
       "1       459853.34375  6560993.0  1348.462400  0.389460  133.525543  2.129777   \n",
       "2       459853.34375  6560993.0  1348.614400  0.394868  130.739624  2.138082   \n",
       "3       459853.34375  6560993.0  1348.766400  0.389355  128.074249  2.153999   \n",
       "4       459853.34375  6560993.0  1348.918400  0.365808  121.454926  2.140920   \n",
       "...              ...        ...          ...       ...         ...       ...   \n",
       "121782  486205.25000  6853315.0  5005.289975  0.187208   78.761744  2.470152   \n",
       "121783  486205.31250  6853315.0  5005.441975  0.190700   78.112534  2.479506   \n",
       "121784  486205.37500  6853315.0  5005.593975  0.190700   77.348389  2.476743   \n",
       "121785  486205.43750  6853315.0  5005.745975  0.190700   77.315188  2.473132   \n",
       "121786  486205.50000  6853315.0  5005.897976  0.190700   81.180422  2.459101   \n",
       "\n",
       "               GR       CALI  \n",
       "0       61.177399  61.177399  \n",
       "1       63.512333  63.512333  \n",
       "2       63.515835  63.515835  \n",
       "3       63.153057  63.153057  \n",
       "4       60.224148  60.224148  \n",
       "...           ...        ...  \n",
       "121782  66.890999  66.890999  \n",
       "121783  66.629593  66.629593  \n",
       "121784  65.412140  65.412140  \n",
       "121785  65.491470  65.491470  \n",
       "121786  64.528580  64.528580  \n",
       "\n",
       "[114368 rows x 8 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_dataset = df[['X_LOC','Y_LOC','DEPT','NPHI','DTC','RHOB','GR','CALI']]\n",
    "cleaned_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PREDICT TEST DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import load_model\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Muat kembali model\n",
    "loaded_model = load_model('final_lithology_model_2')\n",
    "\n",
    "# Gunakan model yang telah dimuat kembali untuk prediksi\n",
    "test_predictions = predict_model(loaded_model, data=cleaned_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with uuid and predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'uuid': test_df['uuid'],\n",
    "    'prediction_label': test_predictions['prediction_label']\n",
    "})\n",
    "\n",
    "# Map the numerical predictions to lithology names using the mapping from cell 11\n",
    "lithology_mapping = {\n",
    "    30000: \"Sandstone\",\n",
    "    65030: \"Sandstone/Shale\",\n",
    "    65000: \"Shale\",\n",
    "    80000: \"Marl\",\n",
    "    74000: \"Dolomite\",\n",
    "    70000: \"Limestone\",\n",
    "    70032: \"Chalk\",\n",
    "    88000: \"Halite\",\n",
    "    86000: \"Anhydrite\",\n",
    "    99000: \"Tuff\",\n",
    "    90000: \"Coal\",\n",
    "    93000: \"Basement\"\n",
    "}\n",
    "\n",
    "# Add lithology names\n",
    "results_df['label_name'] = results_df['prediction_label'].map(lithology_mapping)\n",
    "\n",
    "# Create final submission DataFrame with only uuid and label_name\n",
    "submission = results_df[['uuid', 'label_name']]\n",
    "submission.to_csv('submission_7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_name\n",
       "Shale              88448\n",
       "Sandstone          14983\n",
       "Limestone           8772\n",
       "Halite               987\n",
       "Anhydrite            418\n",
       "Tuff                 306\n",
       "Sandstone/Shale      265\n",
       "Chalk                 69\n",
       "Dolomite              54\n",
       "Coal                  41\n",
       "Marl                  25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['label_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "X_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DEPT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DTC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CALI",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "09ec1d4b-7d1e-48d5-9f49-29d66c438a37",
       "rows": [
        [
         "count",
         "249676.0",
         "249676.0",
         "249676.0",
         "249676.0",
         "249676.0",
         "249676.0",
         "249676.0",
         "249676.0"
        ],
        [
         "mean",
         "471167.8966310338",
         "6570307.06855685",
         "1827.8699388141513",
         "0.3752461395278268",
         "119.68442415802964",
         "2.2180889069368193",
         "60.316563867304716",
         "14.133997689765762"
        ],
        [
         "std",
         "25771.314471935966",
         "107304.42860916039",
         "852.4387343128775",
         "0.13754779561035854",
         "30.388532674699135",
         "0.25156796363621914",
         "29.171704574209887",
         "3.522576240603045"
        ],
        [
         "min",
         "437593.34375",
         "6435549.0",
         "136.086",
         "1.9752e-05",
         "12.386660576",
         "1.3577766417999997",
         "1.2736747264999997",
         "7.6197061539"
        ],
        [
         "25%",
         "444150.875",
         "6478952.0",
         "1186.6749989500001",
         "0.271553888925",
         "91.128583908",
         "2.0362788439",
         "37.844254493499996",
         "12.243706942000001"
        ],
        [
         "50%",
         "476768.125",
         "6523588.5",
         "1741.1243993999997",
         "0.4075998217000001",
         "126.25074768",
         "2.18015646935",
         "57.349401474000004",
         "13.178944110499998"
        ],
        [
         "75%",
         "487279.40625",
         "6643946.0",
         "2411.38350135",
         "0.4703018962999999",
         "145.4196548475",
         "2.4355837107",
         "80.842294693",
         "17.504580974250004"
        ],
        [
         "max",
         "520153.1875",
         "6759399.0",
         "4388.762000600002",
         "0.8552032709",
         "230.43295288",
         "3.2662498951",
         "264.59262085",
         "27.344881058"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>DTC</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>CALI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>249676.000000</td>\n",
       "      <td>2.496760e+05</td>\n",
       "      <td>249676.000000</td>\n",
       "      <td>249676.000000</td>\n",
       "      <td>249676.000000</td>\n",
       "      <td>249676.000000</td>\n",
       "      <td>249676.000000</td>\n",
       "      <td>249676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>471167.896631</td>\n",
       "      <td>6.570307e+06</td>\n",
       "      <td>1827.869939</td>\n",
       "      <td>0.375246</td>\n",
       "      <td>119.684424</td>\n",
       "      <td>2.218089</td>\n",
       "      <td>60.316564</td>\n",
       "      <td>14.133998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25771.314472</td>\n",
       "      <td>1.073044e+05</td>\n",
       "      <td>852.438734</td>\n",
       "      <td>0.137548</td>\n",
       "      <td>30.388533</td>\n",
       "      <td>0.251568</td>\n",
       "      <td>29.171705</td>\n",
       "      <td>3.522576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>437593.343750</td>\n",
       "      <td>6.435549e+06</td>\n",
       "      <td>136.086000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>12.386661</td>\n",
       "      <td>1.357777</td>\n",
       "      <td>1.273675</td>\n",
       "      <td>7.619706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>444150.875000</td>\n",
       "      <td>6.478952e+06</td>\n",
       "      <td>1186.674999</td>\n",
       "      <td>0.271554</td>\n",
       "      <td>91.128584</td>\n",
       "      <td>2.036279</td>\n",
       "      <td>37.844254</td>\n",
       "      <td>12.243707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>476768.125000</td>\n",
       "      <td>6.523588e+06</td>\n",
       "      <td>1741.124399</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>126.250748</td>\n",
       "      <td>2.180156</td>\n",
       "      <td>57.349401</td>\n",
       "      <td>13.178944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>487279.406250</td>\n",
       "      <td>6.643946e+06</td>\n",
       "      <td>2411.383501</td>\n",
       "      <td>0.470302</td>\n",
       "      <td>145.419655</td>\n",
       "      <td>2.435584</td>\n",
       "      <td>80.842295</td>\n",
       "      <td>17.504581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>520153.187500</td>\n",
       "      <td>6.759399e+06</td>\n",
       "      <td>4388.762001</td>\n",
       "      <td>0.855203</td>\n",
       "      <td>230.432953</td>\n",
       "      <td>3.266250</td>\n",
       "      <td>264.592621</td>\n",
       "      <td>27.344881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_LOC         Y_LOC           DEPT           NPHI  \\\n",
       "count  249676.000000  2.496760e+05  249676.000000  249676.000000   \n",
       "mean   471167.896631  6.570307e+06    1827.869939       0.375246   \n",
       "std     25771.314472  1.073044e+05     852.438734       0.137548   \n",
       "min    437593.343750  6.435549e+06     136.086000       0.000020   \n",
       "25%    444150.875000  6.478952e+06    1186.674999       0.271554   \n",
       "50%    476768.125000  6.523588e+06    1741.124399       0.407600   \n",
       "75%    487279.406250  6.643946e+06    2411.383501       0.470302   \n",
       "max    520153.187500  6.759399e+06    4388.762001       0.855203   \n",
       "\n",
       "                 DTC           RHOB             GR           CALI  \n",
       "count  249676.000000  249676.000000  249676.000000  249676.000000  \n",
       "mean      119.684424       2.218089      60.316564      14.133998  \n",
       "std        30.388533       0.251568      29.171705       3.522576  \n",
       "min        12.386661       1.357777       1.273675       7.619706  \n",
       "25%        91.128584       2.036279      37.844254      12.243707  \n",
       "50%       126.250748       2.180156      57.349401      13.178944  \n",
       "75%       145.419655       2.435584      80.842295      17.504581  \n",
       "max       230.432953       3.266250     264.592621      27.344881  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[['X_LOC','Y_LOC','DEPT','NPHI','DTC','RHOB','GR','CALI']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "X_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y_LOC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DEPT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DTC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CALI",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "24786220-845a-442e-94b0-4d1d587cf92d",
       "rows": [
        [
         "count",
         "114368.0",
         "114368.0",
         "114368.0",
         "114368.0",
         "114368.0",
         "114368.0",
         "114368.0",
         "114368.0"
        ],
        [
         "mean",
         "480192.1698314323",
         "6640369.464745384",
         "2533.8853695312114",
         "0.32593696741907907",
         "108.35293959766733",
         "2.317662182272542",
         "62.8596160807754",
         "62.8596160807754"
        ],
        [
         "std",
         "19612.107336245786",
         "136071.82020516795",
         "990.8803483369638",
         "0.11908727739784489",
         "30.152392551375602",
         "0.23742012571197282",
         "32.862980099488546",
         "32.862980099488546"
        ],
        [
         "min",
         "443841.28125",
         "6436486.0",
         "682.91320068",
         "2.263e-06",
         "38.974662781000006",
         "1.7048790455",
         "3.6702511311",
         "3.6702511311"
        ],
        [
         "25%",
         "463392.625",
         "6520634.0",
         "1761.005299875",
         "0.23620762588464317",
         "85.93261146525",
         "2.144723117325",
         "39.269442558499996",
         "39.269442558499996"
        ],
        [
         "50%",
         "479849.015625",
         "6608184.0",
         "2450.1828963",
         "0.31570124625",
         "100.40287398999999",
         "2.34803676605",
         "59.774505615500004",
         "59.774505615500004"
        ],
        [
         "75%",
         "501131.84375",
         "6771065.5",
         "3297.2055503250003",
         "0.4176253221792756",
         "133.2499046325",
         "2.520718634125",
         "90.0927791595",
         "90.0927791595"
        ],
        [
         "max",
         "515574.4375",
         "6853315.0",
         "5005.8979755",
         "0.6281248008385141",
         "199.95022583",
         "3.0154242516000003",
         "169.74417114",
         "169.74417114"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>DTC</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>CALI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114368.000000</td>\n",
       "      <td>1.143680e+05</td>\n",
       "      <td>114368.000000</td>\n",
       "      <td>114368.000000</td>\n",
       "      <td>114368.000000</td>\n",
       "      <td>114368.000000</td>\n",
       "      <td>114368.000000</td>\n",
       "      <td>114368.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>480192.169831</td>\n",
       "      <td>6.640369e+06</td>\n",
       "      <td>2533.885370</td>\n",
       "      <td>0.325937</td>\n",
       "      <td>108.352940</td>\n",
       "      <td>2.317662</td>\n",
       "      <td>62.859616</td>\n",
       "      <td>62.859616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19612.107336</td>\n",
       "      <td>1.360718e+05</td>\n",
       "      <td>990.880348</td>\n",
       "      <td>0.119087</td>\n",
       "      <td>30.152393</td>\n",
       "      <td>0.237420</td>\n",
       "      <td>32.862980</td>\n",
       "      <td>32.862980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>443841.281250</td>\n",
       "      <td>6.436486e+06</td>\n",
       "      <td>682.913201</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>38.974663</td>\n",
       "      <td>1.704879</td>\n",
       "      <td>3.670251</td>\n",
       "      <td>3.670251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>463392.625000</td>\n",
       "      <td>6.520634e+06</td>\n",
       "      <td>1761.005300</td>\n",
       "      <td>0.236208</td>\n",
       "      <td>85.932611</td>\n",
       "      <td>2.144723</td>\n",
       "      <td>39.269443</td>\n",
       "      <td>39.269443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>479849.015625</td>\n",
       "      <td>6.608184e+06</td>\n",
       "      <td>2450.182896</td>\n",
       "      <td>0.315701</td>\n",
       "      <td>100.402874</td>\n",
       "      <td>2.348037</td>\n",
       "      <td>59.774506</td>\n",
       "      <td>59.774506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>501131.843750</td>\n",
       "      <td>6.771066e+06</td>\n",
       "      <td>3297.205550</td>\n",
       "      <td>0.417625</td>\n",
       "      <td>133.249905</td>\n",
       "      <td>2.520719</td>\n",
       "      <td>90.092779</td>\n",
       "      <td>90.092779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>515574.437500</td>\n",
       "      <td>6.853315e+06</td>\n",
       "      <td>5005.897976</td>\n",
       "      <td>0.628125</td>\n",
       "      <td>199.950226</td>\n",
       "      <td>3.015424</td>\n",
       "      <td>169.744171</td>\n",
       "      <td>169.744171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_LOC         Y_LOC           DEPT           NPHI  \\\n",
       "count  114368.000000  1.143680e+05  114368.000000  114368.000000   \n",
       "mean   480192.169831  6.640369e+06    2533.885370       0.325937   \n",
       "std     19612.107336  1.360718e+05     990.880348       0.119087   \n",
       "min    443841.281250  6.436486e+06     682.913201       0.000002   \n",
       "25%    463392.625000  6.520634e+06    1761.005300       0.236208   \n",
       "50%    479849.015625  6.608184e+06    2450.182896       0.315701   \n",
       "75%    501131.843750  6.771066e+06    3297.205550       0.417625   \n",
       "max    515574.437500  6.853315e+06    5005.897976       0.628125   \n",
       "\n",
       "                 DTC           RHOB             GR           CALI  \n",
       "count  114368.000000  114368.000000  114368.000000  114368.000000  \n",
       "mean      108.352940       2.317662      62.859616      62.859616  \n",
       "std        30.152393       0.237420      32.862980      32.862980  \n",
       "min        38.974663       1.704879       3.670251       3.670251  \n",
       "25%        85.932611       2.144723      39.269443      39.269443  \n",
       "50%       100.402874       2.348037      59.774506      59.774506  \n",
       "75%       133.249905       2.520719      90.092779      90.092779  \n",
       "max       199.950226       3.015424     169.744171     169.744171  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_dataset.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RUL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
