{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_dataset = pd.read_csv(\"./dataset/undersampling_dataset_50_2.csv\")\n",
    "training_dataset.drop(columns=['PHI_S'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah sampel sebelum undersampling:\n",
      "Kelas 65000.0: 144966 sampel\n",
      "Kelas 30000.0: 43855 sampel\n",
      "Kelas 65030.0: 20284 sampel\n",
      "Kelas 70000.0: 16767 sampel\n",
      "Kelas 80000.0: 8245 sampel\n",
      "Kelas 70032.0: 5343 sampel\n",
      "Kelas 88000.0: 3919 sampel\n",
      "Kelas 99000.0: 3824 sampel\n",
      "Kelas 74000.0: 1109 sampel\n",
      "Kelas 90000.0: 1027 sampel\n",
      "Kelas 86000.0: 920 sampel\n",
      "Kelas 93000.0: 141 sampel\n",
      "\n",
      "Distribusi kelas setelah undersampling:\n",
      "Lithology_code\n",
      "65000.0    50000\n",
      "30000.0    43855\n",
      "65030.0    20284\n",
      "70000.0    16767\n",
      "80000.0     8245\n",
      "70032.0     5343\n",
      "88000.0     3919\n",
      "99000.0     3824\n",
      "74000.0     1109\n",
      "90000.0     1027\n",
      "86000.0      920\n",
      "93000.0      141\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "# Assume dataset_df_updated is your dataframe with 'Lithology_code' and feature columns\n",
    "\n",
    "# Define the list of majority classes to undersample\n",
    "majority_classes = [65000, 65030, 30000, 70000]  # Ganti dengan kode kelas mayoritas yang sesuai\n",
    "\n",
    "# Get class frequencies to understand the initial distribution\n",
    "class_counts = training_dataset['Lithology_code'].value_counts()\n",
    "\n",
    "# Display initial distribution\n",
    "print(\"Jumlah sampel sebelum undersampling:\")\n",
    "for cls in class_counts.index:\n",
    "    print(f\"Kelas {cls}: {class_counts[cls]} sampel\")\n",
    "\n",
    "# Identify minority classes (all classes not in majority_classes)\n",
    "minority_classes = [cls for cls in class_counts.index if cls not in majority_classes]\n",
    "\n",
    "target_size = 50000\n",
    "\n",
    "# Features used for clustering\n",
    "features_for_clustering = training_dataset.columns.to_list()\n",
    "\n",
    "# List to hold the processed dataframes\n",
    "df_list = []\n",
    "\n",
    "# Process each class group\n",
    "for cls, group in training_dataset.groupby('Lithology_code'):\n",
    "    if cls in majority_classes and len(group) > target_size:\n",
    "        # Perform clustering-based undersampling for majority class es exceeding target_size\n",
    "        n_clusters = target_size\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        group['Cluster'] = kmeans.fit_predict(group[features_for_clustering])\n",
    "        # Select one sample per cluster to maintain variation\n",
    "        group_undersampled = group.groupby('Cluster').apply(\n",
    "            lambda x: x.sample(1, random_state=42)\n",
    "        ).reset_index(drop=True)\n",
    "        df_list.append(group_undersampled.drop(columns=['Cluster']))\n",
    "    else:\n",
    "        # Keep all samples for minority classes or majority classes with size <= target_size\n",
    "        df_list.append(group)\n",
    "\n",
    "# Combine all processed dataframes\n",
    "df_balanced = pd.concat(df_list, ignore_index=True)\n",
    "df_balanced = shuffle(df_balanced, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the class distribution after undersampling\n",
    "print(\"\\nDistribusi kelas setelah undersampling:\")\n",
    "print(df_balanced['Lithology_code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.to_csv(\"./dataset/undersampling_dataset_50_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_43cda_row9_col1, #T_43cda_row13_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_43cda\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_43cda_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_43cda_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_43cda_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_43cda_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_43cda_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_43cda_row1_col1\" class=\"data row1 col1\" >Lithology_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_43cda_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_43cda_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_43cda_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_43cda_row3_col1\" class=\"data row3 col1\" >30000.0: 0, 65000.0: 1, 65030.0: 2, 70000.0: 3, 70032.0: 4, 74000.0: 5, 80000.0: 6, 86000.0: 7, 88000.0: 8, 90000.0: 9, 93000.0: 10, 99000.0: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_43cda_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_43cda_row4_col1\" class=\"data row4 col1\" >(124347, 13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_43cda_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_43cda_row5_col1\" class=\"data row5 col1\" >(124347, 13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_43cda_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_43cda_row6_col1\" class=\"data row6 col1\" >(87042, 13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_43cda_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_43cda_row7_col1\" class=\"data row7 col1\" >(37305, 13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_43cda_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_43cda_row8_col1\" class=\"data row8 col1\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_43cda_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_43cda_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_43cda_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_43cda_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_43cda_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_43cda_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_43cda_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_43cda_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_43cda_row13_col0\" class=\"data row13 col0\" >Normalize</td>\n",
       "      <td id=\"T_43cda_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_43cda_row14_col0\" class=\"data row14 col0\" >Normalize method</td>\n",
       "      <td id=\"T_43cda_row14_col1\" class=\"data row14 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_43cda_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_43cda_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_43cda_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_43cda_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_43cda_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_43cda_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_43cda_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_43cda_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_43cda_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_43cda_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_43cda_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_43cda_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43cda_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_43cda_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_43cda_row21_col1\" class=\"data row21 col1\" >db90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b680502100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b5aeb th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b5aeb_row0_col0, #T_b5aeb_row1_col0, #T_b5aeb_row1_col1, #T_b5aeb_row1_col2, #T_b5aeb_row1_col3, #T_b5aeb_row1_col4, #T_b5aeb_row1_col5, #T_b5aeb_row1_col6, #T_b5aeb_row1_col7, #T_b5aeb_row2_col0, #T_b5aeb_row2_col1, #T_b5aeb_row2_col2, #T_b5aeb_row2_col3, #T_b5aeb_row2_col4, #T_b5aeb_row2_col5, #T_b5aeb_row2_col6, #T_b5aeb_row2_col7, #T_b5aeb_row3_col0, #T_b5aeb_row3_col1, #T_b5aeb_row3_col2, #T_b5aeb_row3_col3, #T_b5aeb_row3_col4, #T_b5aeb_row3_col5, #T_b5aeb_row3_col6, #T_b5aeb_row3_col7, #T_b5aeb_row4_col0, #T_b5aeb_row4_col1, #T_b5aeb_row4_col2, #T_b5aeb_row4_col3, #T_b5aeb_row4_col4, #T_b5aeb_row4_col5, #T_b5aeb_row4_col6, #T_b5aeb_row4_col7, #T_b5aeb_row5_col0, #T_b5aeb_row5_col1, #T_b5aeb_row5_col2, #T_b5aeb_row5_col3, #T_b5aeb_row5_col4, #T_b5aeb_row5_col5, #T_b5aeb_row5_col6, #T_b5aeb_row5_col7, #T_b5aeb_row6_col0, #T_b5aeb_row6_col1, #T_b5aeb_row6_col2, #T_b5aeb_row6_col3, #T_b5aeb_row6_col4, #T_b5aeb_row6_col5, #T_b5aeb_row6_col6, #T_b5aeb_row6_col7, #T_b5aeb_row7_col0, #T_b5aeb_row7_col1, #T_b5aeb_row7_col2, #T_b5aeb_row7_col3, #T_b5aeb_row7_col4, #T_b5aeb_row7_col5, #T_b5aeb_row7_col6, #T_b5aeb_row7_col7, #T_b5aeb_row8_col0, #T_b5aeb_row8_col1, #T_b5aeb_row8_col2, #T_b5aeb_row8_col3, #T_b5aeb_row8_col4, #T_b5aeb_row8_col5, #T_b5aeb_row8_col6, #T_b5aeb_row8_col7, #T_b5aeb_row9_col0, #T_b5aeb_row9_col1, #T_b5aeb_row9_col2, #T_b5aeb_row9_col3, #T_b5aeb_row9_col4, #T_b5aeb_row9_col5, #T_b5aeb_row9_col6, #T_b5aeb_row9_col7, #T_b5aeb_row10_col0, #T_b5aeb_row10_col1, #T_b5aeb_row10_col2, #T_b5aeb_row10_col3, #T_b5aeb_row10_col4, #T_b5aeb_row10_col5, #T_b5aeb_row10_col6, #T_b5aeb_row10_col7, #T_b5aeb_row11_col0, #T_b5aeb_row11_col1, #T_b5aeb_row11_col2, #T_b5aeb_row11_col3, #T_b5aeb_row11_col4, #T_b5aeb_row11_col5, #T_b5aeb_row11_col6, #T_b5aeb_row11_col7, #T_b5aeb_row12_col0, #T_b5aeb_row12_col1, #T_b5aeb_row12_col2, #T_b5aeb_row12_col3, #T_b5aeb_row12_col4, #T_b5aeb_row12_col5, #T_b5aeb_row12_col6, #T_b5aeb_row12_col7, #T_b5aeb_row13_col0, #T_b5aeb_row13_col1, #T_b5aeb_row13_col2, #T_b5aeb_row13_col3, #T_b5aeb_row13_col4, #T_b5aeb_row13_col5, #T_b5aeb_row13_col6, #T_b5aeb_row13_col7, #T_b5aeb_row14_col0, #T_b5aeb_row14_col1, #T_b5aeb_row14_col2, #T_b5aeb_row14_col3, #T_b5aeb_row14_col4, #T_b5aeb_row14_col5, #T_b5aeb_row14_col6, #T_b5aeb_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b5aeb_row0_col1, #T_b5aeb_row0_col2, #T_b5aeb_row0_col3, #T_b5aeb_row0_col4, #T_b5aeb_row0_col5, #T_b5aeb_row0_col6, #T_b5aeb_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_b5aeb_row0_col8, #T_b5aeb_row1_col8, #T_b5aeb_row2_col8, #T_b5aeb_row3_col8, #T_b5aeb_row4_col8, #T_b5aeb_row5_col8, #T_b5aeb_row6_col8, #T_b5aeb_row7_col8, #T_b5aeb_row8_col8, #T_b5aeb_row9_col8, #T_b5aeb_row10_col8, #T_b5aeb_row11_col8, #T_b5aeb_row13_col8, #T_b5aeb_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_b5aeb_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b5aeb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5aeb_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b5aeb_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_b5aeb_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_b5aeb_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_b5aeb_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_b5aeb_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_b5aeb_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_b5aeb_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_b5aeb_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_b5aeb_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_b5aeb_row0_col1\" class=\"data row0 col1\" >0.9681</td>\n",
       "      <td id=\"T_b5aeb_row0_col2\" class=\"data row0 col2\" >0.9984</td>\n",
       "      <td id=\"T_b5aeb_row0_col3\" class=\"data row0 col3\" >0.9681</td>\n",
       "      <td id=\"T_b5aeb_row0_col4\" class=\"data row0 col4\" >0.9682</td>\n",
       "      <td id=\"T_b5aeb_row0_col5\" class=\"data row0 col5\" >0.9680</td>\n",
       "      <td id=\"T_b5aeb_row0_col6\" class=\"data row0 col6\" >0.9592</td>\n",
       "      <td id=\"T_b5aeb_row0_col7\" class=\"data row0 col7\" >0.9592</td>\n",
       "      <td id=\"T_b5aeb_row0_col8\" class=\"data row0 col8\" >1.0490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_b5aeb_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_b5aeb_row1_col1\" class=\"data row1 col1\" >0.9653</td>\n",
       "      <td id=\"T_b5aeb_row1_col2\" class=\"data row1 col2\" >0.9980</td>\n",
       "      <td id=\"T_b5aeb_row1_col3\" class=\"data row1 col3\" >0.9653</td>\n",
       "      <td id=\"T_b5aeb_row1_col4\" class=\"data row1 col4\" >0.9653</td>\n",
       "      <td id=\"T_b5aeb_row1_col5\" class=\"data row1 col5\" >0.9651</td>\n",
       "      <td id=\"T_b5aeb_row1_col6\" class=\"data row1 col6\" >0.9555</td>\n",
       "      <td id=\"T_b5aeb_row1_col7\" class=\"data row1 col7\" >0.9556</td>\n",
       "      <td id=\"T_b5aeb_row1_col8\" class=\"data row1 col8\" >3.7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row2\" class=\"row_heading level0 row2\" >xgboost</th>\n",
       "      <td id=\"T_b5aeb_row2_col0\" class=\"data row2 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_b5aeb_row2_col1\" class=\"data row2 col1\" >0.9614</td>\n",
       "      <td id=\"T_b5aeb_row2_col2\" class=\"data row2 col2\" >0.9978</td>\n",
       "      <td id=\"T_b5aeb_row2_col3\" class=\"data row2 col3\" >0.9614</td>\n",
       "      <td id=\"T_b5aeb_row2_col4\" class=\"data row2 col4\" >0.9614</td>\n",
       "      <td id=\"T_b5aeb_row2_col5\" class=\"data row2 col5\" >0.9613</td>\n",
       "      <td id=\"T_b5aeb_row2_col6\" class=\"data row2 col6\" >0.9506</td>\n",
       "      <td id=\"T_b5aeb_row2_col7\" class=\"data row2 col7\" >0.9506</td>\n",
       "      <td id=\"T_b5aeb_row2_col8\" class=\"data row2 col8\" >2.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_b5aeb_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_b5aeb_row3_col1\" class=\"data row3 col1\" >0.9359</td>\n",
       "      <td id=\"T_b5aeb_row3_col2\" class=\"data row3 col2\" >0.9591</td>\n",
       "      <td id=\"T_b5aeb_row3_col3\" class=\"data row3 col3\" >0.9359</td>\n",
       "      <td id=\"T_b5aeb_row3_col4\" class=\"data row3 col4\" >0.9360</td>\n",
       "      <td id=\"T_b5aeb_row3_col5\" class=\"data row3 col5\" >0.9359</td>\n",
       "      <td id=\"T_b5aeb_row3_col6\" class=\"data row3 col6\" >0.9181</td>\n",
       "      <td id=\"T_b5aeb_row3_col7\" class=\"data row3 col7\" >0.9181</td>\n",
       "      <td id=\"T_b5aeb_row3_col8\" class=\"data row3 col8\" >0.3270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row4\" class=\"row_heading level0 row4\" >knn</th>\n",
       "      <td id=\"T_b5aeb_row4_col0\" class=\"data row4 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_b5aeb_row4_col1\" class=\"data row4 col1\" >0.9348</td>\n",
       "      <td id=\"T_b5aeb_row4_col2\" class=\"data row4 col2\" >0.9880</td>\n",
       "      <td id=\"T_b5aeb_row4_col3\" class=\"data row4 col3\" >0.9348</td>\n",
       "      <td id=\"T_b5aeb_row4_col4\" class=\"data row4 col4\" >0.9348</td>\n",
       "      <td id=\"T_b5aeb_row4_col5\" class=\"data row4 col5\" >0.9345</td>\n",
       "      <td id=\"T_b5aeb_row4_col6\" class=\"data row4 col6\" >0.9166</td>\n",
       "      <td id=\"T_b5aeb_row4_col7\" class=\"data row4 col7\" >0.9166</td>\n",
       "      <td id=\"T_b5aeb_row4_col8\" class=\"data row4 col8\" >0.5070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row5\" class=\"row_heading level0 row5\" >gbc</th>\n",
       "      <td id=\"T_b5aeb_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_b5aeb_row5_col1\" class=\"data row5 col1\" >0.9030</td>\n",
       "      <td id=\"T_b5aeb_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row5_col3\" class=\"data row5 col3\" >0.9030</td>\n",
       "      <td id=\"T_b5aeb_row5_col4\" class=\"data row5 col4\" >0.9028</td>\n",
       "      <td id=\"T_b5aeb_row5_col5\" class=\"data row5 col5\" >0.9014</td>\n",
       "      <td id=\"T_b5aeb_row5_col6\" class=\"data row5 col6\" >0.8750</td>\n",
       "      <td id=\"T_b5aeb_row5_col7\" class=\"data row5 col7\" >0.8756</td>\n",
       "      <td id=\"T_b5aeb_row5_col8\" class=\"data row5 col8\" >74.3190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row6\" class=\"row_heading level0 row6\" >lightgbm</th>\n",
       "      <td id=\"T_b5aeb_row6_col0\" class=\"data row6 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_b5aeb_row6_col1\" class=\"data row6 col1\" >0.8428</td>\n",
       "      <td id=\"T_b5aeb_row6_col2\" class=\"data row6 col2\" >0.9087</td>\n",
       "      <td id=\"T_b5aeb_row6_col3\" class=\"data row6 col3\" >0.8428</td>\n",
       "      <td id=\"T_b5aeb_row6_col4\" class=\"data row6 col4\" >0.8482</td>\n",
       "      <td id=\"T_b5aeb_row6_col5\" class=\"data row6 col5\" >0.8441</td>\n",
       "      <td id=\"T_b5aeb_row6_col6\" class=\"data row6 col6\" >0.7994</td>\n",
       "      <td id=\"T_b5aeb_row6_col7\" class=\"data row6 col7\" >0.7997</td>\n",
       "      <td id=\"T_b5aeb_row6_col8\" class=\"data row6 col8\" >2.7320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row7\" class=\"row_heading level0 row7\" >lr</th>\n",
       "      <td id=\"T_b5aeb_row7_col0\" class=\"data row7 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_b5aeb_row7_col1\" class=\"data row7 col1\" >0.6762</td>\n",
       "      <td id=\"T_b5aeb_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row7_col3\" class=\"data row7 col3\" >0.6762</td>\n",
       "      <td id=\"T_b5aeb_row7_col4\" class=\"data row7 col4\" >0.6417</td>\n",
       "      <td id=\"T_b5aeb_row7_col5\" class=\"data row7 col5\" >0.6417</td>\n",
       "      <td id=\"T_b5aeb_row7_col6\" class=\"data row7 col6\" >0.5700</td>\n",
       "      <td id=\"T_b5aeb_row7_col7\" class=\"data row7 col7\" >0.5769</td>\n",
       "      <td id=\"T_b5aeb_row7_col8\" class=\"data row7 col8\" >1.5120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_b5aeb_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_b5aeb_row8_col1\" class=\"data row8 col1\" >0.6557</td>\n",
       "      <td id=\"T_b5aeb_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row8_col3\" class=\"data row8 col3\" >0.6557</td>\n",
       "      <td id=\"T_b5aeb_row8_col4\" class=\"data row8 col4\" >0.6304</td>\n",
       "      <td id=\"T_b5aeb_row8_col5\" class=\"data row8 col5\" >0.6170</td>\n",
       "      <td id=\"T_b5aeb_row8_col6\" class=\"data row8 col6\" >0.5432</td>\n",
       "      <td id=\"T_b5aeb_row8_col7\" class=\"data row8 col7\" >0.5503</td>\n",
       "      <td id=\"T_b5aeb_row8_col8\" class=\"data row8 col8\" >0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row9\" class=\"row_heading level0 row9\" >svm</th>\n",
       "      <td id=\"T_b5aeb_row9_col0\" class=\"data row9 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_b5aeb_row9_col1\" class=\"data row9 col1\" >0.6469</td>\n",
       "      <td id=\"T_b5aeb_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row9_col3\" class=\"data row9 col3\" >0.6469</td>\n",
       "      <td id=\"T_b5aeb_row9_col4\" class=\"data row9 col4\" >0.5963</td>\n",
       "      <td id=\"T_b5aeb_row9_col5\" class=\"data row9 col5\" >0.6067</td>\n",
       "      <td id=\"T_b5aeb_row9_col6\" class=\"data row9 col6\" >0.5315</td>\n",
       "      <td id=\"T_b5aeb_row9_col7\" class=\"data row9 col7\" >0.5395</td>\n",
       "      <td id=\"T_b5aeb_row9_col8\" class=\"data row9 col8\" >0.1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row10\" class=\"row_heading level0 row10\" >qda</th>\n",
       "      <td id=\"T_b5aeb_row10_col0\" class=\"data row10 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_b5aeb_row10_col1\" class=\"data row10 col1\" >0.6179</td>\n",
       "      <td id=\"T_b5aeb_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row10_col3\" class=\"data row10 col3\" >0.6179</td>\n",
       "      <td id=\"T_b5aeb_row10_col4\" class=\"data row10 col4\" >0.7040</td>\n",
       "      <td id=\"T_b5aeb_row10_col5\" class=\"data row10 col5\" >0.6217</td>\n",
       "      <td id=\"T_b5aeb_row10_col6\" class=\"data row10 col6\" >0.5300</td>\n",
       "      <td id=\"T_b5aeb_row10_col7\" class=\"data row10 col7\" >0.5421</td>\n",
       "      <td id=\"T_b5aeb_row10_col8\" class=\"data row10 col8\" >0.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row11\" class=\"row_heading level0 row11\" >ridge</th>\n",
       "      <td id=\"T_b5aeb_row11_col0\" class=\"data row11 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_b5aeb_row11_col1\" class=\"data row11 col1\" >0.6147</td>\n",
       "      <td id=\"T_b5aeb_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row11_col3\" class=\"data row11 col3\" >0.6147</td>\n",
       "      <td id=\"T_b5aeb_row11_col4\" class=\"data row11 col4\" >0.6000</td>\n",
       "      <td id=\"T_b5aeb_row11_col5\" class=\"data row11 col5\" >0.5429</td>\n",
       "      <td id=\"T_b5aeb_row11_col6\" class=\"data row11 col6\" >0.4729</td>\n",
       "      <td id=\"T_b5aeb_row11_col7\" class=\"data row11 col7\" >0.4926</td>\n",
       "      <td id=\"T_b5aeb_row11_col8\" class=\"data row11 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n",
       "      <td id=\"T_b5aeb_row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_b5aeb_row12_col1\" class=\"data row12 col1\" >0.5586</td>\n",
       "      <td id=\"T_b5aeb_row12_col2\" class=\"data row12 col2\" >0.8587</td>\n",
       "      <td id=\"T_b5aeb_row12_col3\" class=\"data row12 col3\" >0.5586</td>\n",
       "      <td id=\"T_b5aeb_row12_col4\" class=\"data row12 col4\" >0.6205</td>\n",
       "      <td id=\"T_b5aeb_row12_col5\" class=\"data row12 col5\" >0.5435</td>\n",
       "      <td id=\"T_b5aeb_row12_col6\" class=\"data row12 col6\" >0.4494</td>\n",
       "      <td id=\"T_b5aeb_row12_col7\" class=\"data row12 col7\" >0.4561</td>\n",
       "      <td id=\"T_b5aeb_row12_col8\" class=\"data row12 col8\" >0.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row13\" class=\"row_heading level0 row13\" >ada</th>\n",
       "      <td id=\"T_b5aeb_row13_col0\" class=\"data row13 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_b5aeb_row13_col1\" class=\"data row13 col1\" >0.4697</td>\n",
       "      <td id=\"T_b5aeb_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row13_col3\" class=\"data row13 col3\" >0.4697</td>\n",
       "      <td id=\"T_b5aeb_row13_col4\" class=\"data row13 col4\" >0.2942</td>\n",
       "      <td id=\"T_b5aeb_row13_col5\" class=\"data row13 col5\" >0.3589</td>\n",
       "      <td id=\"T_b5aeb_row13_col6\" class=\"data row13 col6\" >0.2426</td>\n",
       "      <td id=\"T_b5aeb_row13_col7\" class=\"data row13 col7\" >0.2686</td>\n",
       "      <td id=\"T_b5aeb_row13_col8\" class=\"data row13 col8\" >1.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5aeb_level0_row14\" class=\"row_heading level0 row14\" >dummy</th>\n",
       "      <td id=\"T_b5aeb_row14_col0\" class=\"data row14 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_b5aeb_row14_col1\" class=\"data row14 col1\" >0.3226</td>\n",
       "      <td id=\"T_b5aeb_row14_col2\" class=\"data row14 col2\" >0.5000</td>\n",
       "      <td id=\"T_b5aeb_row14_col3\" class=\"data row14 col3\" >0.3226</td>\n",
       "      <td id=\"T_b5aeb_row14_col4\" class=\"data row14 col4\" >0.1041</td>\n",
       "      <td id=\"T_b5aeb_row14_col5\" class=\"data row14 col5\" >0.1574</td>\n",
       "      <td id=\"T_b5aeb_row14_col6\" class=\"data row14 col6\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row14_col7\" class=\"data row14 col7\" >0.0000</td>\n",
       "      <td id=\"T_b5aeb_row14_col8\" class=\"data row14 col8\" >0.0480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b68085bb80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88653b30b1794f198ac873d0a8b0a0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset (ganti dengan dataset yang sesuai)\n",
    "data = training_dataset.copy()\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "target_column = \"Lithology_code\"  # Ganti dengan nama kolom target\n",
    "\n",
    "# Split dataset into train and test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setup PyCaret\n",
    "clf = setup(train_data, target=target_column, normalize=True, session_id=42)\n",
    "\n",
    "# Compare models and find the best one\n",
    "best_model = compare_models()\n",
    "\n",
    "# Evaluate best model on training data\n",
    "evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_365f0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_365f0_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_365f0_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_365f0_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_365f0_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_365f0_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_365f0_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_365f0_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_365f0_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_365f0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_365f0_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_365f0_row0_col1\" class=\"data row0 col1\" >0.9684</td>\n",
       "      <td id=\"T_365f0_row0_col2\" class=\"data row0 col2\" >0.9985</td>\n",
       "      <td id=\"T_365f0_row0_col3\" class=\"data row0 col3\" >0.9684</td>\n",
       "      <td id=\"T_365f0_row0_col4\" class=\"data row0 col4\" >0.9684</td>\n",
       "      <td id=\"T_365f0_row0_col5\" class=\"data row0 col5\" >0.9683</td>\n",
       "      <td id=\"T_365f0_row0_col6\" class=\"data row0 col6\" >0.9596</td>\n",
       "      <td id=\"T_365f0_row0_col7\" class=\"data row0 col7\" >0.9596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b681a72fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test data:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     30000.0       1.00      1.00      1.00      8813\n",
      "     65000.0       1.00      1.00      1.00      9885\n",
      "     65030.0       1.00      1.00      1.00      4147\n",
      "     70000.0       1.00      1.00      1.00      3343\n",
      "     70032.0       1.00      1.00      1.00      1034\n",
      "     74000.0       1.00      1.00      1.00       222\n",
      "     80000.0       1.00      1.00      1.00      1686\n",
      "     86000.0       1.00      1.00      1.00       181\n",
      "     88000.0       1.00      1.00      1.00       789\n",
      "     90000.0       1.00      1.00      1.00       201\n",
      "     93000.0       1.00      1.00      1.00        29\n",
      "     99000.0       1.00      1.00      1.00       757\n",
      "\n",
      "    accuracy                           1.00     31087\n",
      "   macro avg       1.00      1.00      1.00     31087\n",
      "weighted avg       1.00      1.00      1.00     31087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate best model on test data\n",
    "test_predictions = predict_model(best_model, data=test_data)\n",
    "print(\"Evaluation on test data:\")\n",
    "# print(test_predictions)\n",
    "\n",
    "# Measure prediction quality\n",
    "y_true = test_data[target_column]\n",
    "y_pred = test_predictions['Lithology_code']\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lithology_code\n",
       "65000.0    9885\n",
       "30000.0    8813\n",
       "65030.0    4147\n",
       "70000.0    3343\n",
       "80000.0    1686\n",
       "70032.0    1034\n",
       "88000.0     789\n",
       "99000.0     757\n",
       "74000.0     222\n",
       "90000.0     201\n",
       "86000.0     181\n",
       "93000.0      29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('label_encoding',\n",
       "                  TransformerWrapperWithInverse(exclude=None, include=None,\n",
       "                                                transformer=LabelEncoder())),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['SP', 'GR', 'DTC', 'Y_LOC', 'DRHO',\n",
       "                                              'RHOB', 'NPHI', 'X_LOC', 'CALI',\n",
       "                                              'DEPT', 'Vclay', 'NDPD'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               f...\n",
       "                  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                                       class_weight=None, criterion='gini',\n",
       "                                       max_depth=None, max_features='sqrt',\n",
       "                                       max_leaf_nodes=None, max_samples=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       monotonic_cst=None, n_estimators=100,\n",
       "                                       n_jobs=-1, oob_score=False,\n",
       "                                       random_state=42, verbose=0,\n",
       "                                       warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_model_1.pkl')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import save_model\n",
    "\n",
    "# Simpan model\n",
    "save_model(best_model, 'best_model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## EXTRA TREES CLASSFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250400, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_full = pd.read_csv(\"./dataset/ready_training_dataset.csv\")\n",
    "dataset_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9808\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     30000.0       0.98      0.98      0.98      8677\n",
      "     65000.0       0.98      0.99      0.99     29001\n",
      "     65030.0       0.96      0.93      0.95      4095\n",
      "     70000.0       0.98      0.94      0.96      3394\n",
      "     70032.0       0.99      0.98      0.98      1033\n",
      "     74000.0       0.99      0.82      0.90       227\n",
      "     80000.0       0.97      0.96      0.96      1654\n",
      "     86000.0       0.98      0.99      0.99       174\n",
      "     88000.0       1.00      1.00      1.00       815\n",
      "     90000.0       0.98      0.94      0.96       202\n",
      "     93000.0       1.00      1.00      1.00        20\n",
      "     99000.0       0.98      0.97      0.98       788\n",
      "\n",
      "    accuracy                           0.98     50080\n",
      "   macro avg       0.98      0.96      0.97     50080\n",
      "weighted avg       0.98      0.98      0.98     50080\n",
      "\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best cross-validation accuracy: 0.9788039137380192\n",
      "Final accuracy with tuned model: 0.9814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = dataset_full.drop(columns=['Lithology_code'])\n",
    "y = dataset_full['Lithology_code']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train Extra Trees Classifier\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    ExtraTreesClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Use best model for final prediction\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Print final accuracy\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Final accuracy with tuned model: {final_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lithology_code', 'SP', 'GR', 'DTC', 'Y_LOC', 'DRHO', 'RHOB', 'NPHI',\n",
       "       'X_LOC', 'CALI', 'DEPT', 'Vclay', 'NDPD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9814\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     30000.0       0.98      0.98      0.98      8677\n",
      "     65000.0       0.98      0.99      0.99     29001\n",
      "     65030.0       0.96      0.94      0.95      4095\n",
      "     70000.0       0.98      0.95      0.96      3394\n",
      "     70032.0       0.99      0.98      0.99      1033\n",
      "     74000.0       0.99      0.81      0.89       227\n",
      "     80000.0       0.97      0.96      0.96      1654\n",
      "     86000.0       0.98      0.99      0.99       174\n",
      "     88000.0       1.00      1.00      1.00       815\n",
      "     90000.0       0.97      0.93      0.95       202\n",
      "     93000.0       0.95      1.00      0.98        20\n",
      "     99000.0       0.98      0.97      0.98       788\n",
      "\n",
      "    accuracy                           0.98     50080\n",
      "   macro avg       0.98      0.96      0.97     50080\n",
      "weighted avg       0.98      0.98      0.98     50080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = dataset_full.drop(columns=['Lithology_code'])\n",
    "y = dataset_full['Lithology_code']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train Extra Trees Classifier\n",
    "model = ExtraTreesClassifier(n_estimators=300, random_state=42, min_samples_split = 2, min_samples_leaf = 1, max_depth = None)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extra_trees_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'extra_trees_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RUL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
